{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import logging\n",
    "import os\n",
    "from pathlib import Path\n",
    "from pprint import pprint as pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mnt/d/imperial/second_term/adls/rs1923/mase_real'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# figure out the correct path\n",
    "machop_path = Path(\".\").resolve().parent.parent /\"rs1923/mase_real/machop\"\n",
    "assert machop_path.exists(), \"Failed to find machop at: {}\".format(machop_path)\n",
    "sys.path.append(str(machop_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ruiqi/anaconda3/envs/mase/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of JSC_1923 parameters: 3285\n",
      "Total number of JSC_Tiny parameters: 117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mSet logging level to debug\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from chop.dataset import MaseDataModule, get_dataset_info\n",
    "from chop.tools.logger import set_logging_verbosity\n",
    "\n",
    "from chop.passes.graph import (\n",
    "    save_node_meta_param_interface_pass,\n",
    "    report_node_meta_param_analysis_pass,\n",
    "    profile_statistics_analysis_pass,\n",
    "    add_common_metadata_analysis_pass,\n",
    "    init_metadata_analysis_pass,\n",
    "    add_software_metadata_analysis_pass,\n",
    ")\n",
    "from chop.tools.get_input import InputGenerator\n",
    "from chop.tools.checkpoint_load import load_model\n",
    "from chop.ir import MaseGraph\n",
    "\n",
    "from chop.models import get_model_info, get_model\n",
    "\n",
    "set_logging_verbosity(\"debug\") # shift to \"debug\" mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the dataset\n",
    "\n",
    "batch_size = 8\n",
    "model_name = \"jsc-tiny\"\n",
    "#model_name = \"jsc-rs1923\"\n",
    "dataset_name = \"jsc\"\n",
    "\n",
    "data_module = MaseDataModule(\n",
    "    name=dataset_name,\n",
    "    batch_size=batch_size,\n",
    "    model_name=model_name,\n",
    "    num_workers=0,\n",
    ")\n",
    "data_module.prepare_data()\n",
    "data_module.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mLoaded pytorch lightning checkpoint from ./mase_output/jsc-tiny_classification_jsc_2024-02-03/software/training_ckpts/best.ckpt\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# set up the model\n",
    "\n",
    "model_info = get_model_info(model_name)\n",
    "model = get_model(\n",
    "    model_name,\n",
    "    task=\"cls\",\n",
    "    dataset_info=data_module.dataset_info,\n",
    "    pretrained=False,\n",
    "    checkpoint=None)\n",
    "\n",
    "# we use the one that we've trained for 10 epochs on colab\n",
    "CHECKPOINT_PATH = \"./mase_output/jsc-tiny_classification_jsc_2024-02-03/software/training_ckpts/best.ckpt\"  #for JSC-Tiny\n",
    "#CHECKPOINT_PATH = \"./mase_output/jsc-rs1923_classification_jsc_2024-02-05/software/training_ckpts/best.ckpt\"   #for JSC-rs1923\n",
    "\n",
    "own_model = load_model(load_name=CHECKPOINT_PATH, load_type=\"pl\", model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate the mase graph and initialize node metadata\n",
    "mg = MaseGraph(model = own_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the input generator\n",
    "input_generator = InputGenerator(\n",
    "    data_module=data_module,\n",
    "    model_info=model_info,\n",
    "    task=\"cls\",\n",
    "    which_dataloader=\"train\",\n",
    ")\n",
    "\n",
    "# a demonstration of how to feed an input value to the model\n",
    "dummy_in = next(iter(input_generator))\n",
    "_ = model(**dummy_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 1, 16])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_in['x'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36mDEBUG   \u001b[0m \u001b[34mgraph():\n",
      "    %x : [num_users=1] = placeholder[target=x]\n",
      "    %conv1 : [num_users=1] = call_module[target=conv1](args = (%x,), kwargs = {})\n",
      "    %relu : [num_users=1] = call_function[target=torch.nn.functional.relu](args = (%conv1,), kwargs = {inplace: False})\n",
      "    %conv2 : [num_users=1] = call_module[target=conv2](args = (%relu,), kwargs = {})\n",
      "    %relu_1 : [num_users=2] = call_function[target=torch.nn.functional.relu](args = (%conv2,), kwargs = {inplace: False})\n",
      "    %block_conv1 : [num_users=1] = call_module[target=block.conv1](args = (%relu_1,), kwargs = {})\n",
      "    %relu_2 : [num_users=1] = call_function[target=torch.nn.functional.relu](args = (%block_conv1,), kwargs = {inplace: False})\n",
      "    %block_conv2 : [num_users=1] = call_module[target=block.conv2](args = (%relu_2,), kwargs = {})\n",
      "    %add : [num_users=1] = call_function[target=operator.add](args = (%block_conv2, %relu_1), kwargs = {})\n",
      "    %relu_3 : [num_users=1] = call_function[target=torch.nn.functional.relu](args = (%add,), kwargs = {inplace: False})\n",
      "    %view : [num_users=1] = call_method[target=view](args = (%relu_3, -1, 256), kwargs = {})\n",
      "    %fc : [num_users=1] = call_module[target=fc](args = (%view,), kwargs = {})\n",
      "    %relu_4 : [num_users=1] = call_function[target=torch.nn.functional.relu](args = (%fc,), kwargs = {inplace: False})\n",
      "    return relu_4\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "mg, _ = init_metadata_analysis_pass(mg, None)\n",
    "mg, _ = add_common_metadata_analysis_pass(mg, {\"dummy_in\": dummy_in})\n",
    "mg, _ = add_software_metadata_analysis_pass(mg, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph():\n",
      "    %x : [num_users=1] = placeholder[target=x]\n",
      "    %conv1 : [num_users=1] = call_module[target=conv1](args = (%x,), kwargs = {})\n",
      "    %relu : [num_users=1] = call_function[target=torch.nn.functional.relu](args = (%conv1,), kwargs = {inplace: False})\n",
      "    %conv2 : [num_users=1] = call_module[target=conv2](args = (%relu,), kwargs = {})\n",
      "    %relu_1 : [num_users=2] = call_function[target=torch.nn.functional.relu](args = (%conv2,), kwargs = {inplace: False})\n",
      "    %block_conv1 : [num_users=1] = call_module[target=block.conv1](args = (%relu_1,), kwargs = {})\n",
      "    %relu_2 : [num_users=1] = call_function[target=torch.nn.functional.relu](args = (%block_conv1,), kwargs = {inplace: False})\n",
      "    %block_conv2 : [num_users=1] = call_module[target=block.conv2](args = (%relu_2,), kwargs = {})\n",
      "    %add : [num_users=1] = call_function[target=operator.add](args = (%block_conv2, %relu_1), kwargs = {})\n",
      "    %relu_3 : [num_users=1] = call_function[target=torch.nn.functional.relu](args = (%add,), kwargs = {inplace: False})\n",
      "    %view : [num_users=1] = call_method[target=view](args = (%relu_3, -1, 256), kwargs = {})\n",
      "    %fc : [num_users=1] = call_module[target=fc](args = (%view,), kwargs = {})\n",
      "    %relu_4 : [num_users=1] = call_function[target=torch.nn.functional.relu](args = (%fc,), kwargs = {inplace: False})\n",
      "    return relu_4\n",
      "Network overview:\n",
      "{'placeholder': 1, 'get_attr': 0, 'call_function': 6, 'call_method': 1, 'call_module': 5, 'output': 1}\n",
      "Layer types:\n",
      "[Conv1d(1, 8, kernel_size=(3,), stride=(1,), padding=(1,)), Conv1d(8, 16, kernel_size=(3,), stride=(1,), padding=(1,)), Conv1d(16, 16, kernel_size=(3,), stride=(1,), padding=(1,)), Conv1d(16, 16, kernel_size=(3,), stride=(1,), padding=(1,)), Linear(in_features=256, out_features=5, bias=True)]\n"
     ]
    }
   ],
   "source": [
    "# report graph is an analysis pass that shows you the detailed information in the graph\n",
    "from chop.passes import report_graph_analysis_pass\n",
    "_ = report_graph_analysis_pass(mg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# at present, designed only for JSC-Tiny \n",
    "\n",
    "pass_args = {\n",
    "    \"by\": \"type\",                                                            # collect statistics by node name\n",
    "    \"target_weight_nodes\": [\"linear\"],                                       # collect weight statistics for linear layers\n",
    "    \"target_activation_nodes\": [\"relu\"],                                     # collect activation statistics for relu layers\n",
    "    \"weight_statistics\": {\n",
    "        \"variance_precise\": {\"device\": \"cpu\", \"dims\": \"all\"},                # collect precise variance of the weight\n",
    "    },\n",
    "    \"activation_statistics\": {\n",
    "        \"range_quantile\": {\"device\": \"cpu\", \"dims\": \"all\", \"quantile\": 0.97} # collect 97% quantile of the activation range\n",
    "    },\n",
    "    \"input_generator\": input_generator,                                      # the input generator for feeding data to the model\n",
    "    \"num_samples\": 32,                                                       # feed 32 samples to the model\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Profiling weight statistics: 100%|██████████| 6/6 [00:00<00:00, 4629.47it/s]\n",
      "Profiling act statistics: 100%|██████████| 4/4 [00:00<00:00, 143.95it/s]\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mInspecting graph [add_common_meta_param_analysis_pass]\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
      "+--------------+--------------+---------------------+--------------+------------------------------------------------------------------------------------------+\n",
      "| Node name    | Fx Node op   | Mase type           | Mase op      | Software Param                                                                           |\n",
      "+==============+==============+=====================+==============+==========================================================================================+\n",
      "| x            | placeholder  | placeholder         | placeholder  | {'results': {'data_out_0': {'stat': {}}}}                                                |\n",
      "+--------------+--------------+---------------------+--------------+------------------------------------------------------------------------------------------+\n",
      "| seq_blocks_0 | call_module  | module              | batch_norm1d | {'args': {'bias': {'stat': {}},                                                          |\n",
      "|              |              |                     |              |           'data_in_0': {'stat': {}},                                                     |\n",
      "|              |              |                     |              |           'running_mean': {'stat': {}},                                                  |\n",
      "|              |              |                     |              |           'running_var': {'stat': {}},                                                   |\n",
      "|              |              |                     |              |           'weight': {'stat': {}}},                                                       |\n",
      "|              |              |                     |              |  'results': {'data_out_0': {'stat': {}}}}                                                |\n",
      "+--------------+--------------+---------------------+--------------+------------------------------------------------------------------------------------------+\n",
      "| seq_blocks_1 | call_module  | module_related_func | relu         | {'args': {'data_in_0': {'stat': {'range_quantile': {'count': 512,                        |\n",
      "|              |              |                     |              |                                                     'max': 2.0015931129455566,           |\n",
      "|              |              |                     |              |                                                     'min': -1.525671124458313,           |\n",
      "|              |              |                     |              |                                                     'range': 3.52726411819458}}}},       |\n",
      "|              |              |                     |              |  'results': {'data_out_0': {'stat': {}}}}                                                |\n",
      "+--------------+--------------+---------------------+--------------+------------------------------------------------------------------------------------------+\n",
      "| seq_blocks_2 | call_module  | module_related_func | linear       | {'args': {'bias': {'stat': {'variance_precise': {'count': 5,                             |\n",
      "|              |              |                     |              |                                                  'mean': -0.010053220205008984,          |\n",
      "|              |              |                     |              |                                                  'variance': 0.05255531892180443}}},     |\n",
      "|              |              |                     |              |           'data_in_0': {'stat': {}},                                                     |\n",
      "|              |              |                     |              |           'weight': {'stat': {'variance_precise': {'count': 80,                          |\n",
      "|              |              |                     |              |                                                    'mean': -0.009381229057908058,        |\n",
      "|              |              |                     |              |                                                    'variance': 0.020840153098106384}}}}, |\n",
      "|              |              |                     |              |  'results': {'data_out_0': {'stat': {}}}}                                                |\n",
      "+--------------+--------------+---------------------+--------------+------------------------------------------------------------------------------------------+\n",
      "| seq_blocks_3 | call_module  | module_related_func | relu         | {'args': {'data_in_0': {'stat': {'range_quantile': {'count': 160,                        |\n",
      "|              |              |                     |              |                                                     'max': 0.803267240524292,            |\n",
      "|              |              |                     |              |                                                     'min': -1.0490492582321167,          |\n",
      "|              |              |                     |              |                                                     'range': 1.8523164987564087}}}},     |\n",
      "|              |              |                     |              |  'results': {'data_out_0': {'stat': {}}}}                                                |\n",
      "+--------------+--------------+---------------------+--------------+------------------------------------------------------------------------------------------+\n",
      "| output       | output       | output              | output       | {'args': {'data_in_0': {'stat': {}}}}                                                    |\n",
      "+--------------+--------------+---------------------+--------------+------------------------------------------------------------------------------------------+\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# at present, designed only for JSC-Tiny\n",
    "\n",
    "mg, _ = profile_statistics_analysis_pass(mg, pass_args)\n",
    "mg, _ = report_node_meta_param_analysis_pass(mg, {\"which\": (\"software\",)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mInspecting graph [add_common_meta_param_analysis_pass]\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
      "+--------------+--------------+---------------------+--------------+-----------------------------------------------------------------------------------------------------------------------+\n",
      "| Node name    | Fx Node op   | Mase type           | Mase op      | Common Param                                                                                                          |\n",
      "+==============+==============+=====================+==============+=======================================================================================================================+\n",
      "| x            | placeholder  | placeholder         | placeholder  | {'args': {},                                                                                                          |\n",
      "|              |              |                     |              |  'mase_op': 'placeholder',                                                                                            |\n",
      "|              |              |                     |              |  'mase_type': 'placeholder',                                                                                          |\n",
      "|              |              |                     |              |  'results': {'data_out_0': {'precision': [32],                                                                        |\n",
      "|              |              |                     |              |                             'shape': [8, 16],                                                                         |\n",
      "|              |              |                     |              |                             'torch_dtype': torch.float32,                                                             |\n",
      "|              |              |                     |              |                             'type': 'float',                                                                          |\n",
      "|              |              |                     |              |                             'value': tensor([[-1.6374,  0.8681,  1.5298,  1.5143,  2.3048,  2.8574,  0.8078,  1.2207, |\n",
      "|              |              |                     |              |           0.8078,  1.2124,  0.8705,  0.4587,  1.1623,  1.0441,  1.3870,  2.5328],                                     |\n",
      "|              |              |                     |              |         [-0.4317,  0.5679,  1.7765,  1.9288,  0.7575,  0.3844, -0.9782, -0.8207,                                      |\n",
      "|              |              |                     |              |          -0.9782, -0.6207, -0.2976, -0.4898, -0.7933, -0.8126,  1.4724,  0.4106],                                     |\n",
      "|              |              |                     |              |         [ 0.5604,  0.2078, -0.0286, -0.1999, -0.2109, -0.4424, -0.5674, -0.9631,                                      |\n",
      "|              |              |                     |              |          -0.5674, -1.0642, -0.9840, -0.9869, -0.9588, -1.1134,  0.0976, -1.2293],                                     |\n",
      "|              |              |                     |              |         [-1.1156,  0.7785,  0.2948, -0.2028,  0.2327, -0.1615, -0.2087, -0.1632,                                      |\n",
      "|              |              |                     |              |          -0.2087,  0.8908,  1.3089,  1.2637,  0.8901,  0.7605,  0.0036,  0.6035],                                     |\n",
      "|              |              |                     |              |         [ 0.6127, -0.5371, -1.1590, -0.8422, -0.9751, -0.6138,  1.4957,  1.8351,                                      |\n",
      "|              |              |                     |              |           1.4957,  0.8588,  0.3013,  0.0146,  1.0341,  0.8774, -1.2074, -0.4094],                                     |\n",
      "|              |              |                     |              |         [-1.0749,  0.7965, -0.0521, -0.4214,  0.1285, -0.2064,  0.2761,  0.3212,                                      |\n",
      "|              |              |                     |              |           0.2761,  1.0950,  1.2917,  0.7525,  0.9033,  0.5215, -0.1968,  0.1212],                                     |\n",
      "|              |              |                     |              |         [-0.0047,  0.2718, -0.0053, -0.1007,  0.2397, -0.1479,  0.4169, -0.3106,                                      |\n",
      "|              |              |                     |              |           0.4169, -0.7319, -0.7612, -1.0257, -0.4013, -0.7222,  0.3493, -0.6023],                                     |\n",
      "|              |              |                     |              |         [-0.7658,  0.4269, -0.9402, -0.8135, -0.7796, -0.5837,  0.5059,  0.7632,                                      |\n",
      "|              |              |                     |              |           0.5059,  1.4739,  1.5435,  1.1988,  1.2301,  0.9327, -1.0919,  0.9411]])}}}                                 |\n",
      "+--------------+--------------+---------------------+--------------+-----------------------------------------------------------------------------------------------------------------------+\n",
      "| seq_blocks_0 | call_module  | module              | batch_norm1d | {'args': {'bias': {'from': None,                                                                                      |\n",
      "|              |              |                     |              |                    'precision': [32],                                                                                 |\n",
      "|              |              |                     |              |                    'shape': [16],                                                                                     |\n",
      "|              |              |                     |              |                    'type': 'float',                                                                                   |\n",
      "|              |              |                     |              |                    'value': Parameter containing:                                                                     |\n",
      "|              |              |                     |              | tensor([-0.0258, -0.0276,  0.0286,  0.0324,  0.0203,  0.0295,  0.0198,  0.0240,                                       |\n",
      "|              |              |                     |              |         -0.0233,  0.0135, -0.0043, -0.0164, -0.0185,  0.0131,  0.0303, -0.0279],                                      |\n",
      "|              |              |                     |              |        requires_grad=True)},                                                                                          |\n",
      "|              |              |                     |              |           'data_in_0': {'precision': [32],                                                                            |\n",
      "|              |              |                     |              |                         'shape': [8, 16],                                                                             |\n",
      "|              |              |                     |              |                         'torch_dtype': torch.float32,                                                                 |\n",
      "|              |              |                     |              |                         'type': 'float',                                                                              |\n",
      "|              |              |                     |              |                         'value': tensor([[-1.6374,  0.8681,  1.5298,  1.5143,  2.3048,  2.8574,  0.8078,  1.2207,     |\n",
      "|              |              |                     |              |           0.8078,  1.2124,  0.8705,  0.4587,  1.1623,  1.0441,  1.3870,  2.5328],                                     |\n",
      "|              |              |                     |              |         [-0.4317,  0.5679,  1.7765,  1.9288,  0.7575,  0.3844, -0.9782, -0.8207,                                      |\n",
      "|              |              |                     |              |          -0.9782, -0.6207, -0.2976, -0.4898, -0.7933, -0.8126,  1.4724,  0.4106],                                     |\n",
      "|              |              |                     |              |         [ 0.5604,  0.2078, -0.0286, -0.1999, -0.2109, -0.4424, -0.5674, -0.9631,                                      |\n",
      "|              |              |                     |              |          -0.5674, -1.0642, -0.9840, -0.9869, -0.9588, -1.1134,  0.0976, -1.2293],                                     |\n",
      "|              |              |                     |              |         [-1.1156,  0.7785,  0.2948, -0.2028,  0.2327, -0.1615, -0.2087, -0.1632,                                      |\n",
      "|              |              |                     |              |          -0.2087,  0.8908,  1.3089,  1.2637,  0.8901,  0.7605,  0.0036,  0.6035],                                     |\n",
      "|              |              |                     |              |         [ 0.6127, -0.5371, -1.1590, -0.8422, -0.9751, -0.6138,  1.4957,  1.8351,                                      |\n",
      "|              |              |                     |              |           1.4957,  0.8588,  0.3013,  0.0146,  1.0341,  0.8774, -1.2074, -0.4094],                                     |\n",
      "|              |              |                     |              |         [-1.0749,  0.7965, -0.0521, -0.4214,  0.1285, -0.2064,  0.2761,  0.3212,                                      |\n",
      "|              |              |                     |              |           0.2761,  1.0950,  1.2917,  0.7525,  0.9033,  0.5215, -0.1968,  0.1212],                                     |\n",
      "|              |              |                     |              |         [-0.0047,  0.2718, -0.0053, -0.1007,  0.2397, -0.1479,  0.4169, -0.3106,                                      |\n",
      "|              |              |                     |              |           0.4169, -0.7319, -0.7612, -1.0257, -0.4013, -0.7222,  0.3493, -0.6023],                                     |\n",
      "|              |              |                     |              |         [-0.7658,  0.4269, -0.9402, -0.8135, -0.7796, -0.5837,  0.5059,  0.7632,                                      |\n",
      "|              |              |                     |              |           0.5059,  1.4739,  1.5435,  1.1988,  1.2301,  0.9327, -1.0919,  0.9411]])},                                  |\n",
      "|              |              |                     |              |           'weight': {'from': None,                                                                                    |\n",
      "|              |              |                     |              |                      'precision': [32],                                                                               |\n",
      "|              |              |                     |              |                      'shape': [16],                                                                                   |\n",
      "|              |              |                     |              |                      'type': 'float',                                                                                 |\n",
      "|              |              |                     |              |                      'value': Parameter containing:                                                                   |\n",
      "|              |              |                     |              | tensor([0.9836, 0.9726, 1.0321, 1.0193, 1.0309, 1.0305, 1.0039, 1.0156, 0.9823,                                       |\n",
      "|              |              |                     |              |         0.9764, 0.9750, 0.9737, 0.9856, 1.0223, 1.0300, 0.9724],                                                      |\n",
      "|              |              |                     |              |        requires_grad=True)}},                                                                                         |\n",
      "|              |              |                     |              |  'mase_op': 'batch_norm1d',                                                                                           |\n",
      "|              |              |                     |              |  'mase_type': 'module',                                                                                               |\n",
      "|              |              |                     |              |  'results': {'data_out_0': {'precision': [32],                                                                        |\n",
      "|              |              |                     |              |                             'shape': [8, 16],                                                                         |\n",
      "|              |              |                     |              |                             'torch_dtype': torch.float32,                                                             |\n",
      "|              |              |                     |              |                             'type': 'float',                                                                          |\n",
      "|              |              |                     |              |                             'value': tensor([[0.0000, 0.9813, 1.4646, 1.5071, 2.2854, 2.6494, 0.8233, 1.1075, 0.7630, |\n",
      "|              |              |                     |              |          0.8599, 0.4797, 0.3356, 0.8626, 1.0501, 1.4632, 2.0016],                                                     |\n",
      "|              |              |                     |              |         [0.0390, 0.3015, 1.7264, 1.9417, 0.6105, 0.2689, 0.0000, 0.0000, 0.0000,                                      |\n",
      "|              |              |                     |              |          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.5584, 0.0761],                                                     |\n",
      "|              |              |                     |              |         [1.3144, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,                                      |\n",
      "|              |              |                     |              |          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0257, 0.0000],                                                     |\n",
      "|              |              |                     |              |         [0.0000, 0.7785, 0.1537, 0.0000, 0.0425, 0.0000, 0.0000, 0.0000, 0.0000,                                      |\n",
      "|              |              |                     |              |          0.5292, 0.9396, 1.2482, 0.5546, 0.7074, 0.0000, 0.2511],                                                     |\n",
      "|              |              |                     |              |         [1.3816, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.7613, 1.7830, 1.6807,                                      |\n",
      "|              |              |                     |              |          0.4964, 0.0000, 0.0000, 0.7175, 0.8486, 0.0000, 0.0000],                                                     |\n",
      "|              |              |                     |              |         [0.0000, 0.8191, 0.0000, 0.0000, 0.0000, 0.0000, 0.0984, 0.1185, 0.0536,                                      |\n",
      "|              |              |                     |              |          0.7392, 0.9216, 0.6686, 0.5697, 0.4186, 0.0000, 0.0000],                                                     |\n",
      "|              |              |                     |              |         [0.5879, 0.0000, 0.0000, 0.0000, 0.0501, 0.0000, 0.2903, 0.0000, 0.2414,                                      |\n",
      "|              |              |                     |              |          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3064, 0.0000],                                                     |\n",
      "|              |              |                     |              |         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.4116, 0.6045, 0.3601,                                      |\n",
      "|              |              |                     |              |          1.1288, 1.1857, 1.1746, 0.9392, 0.9155, 0.0000, 0.5575]],                                                    |\n",
      "|              |              |                     |              |        grad_fn=<ReluBackward0>)}}}                                                                                    |\n",
      "+--------------+--------------+---------------------+--------------+-----------------------------------------------------------------------------------------------------------------------+\n",
      "| seq_blocks_1 | call_module  | module_related_func | relu         | {'args': {'data_in_0': {'precision': [32],                                                                            |\n",
      "|              |              |                     |              |                         'shape': [8, 16],                                                                             |\n",
      "|              |              |                     |              |                         'torch_dtype': torch.float32,                                                                 |\n",
      "|              |              |                     |              |                         'type': 'float',                                                                              |\n",
      "|              |              |                     |              |                         'value': tensor([[0.0000, 0.9813, 1.4646, 1.5071, 2.2854, 2.6494, 0.8233, 1.1075, 0.7630,     |\n",
      "|              |              |                     |              |          0.8599, 0.4797, 0.3356, 0.8626, 1.0501, 1.4632, 2.0016],                                                     |\n",
      "|              |              |                     |              |         [0.0390, 0.3015, 1.7264, 1.9417, 0.6105, 0.2689, 0.0000, 0.0000, 0.0000,                                      |\n",
      "|              |              |                     |              |          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.5584, 0.0761],                                                     |\n",
      "|              |              |                     |              |         [1.3144, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,                                      |\n",
      "|              |              |                     |              |          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0257, 0.0000],                                                     |\n",
      "|              |              |                     |              |         [0.0000, 0.7785, 0.1537, 0.0000, 0.0425, 0.0000, 0.0000, 0.0000, 0.0000,                                      |\n",
      "|              |              |                     |              |          0.5292, 0.9396, 1.2482, 0.5546, 0.7074, 0.0000, 0.2511],                                                     |\n",
      "|              |              |                     |              |         [1.3816, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.7613, 1.7830, 1.6807,                                      |\n",
      "|              |              |                     |              |          0.4964, 0.0000, 0.0000, 0.7175, 0.8486, 0.0000, 0.0000],                                                     |\n",
      "|              |              |                     |              |         [0.0000, 0.8191, 0.0000, 0.0000, 0.0000, 0.0000, 0.0984, 0.1185, 0.0536,                                      |\n",
      "|              |              |                     |              |          0.7392, 0.9216, 0.6686, 0.5697, 0.4186, 0.0000, 0.0000],                                                     |\n",
      "|              |              |                     |              |         [0.5879, 0.0000, 0.0000, 0.0000, 0.0501, 0.0000, 0.2903, 0.0000, 0.2414,                                      |\n",
      "|              |              |                     |              |          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3064, 0.0000],                                                     |\n",
      "|              |              |                     |              |         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.4116, 0.6045, 0.3601,                                      |\n",
      "|              |              |                     |              |          1.1288, 1.1857, 1.1746, 0.9392, 0.9155, 0.0000, 0.5575]],                                                    |\n",
      "|              |              |                     |              |        grad_fn=<ReluBackward0>)}},                                                                                    |\n",
      "|              |              |                     |              |  'mase_op': 'relu',                                                                                                   |\n",
      "|              |              |                     |              |  'mase_type': 'module_related_func',                                                                                  |\n",
      "|              |              |                     |              |  'results': {'data_out_0': {'precision': [32],                                                                        |\n",
      "|              |              |                     |              |                             'shape': [8, 16],                                                                         |\n",
      "|              |              |                     |              |                             'torch_dtype': torch.float32,                                                             |\n",
      "|              |              |                     |              |                             'type': 'float',                                                                          |\n",
      "|              |              |                     |              |                             'value': tensor([[0.0000, 0.9813, 1.4646, 1.5071, 2.2854, 2.6494, 0.8233, 1.1075, 0.7630, |\n",
      "|              |              |                     |              |          0.8599, 0.4797, 0.3356, 0.8626, 1.0501, 1.4632, 2.0016],                                                     |\n",
      "|              |              |                     |              |         [0.0390, 0.3015, 1.7264, 1.9417, 0.6105, 0.2689, 0.0000, 0.0000, 0.0000,                                      |\n",
      "|              |              |                     |              |          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.5584, 0.0761],                                                     |\n",
      "|              |              |                     |              |         [1.3144, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,                                      |\n",
      "|              |              |                     |              |          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0257, 0.0000],                                                     |\n",
      "|              |              |                     |              |         [0.0000, 0.7785, 0.1537, 0.0000, 0.0425, 0.0000, 0.0000, 0.0000, 0.0000,                                      |\n",
      "|              |              |                     |              |          0.5292, 0.9396, 1.2482, 0.5546, 0.7074, 0.0000, 0.2511],                                                     |\n",
      "|              |              |                     |              |         [1.3816, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.7613, 1.7830, 1.6807,                                      |\n",
      "|              |              |                     |              |          0.4964, 0.0000, 0.0000, 0.7175, 0.8486, 0.0000, 0.0000],                                                     |\n",
      "|              |              |                     |              |         [0.0000, 0.8191, 0.0000, 0.0000, 0.0000, 0.0000, 0.0984, 0.1185, 0.0536,                                      |\n",
      "|              |              |                     |              |          0.7392, 0.9216, 0.6686, 0.5697, 0.4186, 0.0000, 0.0000],                                                     |\n",
      "|              |              |                     |              |         [0.5879, 0.0000, 0.0000, 0.0000, 0.0501, 0.0000, 0.2903, 0.0000, 0.2414,                                      |\n",
      "|              |              |                     |              |          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3064, 0.0000],                                                     |\n",
      "|              |              |                     |              |         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.4116, 0.6045, 0.3601,                                      |\n",
      "|              |              |                     |              |          1.1288, 1.1857, 1.1746, 0.9392, 0.9155, 0.0000, 0.5575]],                                                    |\n",
      "|              |              |                     |              |        grad_fn=<ReluBackward0>)}}}                                                                                    |\n",
      "+--------------+--------------+---------------------+--------------+-----------------------------------------------------------------------------------------------------------------------+\n",
      "| seq_blocks_2 | call_module  | module_related_func | linear       | {'args': {'bias': {'from': None,                                                                                      |\n",
      "|              |              |                     |              |                    'precision': [32],                                                                                 |\n",
      "|              |              |                     |              |                    'shape': [5],                                                                                      |\n",
      "|              |              |                     |              |                    'type': 'float',                                                                                   |\n",
      "|              |              |                     |              |                    'value': Parameter containing:                                                                     |\n",
      "|              |              |                     |              | tensor([-0.2150,  0.1994,  0.2189, -0.2763,  0.0228], requires_grad=True)},                                           |\n",
      "|              |              |                     |              |           'data_in_0': {'precision': [32],                                                                            |\n",
      "|              |              |                     |              |                         'shape': [8, 16],                                                                             |\n",
      "|              |              |                     |              |                         'torch_dtype': torch.float32,                                                                 |\n",
      "|              |              |                     |              |                         'type': 'float',                                                                              |\n",
      "|              |              |                     |              |                         'value': tensor([[0.0000, 0.9813, 1.4646, 1.5071, 2.2854, 2.6494, 0.8233, 1.1075, 0.7630,     |\n",
      "|              |              |                     |              |          0.8599, 0.4797, 0.3356, 0.8626, 1.0501, 1.4632, 2.0016],                                                     |\n",
      "|              |              |                     |              |         [0.0390, 0.3015, 1.7264, 1.9417, 0.6105, 0.2689, 0.0000, 0.0000, 0.0000,                                      |\n",
      "|              |              |                     |              |          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.5584, 0.0761],                                                     |\n",
      "|              |              |                     |              |         [1.3144, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,                                      |\n",
      "|              |              |                     |              |          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0257, 0.0000],                                                     |\n",
      "|              |              |                     |              |         [0.0000, 0.7785, 0.1537, 0.0000, 0.0425, 0.0000, 0.0000, 0.0000, 0.0000,                                      |\n",
      "|              |              |                     |              |          0.5292, 0.9396, 1.2482, 0.5546, 0.7074, 0.0000, 0.2511],                                                     |\n",
      "|              |              |                     |              |         [1.3816, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.7613, 1.7830, 1.6807,                                      |\n",
      "|              |              |                     |              |          0.4964, 0.0000, 0.0000, 0.7175, 0.8486, 0.0000, 0.0000],                                                     |\n",
      "|              |              |                     |              |         [0.0000, 0.8191, 0.0000, 0.0000, 0.0000, 0.0000, 0.0984, 0.1185, 0.0536,                                      |\n",
      "|              |              |                     |              |          0.7392, 0.9216, 0.6686, 0.5697, 0.4186, 0.0000, 0.0000],                                                     |\n",
      "|              |              |                     |              |         [0.5879, 0.0000, 0.0000, 0.0000, 0.0501, 0.0000, 0.2903, 0.0000, 0.2414,                                      |\n",
      "|              |              |                     |              |          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3064, 0.0000],                                                     |\n",
      "|              |              |                     |              |         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.4116, 0.6045, 0.3601,                                      |\n",
      "|              |              |                     |              |          1.1288, 1.1857, 1.1746, 0.9392, 0.9155, 0.0000, 0.5575]],                                                    |\n",
      "|              |              |                     |              |        grad_fn=<ReluBackward0>)},                                                                                     |\n",
      "|              |              |                     |              |           'weight': {'from': None,                                                                                    |\n",
      "|              |              |                     |              |                      'precision': [32],                                                                               |\n",
      "|              |              |                     |              |                      'shape': [5, 16],                                                                                |\n",
      "|              |              |                     |              |                      'type': 'float',                                                                                 |\n",
      "|              |              |                     |              |                      'value': Parameter containing:                                                                   |\n",
      "|              |              |                     |              | tensor([[-0.0093,  0.1548, -0.1975, -0.1782, -0.0819,  0.0787,  0.0124,  0.2165,                                      |\n",
      "|              |              |                     |              |          -0.0050,  0.0871, -0.0565, -0.0347, -0.2169, -0.1463, -0.0913,  0.0311],                                     |\n",
      "|              |              |                     |              |         [ 0.1280,  0.1211, -0.1974, -0.1350,  0.0628,  0.1800, -0.0529,  0.1885,                                      |\n",
      "|              |              |                     |              |          -0.0417,  0.0248,  0.2271, -0.2109, -0.1581, -0.0471, -0.1257,  0.1872],                                     |\n",
      "|              |              |                     |              |         [-0.1346, -0.0901, -0.1952, -0.2610, -0.1701,  0.1889,  0.1000,  0.0980,                                      |\n",
      "|              |              |                     |              |           0.0015, -0.1496,  0.0317, -0.2480, -0.2022, -0.1511,  0.1357,  0.1190],                                     |\n",
      "|              |              |                     |              |         [-0.1143, -0.0356,  0.1322,  0.2207,  0.0717,  0.0063,  0.1527, -0.1702,                                      |\n",
      "|              |              |                     |              |           0.0321, -0.2191, -0.1980, -0.1540,  0.0884,  0.0749, -0.1757,  0.0492],                                     |\n",
      "|              |              |                     |              |         [ 0.1078, -0.0064,  0.0389,  0.0873,  0.1841,  0.2691, -0.2117, -0.1111,                                      |\n",
      "|              |              |                     |              |           0.0798,  0.1798,  0.1892,  0.1932,  0.0228, -0.2421,  0.0520, -0.1312]],                                    |\n",
      "|              |              |                     |              |        requires_grad=True)}},                                                                                         |\n",
      "|              |              |                     |              |  'mase_op': 'linear',                                                                                                 |\n",
      "|              |              |                     |              |  'mase_type': 'module_related_func',                                                                                  |\n",
      "|              |              |                     |              |  'results': {'data_out_0': {'precision': [32],                                                                        |\n",
      "|              |              |                     |              |                             'shape': [8, 5],                                                                          |\n",
      "|              |              |                     |              |                             'torch_dtype': torch.float32,                                                             |\n",
      "|              |              |                     |              |                             'type': 'float',                                                                          |\n",
      "|              |              |                     |              |                             'value': tensor([[0.0000, 0.6441, 0.0000, 0.0185, 0.9912],                                |\n",
      "|              |              |                     |              |         [0.0000, 0.0000, 0.0000, 0.1407, 0.5174],                                                                     |\n",
      "|              |              |                     |              |         [0.0000, 0.3643, 0.0455, 0.0000, 0.1659],                                                                     |\n",
      "|              |              |                     |              |         [0.0000, 0.1553, 0.0000, 0.0000, 0.3541],                                                                     |\n",
      "|              |              |                     |              |         [0.0000, 0.4080, 0.0389, 0.0000, 0.0000],                                                                     |\n",
      "|              |              |                     |              |         [0.0000, 0.2903, 0.0000, 0.0000, 0.3359],                                                                     |\n",
      "|              |              |                     |              |         [0.0000, 0.2138, 0.2022, 0.0000, 0.0691],                                                                     |\n",
      "|              |              |                     |              |         [0.0000, 0.2389, 0.0000, 0.0000, 0.2781]], grad_fn=<ReluBackward0>)}}}                                        |\n",
      "+--------------+--------------+---------------------+--------------+-----------------------------------------------------------------------------------------------------------------------+\n",
      "| seq_blocks_3 | call_module  | module_related_func | relu         | {'args': {'data_in_0': {'precision': [32],                                                                            |\n",
      "|              |              |                     |              |                         'shape': [8, 5],                                                                              |\n",
      "|              |              |                     |              |                         'torch_dtype': torch.float32,                                                                 |\n",
      "|              |              |                     |              |                         'type': 'float',                                                                              |\n",
      "|              |              |                     |              |                         'value': tensor([[0.0000, 0.6441, 0.0000, 0.0185, 0.9912],                                    |\n",
      "|              |              |                     |              |         [0.0000, 0.0000, 0.0000, 0.1407, 0.5174],                                                                     |\n",
      "|              |              |                     |              |         [0.0000, 0.3643, 0.0455, 0.0000, 0.1659],                                                                     |\n",
      "|              |              |                     |              |         [0.0000, 0.1553, 0.0000, 0.0000, 0.3541],                                                                     |\n",
      "|              |              |                     |              |         [0.0000, 0.4080, 0.0389, 0.0000, 0.0000],                                                                     |\n",
      "|              |              |                     |              |         [0.0000, 0.2903, 0.0000, 0.0000, 0.3359],                                                                     |\n",
      "|              |              |                     |              |         [0.0000, 0.2138, 0.2022, 0.0000, 0.0691],                                                                     |\n",
      "|              |              |                     |              |         [0.0000, 0.2389, 0.0000, 0.0000, 0.2781]], grad_fn=<ReluBackward0>)}},                                        |\n",
      "|              |              |                     |              |  'mase_op': 'relu',                                                                                                   |\n",
      "|              |              |                     |              |  'mase_type': 'module_related_func',                                                                                  |\n",
      "|              |              |                     |              |  'results': {'data_out_0': {'precision': [32],                                                                        |\n",
      "|              |              |                     |              |                             'shape': [8, 5],                                                                          |\n",
      "|              |              |                     |              |                             'torch_dtype': torch.float32,                                                             |\n",
      "|              |              |                     |              |                             'type': 'float',                                                                          |\n",
      "|              |              |                     |              |                             'value': tensor([[0.0000, 0.6441, 0.0000, 0.0185, 0.9912],                                |\n",
      "|              |              |                     |              |         [0.0000, 0.0000, 0.0000, 0.1407, 0.5174],                                                                     |\n",
      "|              |              |                     |              |         [0.0000, 0.3643, 0.0455, 0.0000, 0.1659],                                                                     |\n",
      "|              |              |                     |              |         [0.0000, 0.1553, 0.0000, 0.0000, 0.3541],                                                                     |\n",
      "|              |              |                     |              |         [0.0000, 0.4080, 0.0389, 0.0000, 0.0000],                                                                     |\n",
      "|              |              |                     |              |         [0.0000, 0.2903, 0.0000, 0.0000, 0.3359],                                                                     |\n",
      "|              |              |                     |              |         [0.0000, 0.2138, 0.2022, 0.0000, 0.0691],                                                                     |\n",
      "|              |              |                     |              |         [0.0000, 0.2389, 0.0000, 0.0000, 0.2781]], grad_fn=<ReluBackward0>)}}}                                        |\n",
      "+--------------+--------------+---------------------+--------------+-----------------------------------------------------------------------------------------------------------------------+\n",
      "| output       | output       | output              | output       | {'args': {},                                                                                                          |\n",
      "|              |              |                     |              |  'mase_op': 'output',                                                                                                 |\n",
      "|              |              |                     |              |  'mase_type': 'output',                                                                                               |\n",
      "|              |              |                     |              |  'results': {'data_out_0': {'precision': [32],                                                                        |\n",
      "|              |              |                     |              |                             'shape': [8, 5],                                                                          |\n",
      "|              |              |                     |              |                             'torch_dtype': torch.float32,                                                             |\n",
      "|              |              |                     |              |                             'type': 'float',                                                                          |\n",
      "|              |              |                     |              |                             'value': tensor([[0.0000, 0.6441, 0.0000, 0.0185, 0.9912],                                |\n",
      "|              |              |                     |              |         [0.0000, 0.0000, 0.0000, 0.1407, 0.5174],                                                                     |\n",
      "|              |              |                     |              |         [0.0000, 0.3643, 0.0455, 0.0000, 0.1659],                                                                     |\n",
      "|              |              |                     |              |         [0.0000, 0.1553, 0.0000, 0.0000, 0.3541],                                                                     |\n",
      "|              |              |                     |              |         [0.0000, 0.4080, 0.0389, 0.0000, 0.0000],                                                                     |\n",
      "|              |              |                     |              |         [0.0000, 0.2903, 0.0000, 0.0000, 0.3359],                                                                     |\n",
      "|              |              |                     |              |         [0.0000, 0.2138, 0.2022, 0.0000, 0.0691],                                                                     |\n",
      "|              |              |                     |              |         [0.0000, 0.2389, 0.0000, 0.0000, 0.2781]], grad_fn=<ReluBackward0>)}}}                                        |\n",
      "+--------------+--------------+---------------------+--------------+-----------------------------------------------------------------------------------------------------------------------+\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# we shift from software to common, which offers more information\n",
    "\n",
    "mg, _ = report_node_meta_param_analysis_pass(mg, {\"which\": (\"common\",)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformation pass for JSC-Tiny\n",
    "\n",
    "pass_args = {\n",
    "\"by\": \"type\",\n",
    "\"default\": {\"config\": {\"name\": None}},\n",
    "\n",
    "\"linear\": {  \n",
    "        \"config\": {\n",
    "            \"name\": \"integer\",\n",
    "            # data\n",
    "            \"data_in_width\": 8,\n",
    "            \"data_in_frac_width\": 4,\n",
    "            # weight\n",
    "            \"weight_width\": 8,\n",
    "            \"weight_frac_width\": 4,\n",
    "            # bias\n",
    "            \"bias_width\": 8,\n",
    "            \"bias_frac_width\": 4,\n",
    "        }\n",
    "},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformation pass for JSC-rs1923\n",
    "\n",
    "pass_args = {\n",
    "\"by\": \"type\",\n",
    "\"default\": {\"config\": {\"name\": None}},\n",
    "\n",
    "\"conv1d\": {\n",
    "    \"config\": {\n",
    "        \"name\": \"integer\",\n",
    "        # data\n",
    "        \"data_in_width\": 8,\n",
    "        \"data_in_frac_width\": 4,\n",
    "        # weight\n",
    "        \"weight_width\": 8,\n",
    "        \"weight_frac_width\": 4,\n",
    "        # bias\n",
    "        \"bias_width\": 8,\n",
    "        \"bias_frac_width\": 4,\n",
    "    }\n",
    "},\n",
    "\n",
    "\"linear\": {  \n",
    "        \"config\": {\n",
    "            \"name\": \"integer\",\n",
    "            # data\n",
    "            \"data_in_width\": 8,\n",
    "            \"data_in_frac_width\": 4,\n",
    "            # weight\n",
    "            \"weight_width\": 8,\n",
    "            \"weight_frac_width\": 4,\n",
    "            # bias\n",
    "            \"bias_width\": 8,\n",
    "            \"bias_frac_width\": 4,\n",
    "        }\n",
    "},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36mDEBUG   \u001b[0m \u001b[34mgraph():\n",
      "    %x : [num_users=1] = placeholder[target=x]\n",
      "    %conv1 : [num_users=1] = call_module[target=conv1](args = (%x,), kwargs = {})\n",
      "    %relu : [num_users=1] = call_function[target=torch.nn.functional.relu](args = (%conv1,), kwargs = {inplace: False})\n",
      "    %conv2 : [num_users=1] = call_module[target=conv2](args = (%relu,), kwargs = {})\n",
      "    %relu_1 : [num_users=2] = call_function[target=torch.nn.functional.relu](args = (%conv2,), kwargs = {inplace: False})\n",
      "    %block_conv1 : [num_users=1] = call_module[target=block.conv1](args = (%relu_1,), kwargs = {})\n",
      "    %relu_2 : [num_users=1] = call_function[target=torch.nn.functional.relu](args = (%block_conv1,), kwargs = {inplace: False})\n",
      "    %block_conv2 : [num_users=1] = call_module[target=block.conv2](args = (%relu_2,), kwargs = {})\n",
      "    %add : [num_users=1] = call_function[target=operator.add](args = (%block_conv2, %relu_1), kwargs = {})\n",
      "    %relu_3 : [num_users=1] = call_function[target=torch.nn.functional.relu](args = (%add,), kwargs = {inplace: False})\n",
      "    %view : [num_users=1] = call_method[target=view](args = (%relu_3, -1, 256), kwargs = {})\n",
      "    %fc : [num_users=1] = call_module[target=fc](args = (%view,), kwargs = {})\n",
      "    %relu_4 : [num_users=1] = call_function[target=torch.nn.functional.relu](args = (%fc,), kwargs = {inplace: False})\n",
      "    return relu_4\u001b[0m\n",
      "\u001b[36mDEBUG   \u001b[0m \u001b[34mgraph():\n",
      "    %x : [num_users=1] = placeholder[target=x]\n",
      "    %conv1 : [num_users=1] = call_module[target=conv1](args = (%x,), kwargs = {})\n",
      "    %relu : [num_users=1] = call_function[target=torch.nn.functional.relu](args = (%conv1,), kwargs = {inplace: False})\n",
      "    %conv2 : [num_users=1] = call_module[target=conv2](args = (%relu,), kwargs = {})\n",
      "    %relu_1 : [num_users=2] = call_function[target=torch.nn.functional.relu](args = (%conv2,), kwargs = {inplace: False})\n",
      "    %block_conv1 : [num_users=1] = call_module[target=block.conv1](args = (%relu_1,), kwargs = {})\n",
      "    %relu_2 : [num_users=1] = call_function[target=torch.nn.functional.relu](args = (%block_conv1,), kwargs = {inplace: False})\n",
      "    %block_conv2 : [num_users=1] = call_module[target=block.conv2](args = (%relu_2,), kwargs = {})\n",
      "    %add : [num_users=1] = call_function[target=operator.add](args = (%block_conv2, %relu_1), kwargs = {})\n",
      "    %relu_3 : [num_users=1] = call_function[target=torch.nn.functional.relu](args = (%add,), kwargs = {inplace: False})\n",
      "    %view : [num_users=1] = call_method[target=view](args = (%relu_3, -1, 256), kwargs = {})\n",
      "    %fc : [num_users=1] = call_module[target=fc](args = (%view,), kwargs = {})\n",
      "    %relu_4 : [num_users=1] = call_function[target=torch.nn.functional.relu](args = (%fc,), kwargs = {inplace: False})\n",
      "    return relu_4\u001b[0m\n",
      "\u001b[36mDEBUG   \u001b[0m \u001b[34mCompare nodes:\u001b[0m\n",
      "\u001b[36mDEBUG   \u001b[0m \u001b[34m\n",
      "| Ori name    | New name    | MASE_TYPE           | Mase_OP     | Original type   | Quantized type   | Changed   |\n",
      "|-------------+-------------+---------------------+-------------+-----------------+------------------+-----------|\n",
      "| x           | x           | placeholder         | placeholder | x               | x                | False     |\n",
      "| conv1       | conv1       | module_related_func | conv1d      | Conv1d          | Conv1dInteger    | True      |\n",
      "| relu        | relu        | module_related_func | relu        | relu            | relu             | False     |\n",
      "| conv2       | conv2       | module_related_func | conv1d      | Conv1d          | Conv1dInteger    | True      |\n",
      "| relu_1      | relu_1      | module_related_func | relu        | relu            | relu             | False     |\n",
      "| block_conv1 | block_conv1 | module_related_func | conv1d      | Conv1d          | Conv1dInteger    | True      |\n",
      "| relu_2      | relu_2      | module_related_func | relu        | relu            | relu             | False     |\n",
      "| block_conv2 | block_conv2 | module_related_func | conv1d      | Conv1d          | Conv1dInteger    | True      |\n",
      "| add         | add         | builtin_func        | add         | add             | add              | False     |\n",
      "| relu_3      | relu_3      | module_related_func | relu        | relu            | relu             | False     |\n",
      "| view        | view        | implicit_func       | view        | view            | view             | False     |\n",
      "| fc          | fc          | module_related_func | linear      | Linear          | LinearInteger    | True      |\n",
      "| relu_4      | relu_4      | module_related_func | relu        | relu            | relu             | False     |\n",
      "| output      | output      | output              | output      | output          | output           | False     |\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mQuantized graph histogram:\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
      "| Original type   | OP          |   Total |   Changed |   Unchanged |\n",
      "|-----------------+-------------+---------+-----------+-------------|\n",
      "| Conv1d          | conv1d      |       4 |         4 |           0 |\n",
      "| Linear          | linear      |       1 |         1 |           0 |\n",
      "| add             | add         |       1 |         0 |           1 |\n",
      "| output          | output      |       1 |         0 |           1 |\n",
      "| relu            | relu        |       5 |         0 |           5 |\n",
      "| view            | view        |       1 |         0 |           1 |\n",
      "| x               | placeholder |       1 |         0 |           1 |\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from chop.passes.graph.transforms import (\n",
    "    quantize_transform_pass,\n",
    "    summarize_quantization_analysis_pass,\n",
    ")\n",
    "from chop.ir.graph.mase_graph import MaseGraph\n",
    "\n",
    "\n",
    "ori_mg = MaseGraph(model=own_model)\n",
    "ori_mg, _ = init_metadata_analysis_pass(ori_mg, None)\n",
    "ori_mg, _ = add_common_metadata_analysis_pass(ori_mg, {\"dummy_in\": dummy_in})\n",
    "ori_mg, _ = add_software_metadata_analysis_pass(ori_mg, None)\n",
    "\n",
    "mg = MaseGraph(model=own_model)\n",
    "mg, _ = init_metadata_analysis_pass(mg, None)\n",
    "mg, _ = add_common_metadata_analysis_pass(mg, {\"dummy_in\": dummy_in})\n",
    "mg, _ = add_software_metadata_analysis_pass(mg, None)\n",
    "mg, _ = quantize_transform_pass(mg, pass_args)\n",
    "\n",
    "summarize_quantization_analysis_pass(ori_mg, mg, save_dir=\"quantize_summary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 1,2,3 have no code, they are analysis and have been on the report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 4: traverse both mg and ori_mg\n",
    "\n",
    "from chop.passes.graph.utils import get_mase_op, get_mase_type, get_node_actual_target\n",
    "\n",
    "def get_type_str(node):\n",
    "    if node.op == \"call_module\":\n",
    "        return type(get_node_actual_target(node)).__name__\n",
    "    else:\n",
    "        return node.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tabulate import tabulate\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "headers = [\n",
    "    \"Ori name\",\n",
    "    \"New name\",\n",
    "    \"Node_OP\",\n",
    "    \"MASE_TYPE\",\n",
    "    \"Mase_OP\",\n",
    "    \"Original type\",\n",
    "    \"Quantized type\",\n",
    "    \"Changed\",\n",
    "]\n",
    "\n",
    "rows=[]\n",
    "for ori_n, n in zip(ori_mg.fx_graph.nodes, mg.fx_graph.nodes):\n",
    "    rows.append(\n",
    "            [\n",
    "                ori_n.name,\n",
    "                n.name,\n",
    "                n.op,\n",
    "                get_mase_type(n),\n",
    "                get_mase_op(n),\n",
    "                get_type_str(ori_n),\n",
    "                get_type_str(n),\n",
    "                type(get_node_actual_target(n)) != type(get_node_actual_target(ori_n)),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "logger.debug(\"Compare nodes:\")\n",
    "logger.debug(\"\\n\" + tabulate(rows, headers=headers, tablefmt=\"orgtbl\"))\n",
    "\n",
    "df = pd.DataFrame(rows, columns=headers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ori name</th>\n",
       "      <th>New name</th>\n",
       "      <th>Node_OP</th>\n",
       "      <th>MASE_TYPE</th>\n",
       "      <th>Mase_OP</th>\n",
       "      <th>Original type</th>\n",
       "      <th>Quantized type</th>\n",
       "      <th>Changed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>placeholder</td>\n",
       "      <td>placeholder</td>\n",
       "      <td>placeholder</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>seq_blocks_0</td>\n",
       "      <td>seq_blocks_0</td>\n",
       "      <td>call_module</td>\n",
       "      <td>module</td>\n",
       "      <td>batch_norm1d</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>BatchNorm1d</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>seq_blocks_1</td>\n",
       "      <td>seq_blocks_1</td>\n",
       "      <td>call_module</td>\n",
       "      <td>module_related_func</td>\n",
       "      <td>relu</td>\n",
       "      <td>ReLU</td>\n",
       "      <td>ReLU</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>seq_blocks_2</td>\n",
       "      <td>seq_blocks_2</td>\n",
       "      <td>call_module</td>\n",
       "      <td>module_related_func</td>\n",
       "      <td>linear</td>\n",
       "      <td>Linear</td>\n",
       "      <td>LinearInteger</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>seq_blocks_3</td>\n",
       "      <td>seq_blocks_3</td>\n",
       "      <td>call_module</td>\n",
       "      <td>module_related_func</td>\n",
       "      <td>relu</td>\n",
       "      <td>ReLU</td>\n",
       "      <td>ReLU</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>output</td>\n",
       "      <td>output</td>\n",
       "      <td>output</td>\n",
       "      <td>output</td>\n",
       "      <td>output</td>\n",
       "      <td>output</td>\n",
       "      <td>output</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Ori name      New name      Node_OP            MASE_TYPE       Mase_OP  \\\n",
       "0             x             x  placeholder          placeholder   placeholder   \n",
       "1  seq_blocks_0  seq_blocks_0  call_module               module  batch_norm1d   \n",
       "2  seq_blocks_1  seq_blocks_1  call_module  module_related_func          relu   \n",
       "3  seq_blocks_2  seq_blocks_2  call_module  module_related_func        linear   \n",
       "4  seq_blocks_3  seq_blocks_3  call_module  module_related_func          relu   \n",
       "5        output        output       output               output        output   \n",
       "\n",
       "  Original type Quantized type  Changed  \n",
       "0             x              x    False  \n",
       "1   BatchNorm1d    BatchNorm1d    False  \n",
       "2          ReLU           ReLU    False  \n",
       "3        Linear  LinearInteger     True  \n",
       "4          ReLU           ReLU    False  \n",
       "5        output         output    False  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv(\"/mnt/d/imperial/thanks.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.0752, -0.0539,  0.0252,  ...,  0.0037, -0.1073,  0.0500],\n",
      "        [-0.0059,  0.0253,  0.0007,  ...,  0.0487,  0.0635,  0.0750],\n",
      "        [ 0.0975,  0.0499, -0.0471,  ...,  0.0235,  0.0838,  0.1013],\n",
      "        [ 0.0061,  0.0469, -0.0265,  ...,  0.0446,  0.0610, -0.0798],\n",
      "        [ 0.0059, -0.0739,  0.0598,  ...,  0.0549, -0.0014, -0.0054]],\n",
      "       requires_grad=True)\n",
      "tensor([[ 0.0625, -0.0625,  0.0000,  ...,  0.0000, -0.1250,  0.0625],\n",
      "        [-0.0000,  0.0000,  0.0000,  ...,  0.0625,  0.0625,  0.0625],\n",
      "        [ 0.1250,  0.0625, -0.0625,  ...,  0.0000,  0.0625,  0.1250],\n",
      "        [ 0.0000,  0.0625, -0.0000,  ...,  0.0625,  0.0625, -0.0625],\n",
      "        [ 0.0000, -0.0625,  0.0625,  ...,  0.0625, -0.0000, -0.0000]])\n"
     ]
    }
   ],
   "source": [
    "# 6: Write code to show and verify that the weights of these layers are indeed quantised.\n",
    "\n",
    "from machop.chop.passes.graph.utils import get_node_actual_target\n",
    "from machop.chop.passes.graph.utils import get_mase_op\n",
    "from machop.chop.passes.graph.utils import get_mase_type\n",
    "import torch\n",
    "\n",
    "for ori_n, n in zip(ori_mg.fx_graph.nodes, mg.fx_graph.nodes):\n",
    "    if isinstance(get_node_actual_target(ori_n), torch.nn.modules.Linear): # Linear\n",
    "        print(ori_n.meta[\"mase\"].module.weight)\n",
    "        print(n.meta['mase'].module.w_quantizer(n.meta['mase'].module.weight).detach())\n",
    "\n",
    "# We could see clearly that these weights have been quantized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is quantization at conv1, mase_op: conv1d\n",
      "original module: <class 'torch.nn.modules.conv.Conv1d'>, new_module: <class 'chop.passes.graph.transforms.quantize.quantized_modules.conv1d.Conv1dInteger'>\n",
      "original weight: Parameter containing:\n",
      "tensor([[[ 0.0139,  0.4526, -0.4716]],\n",
      "\n",
      "        [[-0.5095, -0.3401,  0.0407]],\n",
      "\n",
      "        [[-0.0469,  0.5830, -0.0303]],\n",
      "\n",
      "        [[ 0.2598, -0.2470, -0.2621]],\n",
      "\n",
      "        [[-0.5880, -0.5082, -0.3283]],\n",
      "\n",
      "        [[-0.0397,  0.3216,  0.4720]],\n",
      "\n",
      "        [[-0.4444, -0.2566,  0.3409]],\n",
      "\n",
      "        [[ 0.5061, -0.0790,  0.5585]]], requires_grad=True)\n",
      "quantized weight: tensor([[[ 0.0000,  0.4375, -0.5000]],\n",
      "\n",
      "        [[-0.5000, -0.3125,  0.0625]],\n",
      "\n",
      "        [[-0.0625,  0.5625, -0.0000]],\n",
      "\n",
      "        [[ 0.2500, -0.2500, -0.2500]],\n",
      "\n",
      "        [[-0.5625, -0.5000, -0.3125]],\n",
      "\n",
      "        [[-0.0625,  0.3125,  0.5000]],\n",
      "\n",
      "        [[-0.4375, -0.2500,  0.3125]],\n",
      "\n",
      "        [[ 0.5000, -0.0625,  0.5625]]], grad_fn=<IntegerQuantizeBackward>)\n",
      "original bias: Parameter containing:\n",
      "tensor([-0.0137,  0.1588,  0.6167, -0.4398, -0.2613, -0.0681, -0.1072,  0.5210],\n",
      "       requires_grad=True)\n",
      "quantized bias: tensor([-0.3750, -0.4375, -0.5625, -0.0625, -0.2500,  0.3125,  0.2500, -0.0625],\n",
      "       grad_fn=<IntegerQuantizeBackward>)\n",
      "There is quantization at conv2, mase_op: conv1d\n",
      "original module: <class 'torch.nn.modules.conv.Conv1d'>, new_module: <class 'chop.passes.graph.transforms.quantize.quantized_modules.conv1d.Conv1dInteger'>\n",
      "original weight: Parameter containing:\n",
      "tensor([[[-0.0176, -0.0115, -0.0202],\n",
      "         [-0.1420, -0.0769,  0.2752],\n",
      "         [ 0.1411,  0.2040,  0.1229],\n",
      "         [-0.1165,  0.0246, -0.2762],\n",
      "         [-0.1698, -0.0735,  0.2064],\n",
      "         [ 0.1822, -0.0023, -0.0182],\n",
      "         [ 0.2525,  0.2480,  0.1563],\n",
      "         [ 0.0693,  0.2001, -0.1147]],\n",
      "\n",
      "        [[-0.0559, -0.1045, -0.0302],\n",
      "         [-0.0575,  0.1323,  0.0751],\n",
      "         [-0.1086,  0.1235,  0.1803],\n",
      "         [-0.0173, -0.0085,  0.0454],\n",
      "         [ 0.1574,  0.2087, -0.1545],\n",
      "         [-0.1657,  0.0639,  0.1824],\n",
      "         [ 0.2229,  0.2410,  0.0094],\n",
      "         [-0.1549,  0.0159, -0.1347]],\n",
      "\n",
      "        [[-0.0958,  0.2219,  0.2705],\n",
      "         [-0.1425,  0.1324,  0.0298],\n",
      "         [-0.0173, -0.0550,  0.1472],\n",
      "         [-0.0670,  0.0921,  0.0161],\n",
      "         [ 0.1920,  0.1329, -0.2205],\n",
      "         [-0.1003,  0.1631,  0.1093],\n",
      "         [-0.0578,  0.0212,  0.2993],\n",
      "         [ 0.1728, -0.0595, -0.0138]],\n",
      "\n",
      "        [[-0.2163,  0.0220, -0.2445],\n",
      "         [-0.1090,  0.0991,  0.1501],\n",
      "         [-0.0671,  0.1572, -0.1516],\n",
      "         [ 0.2164,  0.0337, -0.1794],\n",
      "         [-0.0320,  0.1076,  0.1274],\n",
      "         [ 0.1393,  0.1653,  0.0086],\n",
      "         [-0.0989,  0.1300, -0.1706],\n",
      "         [-0.0927, -0.1023, -0.1990]],\n",
      "\n",
      "        [[-0.0394, -0.1905,  0.0315],\n",
      "         [ 0.0843, -0.0606,  0.0548],\n",
      "         [ 0.2384,  0.0283,  0.0199],\n",
      "         [ 0.0936,  0.1441,  0.0800],\n",
      "         [ 0.2235,  0.1892,  0.2605],\n",
      "         [-0.1273, -0.3120, -0.2465],\n",
      "         [ 0.0886,  0.0070, -0.0942],\n",
      "         [-0.0708, -0.1338, -0.1401]],\n",
      "\n",
      "        [[-0.0462,  0.1452,  0.1939],\n",
      "         [-0.1401,  0.2249, -0.0744],\n",
      "         [-0.0017, -0.1243,  0.0160],\n",
      "         [ 0.0829, -0.2578, -0.1421],\n",
      "         [ 0.0361,  0.1196, -0.0278],\n",
      "         [ 0.1072, -0.2210,  0.0643],\n",
      "         [ 0.1919,  0.0097,  0.2623],\n",
      "         [ 0.0665, -0.2120,  0.2048]],\n",
      "\n",
      "        [[-0.0437, -0.0353,  0.2808],\n",
      "         [-0.1963,  0.0713, -0.0717],\n",
      "         [ 0.1677,  0.1188,  0.1481],\n",
      "         [ 0.1602, -0.1589, -0.1622],\n",
      "         [-0.2412,  0.1786,  0.1576],\n",
      "         [ 0.1890, -0.1267,  0.0154],\n",
      "         [-0.1425, -0.0413, -0.0836],\n",
      "         [ 0.1193, -0.0819,  0.0326]],\n",
      "\n",
      "        [[ 0.0243,  0.2643, -0.1253],\n",
      "         [-0.1482, -0.1739,  0.0619],\n",
      "         [-0.0381,  0.2920,  0.1390],\n",
      "         [-0.0321, -0.1087,  0.0123],\n",
      "         [-0.0597, -0.1235, -0.0993],\n",
      "         [ 0.0499, -0.1403, -0.1172],\n",
      "         [ 0.2659, -0.1345, -0.1003],\n",
      "         [ 0.2676,  0.1108,  0.0633]],\n",
      "\n",
      "        [[-0.1232,  0.2130, -0.0600],\n",
      "         [-0.0036, -0.0367, -0.0076],\n",
      "         [ 0.0629,  0.2675,  0.1326],\n",
      "         [ 0.2284,  0.0674, -0.1148],\n",
      "         [ 0.1077, -0.1695, -0.1120],\n",
      "         [ 0.0450,  0.0858,  0.1637],\n",
      "         [ 0.0074,  0.0600,  0.1114],\n",
      "         [-0.1630,  0.2094, -0.1264]],\n",
      "\n",
      "        [[-0.0147, -0.0232, -0.1413],\n",
      "         [ 0.1087,  0.2303,  0.0051],\n",
      "         [-0.0966, -0.1145, -0.1615],\n",
      "         [ 0.1623, -0.1138, -0.2302],\n",
      "         [-0.0449,  0.1902,  0.1586],\n",
      "         [ 0.1366,  0.0245, -0.0305],\n",
      "         [ 0.0110,  0.0967,  0.2095],\n",
      "         [-0.0012, -0.1112, -0.0275]],\n",
      "\n",
      "        [[-0.1877,  0.0808, -0.0190],\n",
      "         [-0.1668,  0.2669, -0.0839],\n",
      "         [ 0.0026,  0.1238,  0.0659],\n",
      "         [-0.1860, -0.1736,  0.1223],\n",
      "         [ 0.0450,  0.1778, -0.0420],\n",
      "         [ 0.1767,  0.0659, -0.0292],\n",
      "         [-0.1526,  0.1608,  0.1058],\n",
      "         [ 0.0232, -0.0127, -0.2252]],\n",
      "\n",
      "        [[ 0.2653, -0.1168,  0.1866],\n",
      "         [-0.0256, -0.0374,  0.1189],\n",
      "         [-0.0995,  0.0581,  0.1358],\n",
      "         [-0.1238,  0.0212,  0.1047],\n",
      "         [ 0.0503, -0.1254, -0.1672],\n",
      "         [-0.0701,  0.1510, -0.0034],\n",
      "         [ 0.1459,  0.2493, -0.0349],\n",
      "         [-0.0180,  0.1445,  0.0013]],\n",
      "\n",
      "        [[ 0.0337,  0.0333, -0.1354],\n",
      "         [ 0.0179,  0.1513,  0.1998],\n",
      "         [ 0.1373,  0.0534,  0.1682],\n",
      "         [-0.1973, -0.2689, -0.2947],\n",
      "         [ 0.1843,  0.0941, -0.1523],\n",
      "         [ 0.1417,  0.2374,  0.2707],\n",
      "         [ 0.2354,  0.2251, -0.0027],\n",
      "         [-0.0615,  0.2034,  0.1493]],\n",
      "\n",
      "        [[-0.0730,  0.2924,  0.2029],\n",
      "         [ 0.1389, -0.2069,  0.0084],\n",
      "         [-0.0040,  0.2921,  0.0684],\n",
      "         [ 0.0271, -0.0431,  0.1618],\n",
      "         [-0.1139, -0.0015, -0.2067],\n",
      "         [ 0.0654, -0.1317, -0.2512],\n",
      "         [-0.0209,  0.1342,  0.0328],\n",
      "         [ 0.2695,  0.2284, -0.1491]],\n",
      "\n",
      "        [[-0.1397,  0.0321, -0.0974],\n",
      "         [ 0.2210, -0.0942, -0.1170],\n",
      "         [-0.1967, -0.0378,  0.2305],\n",
      "         [ 0.1593,  0.0766,  0.0961],\n",
      "         [ 0.1627, -0.0940,  0.0196],\n",
      "         [ 0.2585,  0.1972,  0.3028],\n",
      "         [ 0.2151,  0.2090, -0.0498],\n",
      "         [ 0.1508,  0.0685, -0.0183]],\n",
      "\n",
      "        [[-0.1094, -0.0256, -0.2485],\n",
      "         [ 0.2074,  0.2411,  0.0623],\n",
      "         [-0.1136,  0.1819,  0.1404],\n",
      "         [ 0.0602, -0.0208,  0.3045],\n",
      "         [ 0.1211, -0.0986,  0.2403],\n",
      "         [ 0.1286, -0.1072,  0.1465],\n",
      "         [-0.1139, -0.0073,  0.2265],\n",
      "         [ 0.0124, -0.1773, -0.0333]]], requires_grad=True)\n",
      "quantized weight: tensor([[[-0.0000, -0.0000, -0.0000],\n",
      "         [-0.1250, -0.0625,  0.2500],\n",
      "         [ 0.1250,  0.1875,  0.1250],\n",
      "         [-0.1250,  0.0000, -0.2500],\n",
      "         [-0.1875, -0.0625,  0.1875],\n",
      "         [ 0.1875, -0.0000, -0.0000],\n",
      "         [ 0.2500,  0.2500,  0.1875],\n",
      "         [ 0.0625,  0.1875, -0.1250]],\n",
      "\n",
      "        [[-0.0625, -0.1250, -0.0000],\n",
      "         [-0.0625,  0.1250,  0.0625],\n",
      "         [-0.1250,  0.1250,  0.1875],\n",
      "         [-0.0000, -0.0000,  0.0625],\n",
      "         [ 0.1875,  0.1875, -0.1250],\n",
      "         [-0.1875,  0.0625,  0.1875],\n",
      "         [ 0.2500,  0.2500,  0.0000],\n",
      "         [-0.1250,  0.0000, -0.1250]],\n",
      "\n",
      "        [[-0.1250,  0.2500,  0.2500],\n",
      "         [-0.1250,  0.1250,  0.0000],\n",
      "         [-0.0000, -0.0625,  0.1250],\n",
      "         [-0.0625,  0.0625,  0.0000],\n",
      "         [ 0.1875,  0.1250, -0.2500],\n",
      "         [-0.1250,  0.1875,  0.1250],\n",
      "         [-0.0625,  0.0000,  0.3125],\n",
      "         [ 0.1875, -0.0625, -0.0000]],\n",
      "\n",
      "        [[-0.1875,  0.0000, -0.2500],\n",
      "         [-0.1250,  0.1250,  0.1250],\n",
      "         [-0.0625,  0.1875, -0.1250],\n",
      "         [ 0.1875,  0.0625, -0.1875],\n",
      "         [-0.0625,  0.1250,  0.1250],\n",
      "         [ 0.1250,  0.1875,  0.0000],\n",
      "         [-0.1250,  0.1250, -0.1875],\n",
      "         [-0.0625, -0.1250, -0.1875]],\n",
      "\n",
      "        [[-0.0625, -0.1875,  0.0625],\n",
      "         [ 0.0625, -0.0625,  0.0625],\n",
      "         [ 0.2500,  0.0000,  0.0000],\n",
      "         [ 0.0625,  0.1250,  0.0625],\n",
      "         [ 0.2500,  0.1875,  0.2500],\n",
      "         [-0.1250, -0.3125, -0.2500],\n",
      "         [ 0.0625,  0.0000, -0.1250],\n",
      "         [-0.0625, -0.1250, -0.1250]],\n",
      "\n",
      "        [[-0.0625,  0.1250,  0.1875],\n",
      "         [-0.1250,  0.2500, -0.0625],\n",
      "         [-0.0000, -0.1250,  0.0000],\n",
      "         [ 0.0625, -0.2500, -0.1250],\n",
      "         [ 0.0625,  0.1250, -0.0000],\n",
      "         [ 0.1250, -0.2500,  0.0625],\n",
      "         [ 0.1875,  0.0000,  0.2500],\n",
      "         [ 0.0625, -0.1875,  0.1875]],\n",
      "\n",
      "        [[-0.0625, -0.0625,  0.2500],\n",
      "         [-0.1875,  0.0625, -0.0625],\n",
      "         [ 0.1875,  0.1250,  0.1250],\n",
      "         [ 0.1875, -0.1875, -0.1875],\n",
      "         [-0.2500,  0.1875,  0.1875],\n",
      "         [ 0.1875, -0.1250,  0.0000],\n",
      "         [-0.1250, -0.0625, -0.0625],\n",
      "         [ 0.1250, -0.0625,  0.0625]],\n",
      "\n",
      "        [[ 0.0000,  0.2500, -0.1250],\n",
      "         [-0.1250, -0.1875,  0.0625],\n",
      "         [-0.0625,  0.3125,  0.1250],\n",
      "         [-0.0625, -0.1250,  0.0000],\n",
      "         [-0.0625, -0.1250, -0.1250],\n",
      "         [ 0.0625, -0.1250, -0.1250],\n",
      "         [ 0.2500, -0.1250, -0.1250],\n",
      "         [ 0.2500,  0.1250,  0.0625]],\n",
      "\n",
      "        [[-0.1250,  0.1875, -0.0625],\n",
      "         [-0.0000, -0.0625, -0.0000],\n",
      "         [ 0.0625,  0.2500,  0.1250],\n",
      "         [ 0.2500,  0.0625, -0.1250],\n",
      "         [ 0.1250, -0.1875, -0.1250],\n",
      "         [ 0.0625,  0.0625,  0.1875],\n",
      "         [ 0.0000,  0.0625,  0.1250],\n",
      "         [-0.1875,  0.1875, -0.1250]],\n",
      "\n",
      "        [[-0.0000, -0.0000, -0.1250],\n",
      "         [ 0.1250,  0.2500,  0.0000],\n",
      "         [-0.1250, -0.1250, -0.1875],\n",
      "         [ 0.1875, -0.1250, -0.2500],\n",
      "         [-0.0625,  0.1875,  0.1875],\n",
      "         [ 0.1250,  0.0000, -0.0000],\n",
      "         [ 0.0000,  0.1250,  0.1875],\n",
      "         [-0.0000, -0.1250, -0.0000]],\n",
      "\n",
      "        [[-0.1875,  0.0625, -0.0000],\n",
      "         [-0.1875,  0.2500, -0.0625],\n",
      "         [ 0.0000,  0.1250,  0.0625],\n",
      "         [-0.1875, -0.1875,  0.1250],\n",
      "         [ 0.0625,  0.1875, -0.0625],\n",
      "         [ 0.1875,  0.0625, -0.0000],\n",
      "         [-0.1250,  0.1875,  0.1250],\n",
      "         [ 0.0000, -0.0000, -0.2500]],\n",
      "\n",
      "        [[ 0.2500, -0.1250,  0.1875],\n",
      "         [-0.0000, -0.0625,  0.1250],\n",
      "         [-0.1250,  0.0625,  0.1250],\n",
      "         [-0.1250,  0.0000,  0.1250],\n",
      "         [ 0.0625, -0.1250, -0.1875],\n",
      "         [-0.0625,  0.1250, -0.0000],\n",
      "         [ 0.1250,  0.2500, -0.0625],\n",
      "         [-0.0000,  0.1250,  0.0000]],\n",
      "\n",
      "        [[ 0.0625,  0.0625, -0.1250],\n",
      "         [ 0.0000,  0.1250,  0.1875],\n",
      "         [ 0.1250,  0.0625,  0.1875],\n",
      "         [-0.1875, -0.2500, -0.3125],\n",
      "         [ 0.1875,  0.1250, -0.1250],\n",
      "         [ 0.1250,  0.2500,  0.2500],\n",
      "         [ 0.2500,  0.2500, -0.0000],\n",
      "         [-0.0625,  0.1875,  0.1250]],\n",
      "\n",
      "        [[-0.0625,  0.3125,  0.1875],\n",
      "         [ 0.1250, -0.1875,  0.0000],\n",
      "         [-0.0000,  0.3125,  0.0625],\n",
      "         [ 0.0000, -0.0625,  0.1875],\n",
      "         [-0.1250, -0.0000, -0.1875],\n",
      "         [ 0.0625, -0.1250, -0.2500],\n",
      "         [-0.0000,  0.1250,  0.0625],\n",
      "         [ 0.2500,  0.2500, -0.1250]],\n",
      "\n",
      "        [[-0.1250,  0.0625, -0.1250],\n",
      "         [ 0.2500, -0.1250, -0.1250],\n",
      "         [-0.1875, -0.0625,  0.2500],\n",
      "         [ 0.1875,  0.0625,  0.1250],\n",
      "         [ 0.1875, -0.1250,  0.0000],\n",
      "         [ 0.2500,  0.1875,  0.3125],\n",
      "         [ 0.1875,  0.1875, -0.0625],\n",
      "         [ 0.1250,  0.0625, -0.0000]],\n",
      "\n",
      "        [[-0.1250, -0.0000, -0.2500],\n",
      "         [ 0.1875,  0.2500,  0.0625],\n",
      "         [-0.1250,  0.1875,  0.1250],\n",
      "         [ 0.0625, -0.0000,  0.3125],\n",
      "         [ 0.1250, -0.1250,  0.2500],\n",
      "         [ 0.1250, -0.1250,  0.1250],\n",
      "         [-0.1250, -0.0000,  0.2500],\n",
      "         [ 0.0000, -0.1875, -0.0625]]], grad_fn=<IntegerQuantizeBackward>)\n",
      "original bias: Parameter containing:\n",
      "tensor([ 0.0414,  0.0048,  0.0566,  0.2744,  0.1023, -0.0570,  0.0458,  0.1663,\n",
      "         0.2120, -0.1291, -0.0013, -0.1041, -0.0991,  0.1642, -0.1077,  0.1492],\n",
      "       requires_grad=True)\n",
      "quantized bias: tensor([-0.1875, -0.0625, -0.0625,  0.0625,  0.1875,  0.1875, -0.1875,  0.0625,\n",
      "         0.0625,  0.0625,  0.1875,  0.0625, -0.1250, -0.1250,  0.0000, -0.1250],\n",
      "       grad_fn=<IntegerQuantizeBackward>)\n",
      "There is quantization at block_conv1, mase_op: conv1d\n",
      "original module: <class 'torch.nn.modules.conv.Conv1d'>, new_module: <class 'chop.passes.graph.transforms.quantize.quantized_modules.conv1d.Conv1dInteger'>\n",
      "original weight: Parameter containing:\n",
      "tensor([[[ 1.7529e-01,  9.6693e-02, -3.5704e-02],\n",
      "         [-1.2477e-01, -1.0566e-01, -1.4548e-01],\n",
      "         [ 1.2687e-01, -8.7723e-02, -1.0876e-01],\n",
      "         [-1.5910e-01,  2.3152e-02,  1.9729e-01],\n",
      "         [-2.0626e-01,  1.2798e-01, -1.1425e-02],\n",
      "         [ 1.1729e-02, -8.6731e-02, -1.5462e-01],\n",
      "         [ 1.6926e-01,  1.7019e-01,  2.2318e-01],\n",
      "         [ 1.7077e-01,  6.7221e-03,  2.0152e-01],\n",
      "         [ 9.9712e-02,  1.5158e-01, -9.7151e-02],\n",
      "         [-1.0439e-01, -1.6068e-01, -2.1943e-02],\n",
      "         [-7.0865e-02, -1.3442e-01,  1.0918e-01],\n",
      "         [ 1.3588e-01,  5.1574e-02, -1.7752e-01],\n",
      "         [-8.8129e-02, -3.8877e-02,  5.8499e-02],\n",
      "         [ 2.3813e-01,  1.9061e-01,  6.9408e-02],\n",
      "         [ 4.8277e-02, -1.6103e-01, -2.0657e-01],\n",
      "         [ 2.1803e-02, -8.3554e-02,  1.3765e-01]],\n",
      "\n",
      "        [[-7.9756e-02,  6.3147e-03, -6.1013e-02],\n",
      "         [ 3.9618e-02, -2.6508e-02,  1.1274e-01],\n",
      "         [ 1.4593e-01,  1.4067e-01,  8.5509e-02],\n",
      "         [-8.5525e-02, -9.5521e-02,  6.2991e-02],\n",
      "         [-2.7965e-02, -1.6168e-01,  2.9850e-02],\n",
      "         [ 8.0129e-02, -1.2483e-01, -1.3165e-01],\n",
      "         [ 1.4935e-01,  1.7157e-01, -7.5085e-02],\n",
      "         [ 1.1738e-01,  9.3845e-02,  1.6704e-01],\n",
      "         [ 1.6329e-01, -1.9333e-02,  9.9310e-02],\n",
      "         [ 4.8570e-02, -6.1348e-02,  8.9616e-03],\n",
      "         [-8.8632e-02,  7.1052e-02,  4.4259e-02],\n",
      "         [ 3.7964e-02,  1.9295e-01,  1.2243e-01],\n",
      "         [-2.9650e-02,  7.5827e-02,  1.2398e-01],\n",
      "         [-2.0100e-02,  5.5498e-02,  5.9163e-02],\n",
      "         [ 1.1782e-01, -1.7861e-02, -3.6872e-02],\n",
      "         [-1.1523e-01,  8.0166e-02, -1.6713e-02]],\n",
      "\n",
      "        [[-7.2474e-03, -4.9391e-02,  1.0040e-01],\n",
      "         [ 1.5097e-01, -9.1333e-02, -9.9154e-02],\n",
      "         [-1.3094e-01, -4.9112e-02, -1.0192e-02],\n",
      "         [-7.8386e-03, -5.5847e-03,  8.7191e-02],\n",
      "         [-1.1529e-02,  9.3317e-02,  7.2600e-03],\n",
      "         [-1.1538e-01,  1.4939e-02,  1.6504e-01],\n",
      "         [-8.0934e-02,  1.1416e-02, -1.0830e-02],\n",
      "         [ 1.8623e-01, -1.4970e-01, -1.5314e-01],\n",
      "         [ 1.5553e-01, -9.7565e-02,  4.4292e-02],\n",
      "         [ 9.6783e-03, -4.5873e-03,  1.9433e-02],\n",
      "         [ 1.2167e-01, -3.2756e-03, -1.1870e-01],\n",
      "         [-2.2357e-01, -1.7960e-01, -1.7515e-02],\n",
      "         [-1.3640e-01,  1.3874e-01, -1.0186e-02],\n",
      "         [ 1.7609e-02,  8.7086e-02,  5.3549e-02],\n",
      "         [ 2.7559e-02,  9.3542e-03, -8.2769e-02],\n",
      "         [-2.1070e-02,  3.1814e-02,  1.4809e-01]],\n",
      "\n",
      "        [[-5.4750e-02, -1.1387e-01,  6.6108e-02],\n",
      "         [ 1.6914e-01, -1.7280e-03, -1.3357e-01],\n",
      "         [-8.7590e-02,  5.3313e-02, -7.8833e-02],\n",
      "         [-9.8631e-02,  5.7006e-02,  1.2914e-01],\n",
      "         [ 1.3297e-01,  1.2817e-01,  8.5160e-03],\n",
      "         [-7.7909e-02, -1.9442e-01,  1.0997e-01],\n",
      "         [ 5.5069e-02,  7.5406e-02, -1.4796e-01],\n",
      "         [ 9.8901e-02,  1.2235e-01,  1.1998e-01],\n",
      "         [-1.2611e-01, -5.2941e-02, -1.7650e-01],\n",
      "         [ 1.4183e-01, -7.3409e-02, -6.3173e-02],\n",
      "         [ 6.0453e-02,  2.8217e-02, -8.5230e-02],\n",
      "         [ 9.0084e-02,  9.2271e-02, -1.6461e-01],\n",
      "         [ 1.5371e-01, -6.5098e-02,  7.3415e-03],\n",
      "         [ 9.4197e-02,  9.5713e-02, -4.1938e-03],\n",
      "         [ 1.9192e-01,  6.8275e-02, -1.1829e-01],\n",
      "         [ 1.2778e-01,  2.7527e-02, -1.2233e-01]],\n",
      "\n",
      "        [[ 4.1499e-03, -1.7620e-02,  2.0308e-01],\n",
      "         [ 4.0029e-02, -4.8114e-02, -7.0434e-02],\n",
      "         [ 1.5236e-01,  1.0632e-01,  1.0380e-01],\n",
      "         [-1.0253e-01, -3.6747e-02, -3.9684e-02],\n",
      "         [-9.5623e-02, -2.2474e-01, -1.8244e-01],\n",
      "         [ 1.5966e-01, -2.4386e-02, -4.0345e-02],\n",
      "         [ 8.1001e-02,  5.9528e-02, -3.2943e-02],\n",
      "         [ 1.7713e-01, -2.2815e-02,  2.0229e-01],\n",
      "         [-6.5962e-02,  4.2652e-02,  1.3367e-01],\n",
      "         [-1.3742e-04,  1.0133e-01, -1.7520e-01],\n",
      "         [-1.3020e-01,  4.6540e-02,  7.2014e-02],\n",
      "         [ 2.5500e-01,  6.0838e-02,  1.3708e-01],\n",
      "         [ 2.4817e-02,  3.7444e-02,  1.4245e-01],\n",
      "         [-9.2729e-02,  6.4138e-02,  2.2833e-01],\n",
      "         [ 6.1780e-02,  2.0145e-01,  1.3401e-02],\n",
      "         [ 1.3320e-01, -1.3081e-01, -7.1973e-03]],\n",
      "\n",
      "        [[ 1.8054e-02,  9.3113e-02,  1.0057e-02],\n",
      "         [ 1.1636e-01,  1.9409e-02,  7.0838e-02],\n",
      "         [ 9.0158e-02, -6.3842e-04,  1.6096e-01],\n",
      "         [ 2.5087e-02,  8.6612e-02,  9.3984e-02],\n",
      "         [ 1.4329e-01,  1.9503e-01,  5.5743e-02],\n",
      "         [-1.3493e-01,  1.0416e-01,  1.2576e-01],\n",
      "         [ 8.0254e-02, -6.8967e-02,  8.5388e-02],\n",
      "         [ 1.6476e-01, -3.0687e-02, -1.8071e-01],\n",
      "         [ 1.2121e-01, -1.3821e-01,  5.9940e-03],\n",
      "         [ 5.7752e-02, -5.7765e-03,  1.2465e-01],\n",
      "         [-6.5084e-02,  8.7090e-02, -1.1428e-02],\n",
      "         [-9.9444e-02, -6.7508e-02,  6.8923e-02],\n",
      "         [-6.2072e-02,  1.1571e-01,  1.8799e-02],\n",
      "         [-3.6723e-02, -1.4075e-01, -1.2961e-01],\n",
      "         [ 6.9700e-02, -8.4634e-02, -1.8094e-02],\n",
      "         [ 1.1202e-01,  1.8525e-01,  2.1216e-01]],\n",
      "\n",
      "        [[ 1.4868e-01, -6.1972e-02,  4.9823e-02],\n",
      "         [ 5.2893e-03, -1.8089e-02, -5.4625e-02],\n",
      "         [ 2.0846e-01, -6.5547e-02,  1.4355e-01],\n",
      "         [-1.6987e-01,  3.5301e-02,  1.4725e-01],\n",
      "         [-1.3003e-01, -1.0070e-01, -1.8724e-01],\n",
      "         [ 2.3759e-01, -5.8915e-02, -2.3003e-01],\n",
      "         [ 5.5111e-02, -1.0934e-01, -8.2461e-02],\n",
      "         [ 1.9943e-02,  1.5471e-01,  1.7507e-02],\n",
      "         [ 8.2943e-02,  1.9158e-01,  1.4438e-01],\n",
      "         [-6.1726e-02, -1.2304e-01, -1.3085e-01],\n",
      "         [-1.2230e-01,  1.0496e-01,  1.8303e-01],\n",
      "         [ 2.5522e-01,  1.4575e-01,  1.5518e-01],\n",
      "         [-4.2804e-03,  1.9836e-01, -9.7309e-03],\n",
      "         [-8.8663e-02,  5.5183e-02,  1.3998e-01],\n",
      "         [-7.5911e-02,  2.4411e-01,  1.4347e-01],\n",
      "         [-9.7785e-02,  1.2510e-02,  1.6355e-01]],\n",
      "\n",
      "        [[-1.3169e-01,  3.8543e-03,  1.0839e-01],\n",
      "         [-6.6586e-02,  1.1135e-01,  1.1520e-01],\n",
      "         [ 1.4988e-01, -6.8520e-02,  2.2389e-01],\n",
      "         [-7.7795e-02,  1.0467e-01, -9.0371e-02],\n",
      "         [-1.0888e-01,  1.2531e-01,  1.0080e-02],\n",
      "         [ 7.8080e-02, -8.7872e-02, -3.5976e-02],\n",
      "         [-8.4652e-02, -1.8826e-01,  5.0744e-02],\n",
      "         [ 8.8025e-03, -4.4735e-02,  7.5309e-02],\n",
      "         [ 1.6179e-01,  7.4423e-02,  2.7150e-04],\n",
      "         [-4.2495e-02, -8.4383e-02, -1.1137e-01],\n",
      "         [ 1.2709e-02, -3.9587e-02,  1.8316e-01],\n",
      "         [-2.8556e-02,  2.3369e-01, -5.5387e-02],\n",
      "         [ 5.3655e-02,  2.1679e-01,  2.0989e-01],\n",
      "         [-1.0964e-01, -3.2470e-02,  3.0276e-02],\n",
      "         [-7.3022e-03,  5.9423e-02,  1.2655e-01],\n",
      "         [-4.2696e-02,  4.3344e-02,  1.3252e-01]],\n",
      "\n",
      "        [[-3.7391e-02,  1.7077e-01,  2.1501e-02],\n",
      "         [ 4.1176e-02,  1.5933e-01,  4.4557e-02],\n",
      "         [ 5.2662e-02,  6.0751e-03,  1.0738e-01],\n",
      "         [ 8.1757e-02,  8.2798e-02,  6.3938e-02],\n",
      "         [ 7.5425e-02,  7.5952e-02,  1.5314e-01],\n",
      "         [-7.2691e-02,  8.7356e-04,  1.2058e-02],\n",
      "         [-9.4683e-02,  5.6045e-02,  2.6165e-02],\n",
      "         [-6.7718e-02, -8.2679e-02, -8.5571e-03],\n",
      "         [-9.1321e-03,  1.0046e-01,  5.5070e-02],\n",
      "         [ 6.4488e-02,  1.0225e-01,  1.7900e-02],\n",
      "         [ 6.0878e-02,  1.3740e-01,  1.2440e-01],\n",
      "         [ 1.7087e-02,  6.3563e-02,  1.3530e-01],\n",
      "         [-5.9018e-02, -3.4233e-02,  1.5818e-01],\n",
      "         [-1.4626e-01, -8.0429e-02, -1.1857e-01],\n",
      "         [ 8.6060e-02, -1.2103e-01,  1.7914e-01],\n",
      "         [ 1.8450e-01,  9.6611e-02,  8.7247e-02]],\n",
      "\n",
      "        [[ 1.6502e-01, -2.4283e-03,  4.6271e-02],\n",
      "         [-6.0709e-02, -5.8292e-02, -1.8199e-02],\n",
      "         [ 7.7160e-02,  4.4185e-02, -8.3138e-02],\n",
      "         [-3.7755e-02, -8.6788e-02,  3.9626e-03],\n",
      "         [ 4.3762e-02,  6.6668e-02, -1.6138e-01],\n",
      "         [ 6.1962e-02, -1.0008e-01, -2.4281e-01],\n",
      "         [-9.1483e-02,  1.7374e-01,  1.2432e-01],\n",
      "         [ 1.1530e-01,  1.4553e-01, -1.8726e-02],\n",
      "         [ 8.0757e-02,  2.2656e-01, -4.9208e-03],\n",
      "         [ 7.4339e-02, -5.2077e-02, -4.2960e-03],\n",
      "         [-8.2477e-02,  4.7754e-02, -1.4393e-01],\n",
      "         [ 1.0155e-01,  1.7635e-01,  9.6039e-02],\n",
      "         [ 1.8184e-01,  1.9464e-01,  1.5427e-01],\n",
      "         [ 1.3537e-01,  1.8732e-01,  8.5242e-02],\n",
      "         [-6.9069e-02, -3.0016e-02,  4.2175e-03],\n",
      "         [-7.6465e-02,  6.0001e-02,  5.5596e-02]],\n",
      "\n",
      "        [[ 6.9268e-02,  9.6786e-02,  2.1429e-01],\n",
      "         [ 1.1104e-01, -5.9105e-02, -2.3804e-01],\n",
      "         [ 1.3874e-01,  8.8097e-02,  9.2518e-02],\n",
      "         [-2.9866e-01, -8.4626e-02,  1.3169e-01],\n",
      "         [ 9.9603e-03, -2.3014e-01,  1.1787e-01],\n",
      "         [ 2.9273e-02,  9.4759e-02, -9.6148e-02],\n",
      "         [ 1.8437e-01, -1.0796e-01, -9.8252e-02],\n",
      "         [ 1.3330e-01,  2.0217e-01,  1.5022e-01],\n",
      "         [ 1.5118e-01, -4.6459e-02,  1.2073e-01],\n",
      "         [-9.0751e-02, -9.8760e-03, -1.6876e-01],\n",
      "         [-1.4395e-01,  7.5542e-02, -4.9427e-02],\n",
      "         [ 1.0621e-01, -1.5219e-02, -6.1905e-02],\n",
      "         [ 1.1733e-01, -9.9766e-04, -8.2564e-02],\n",
      "         [-1.5654e-02, -3.7005e-02, -5.7251e-02],\n",
      "         [ 1.2802e-01,  1.2791e-01,  5.3416e-02],\n",
      "         [-1.2506e-01,  3.2870e-02,  4.5373e-02]],\n",
      "\n",
      "        [[-1.1350e-01,  2.2100e-02,  1.2976e-01],\n",
      "         [-1.5249e-01, -1.5638e-01,  8.0550e-03],\n",
      "         [ 9.9265e-02, -1.0026e-01,  1.5510e-02],\n",
      "         [ 9.1624e-02,  3.6045e-02,  2.5903e-02],\n",
      "         [ 1.3480e-01,  8.4045e-02, -8.3991e-02],\n",
      "         [ 1.0028e-02,  6.5676e-02,  1.1216e-01],\n",
      "         [-1.4119e-01,  7.8246e-02, -4.8767e-02],\n",
      "         [-1.4854e-01,  2.7544e-02, -7.8780e-02],\n",
      "         [ 9.9913e-03, -1.0213e-01, -1.2298e-01],\n",
      "         [-2.1255e-02, -5.9169e-02,  7.6402e-02],\n",
      "         [ 3.5995e-03,  9.7917e-02,  1.9868e-02],\n",
      "         [-4.6186e-02,  8.9894e-02,  7.8873e-03],\n",
      "         [ 1.4824e-02, -6.1054e-02, -1.5254e-02],\n",
      "         [-3.4463e-02, -1.3930e-02, -1.1927e-01],\n",
      "         [-1.0391e-02, -1.2387e-01, -4.3577e-02],\n",
      "         [ 7.1835e-02, -1.1074e-01, -1.0685e-01]],\n",
      "\n",
      "        [[-2.4619e-02,  3.0270e-02,  1.1234e-01],\n",
      "         [ 4.2128e-02,  8.0614e-02, -1.4789e-01],\n",
      "         [ 6.7366e-02,  1.6761e-01,  2.0163e-01],\n",
      "         [-6.5381e-02, -1.5672e-01,  1.1469e-01],\n",
      "         [ 1.0353e-02, -1.4407e-01, -1.7296e-01],\n",
      "         [ 1.9781e-01, -9.3140e-03, -1.5626e-01],\n",
      "         [-6.4889e-02,  9.4160e-02,  2.6299e-02],\n",
      "         [ 1.4009e-01,  1.8590e-01,  1.2673e-01],\n",
      "         [ 5.1778e-02,  4.6107e-02,  7.8945e-02],\n",
      "         [ 3.4633e-02, -1.6539e-01, -7.4564e-02],\n",
      "         [-1.6814e-01,  6.6978e-02, -1.5031e-02],\n",
      "         [ 2.4570e-01,  1.0420e-01,  4.2120e-03],\n",
      "         [ 1.1034e-01,  8.0857e-02,  1.2616e-01],\n",
      "         [ 1.0293e-01, -6.8091e-02,  2.0461e-01],\n",
      "         [-4.5903e-03, -4.1232e-04,  1.0397e-01],\n",
      "         [ 1.1063e-01, -1.4072e-01,  8.4038e-03]],\n",
      "\n",
      "        [[ 9.6827e-02,  3.9860e-02,  1.7248e-01],\n",
      "         [-8.0249e-02, -9.2469e-02,  1.4411e-01],\n",
      "         [ 3.1163e-02,  1.3727e-01,  2.1153e-03],\n",
      "         [-7.9872e-02, -4.9741e-02, -1.2857e-01],\n",
      "         [ 3.6706e-02,  9.4728e-02,  6.8675e-03],\n",
      "         [-7.7012e-02,  9.6866e-02, -9.8537e-02],\n",
      "         [ 1.1867e-01, -1.8276e-01, -1.5835e-01],\n",
      "         [-6.7018e-02,  1.1336e-01,  3.9961e-02],\n",
      "         [ 2.4412e-02, -2.8337e-02,  1.3341e-01],\n",
      "         [-4.6563e-02,  3.2229e-02,  1.3207e-01],\n",
      "         [ 8.0935e-02, -5.0784e-02,  3.0287e-03],\n",
      "         [-1.5824e-01, -2.2069e-02,  1.9425e-01],\n",
      "         [-1.0939e-01,  1.0672e-01, -8.9574e-03],\n",
      "         [-5.6405e-02, -3.5564e-02, -1.8458e-01],\n",
      "         [-4.4265e-02, -4.2939e-02,  2.6263e-02],\n",
      "         [-2.8061e-02,  1.1973e-01,  1.1836e-01]],\n",
      "\n",
      "        [[-9.7826e-02,  6.7049e-02, -1.1322e-01],\n",
      "         [-1.2288e-01,  4.4121e-02,  2.1213e-03],\n",
      "         [-6.7334e-02, -1.3921e-01, -5.5878e-02],\n",
      "         [ 4.8209e-02, -1.3360e-01, -1.4022e-01],\n",
      "         [ 1.8312e-02, -1.0398e-01, -1.2645e-01],\n",
      "         [-5.5611e-02, -2.3238e-02, -1.3116e-01],\n",
      "         [-9.6378e-02,  9.4639e-03, -1.3611e-01],\n",
      "         [-2.0287e-02, -9.3199e-02, -1.0006e-01],\n",
      "         [ 5.6729e-02, -1.1110e-01, -1.0938e-01],\n",
      "         [ 8.2313e-02,  2.6986e-02,  1.3145e-01],\n",
      "         [-3.8581e-02, -6.9717e-02, -1.3358e-02],\n",
      "         [ 7.3026e-04,  1.1008e-01, -1.4377e-01],\n",
      "         [-1.0277e-02,  6.3848e-02, -7.9484e-02],\n",
      "         [-7.3344e-02,  6.9754e-02, -1.3830e-01],\n",
      "         [ 3.4202e-02, -1.1174e-01,  7.1745e-02],\n",
      "         [-1.2341e-01,  8.8739e-02, -1.3663e-01]],\n",
      "\n",
      "        [[-8.0352e-02,  6.3154e-02,  2.1358e-01],\n",
      "         [-4.2000e-02,  8.6158e-03,  1.5271e-01],\n",
      "         [ 5.7227e-02,  1.5961e-01, -6.1778e-02],\n",
      "         [-1.2095e-01, -5.3383e-02,  1.7401e-01],\n",
      "         [ 1.5221e-02, -1.8701e-01, -3.2080e-02],\n",
      "         [ 1.1005e-01,  2.0487e-02, -1.5961e-01],\n",
      "         [-2.8718e-02,  1.4689e-01, -5.7097e-02],\n",
      "         [-8.8014e-02,  3.9572e-03,  6.6238e-02],\n",
      "         [ 9.3116e-02,  8.4667e-02,  5.3390e-02],\n",
      "         [-4.8340e-02,  2.7189e-03, -1.4999e-01],\n",
      "         [ 1.3783e-01, -4.8185e-02, -1.1758e-02],\n",
      "         [ 2.9722e-02,  1.3592e-01,  2.4359e-01],\n",
      "         [ 1.9881e-01, -2.9574e-02,  8.9756e-02],\n",
      "         [ 8.6557e-02,  1.1415e-01,  1.8365e-01],\n",
      "         [ 9.8418e-02,  3.9107e-02,  2.0644e-01],\n",
      "         [-1.6305e-02,  1.4014e-01,  5.8554e-02]]], requires_grad=True)\n",
      "quantized weight: tensor([[[ 0.1875,  0.1250, -0.0625],\n",
      "         [-0.1250, -0.1250, -0.1250],\n",
      "         [ 0.1250, -0.0625, -0.1250],\n",
      "         [-0.1875,  0.0000,  0.1875],\n",
      "         [-0.1875,  0.1250, -0.0000],\n",
      "         [ 0.0000, -0.0625, -0.1250],\n",
      "         [ 0.1875,  0.1875,  0.2500],\n",
      "         [ 0.1875,  0.0000,  0.1875],\n",
      "         [ 0.1250,  0.1250, -0.1250],\n",
      "         [-0.1250, -0.1875, -0.0000],\n",
      "         [-0.0625, -0.1250,  0.1250],\n",
      "         [ 0.1250,  0.0625, -0.1875],\n",
      "         [-0.0625, -0.0625,  0.0625],\n",
      "         [ 0.2500,  0.1875,  0.0625],\n",
      "         [ 0.0625, -0.1875, -0.1875],\n",
      "         [ 0.0000, -0.0625,  0.1250]],\n",
      "\n",
      "        [[-0.0625,  0.0000, -0.0625],\n",
      "         [ 0.0625, -0.0000,  0.1250],\n",
      "         [ 0.1250,  0.1250,  0.0625],\n",
      "         [-0.0625, -0.1250,  0.0625],\n",
      "         [-0.0000, -0.1875,  0.0000],\n",
      "         [ 0.0625, -0.1250, -0.1250],\n",
      "         [ 0.1250,  0.1875, -0.0625],\n",
      "         [ 0.1250,  0.1250,  0.1875],\n",
      "         [ 0.1875, -0.0000,  0.1250],\n",
      "         [ 0.0625, -0.0625,  0.0000],\n",
      "         [-0.0625,  0.0625,  0.0625],\n",
      "         [ 0.0625,  0.1875,  0.1250],\n",
      "         [-0.0000,  0.0625,  0.1250],\n",
      "         [-0.0000,  0.0625,  0.0625],\n",
      "         [ 0.1250, -0.0000, -0.0625],\n",
      "         [-0.1250,  0.0625, -0.0000]],\n",
      "\n",
      "        [[-0.0000, -0.0625,  0.1250],\n",
      "         [ 0.1250, -0.0625, -0.1250],\n",
      "         [-0.1250, -0.0625, -0.0000],\n",
      "         [-0.0000, -0.0000,  0.0625],\n",
      "         [-0.0000,  0.0625,  0.0000],\n",
      "         [-0.1250,  0.0000,  0.1875],\n",
      "         [-0.0625,  0.0000, -0.0000],\n",
      "         [ 0.1875, -0.1250, -0.1250],\n",
      "         [ 0.1250, -0.1250,  0.0625],\n",
      "         [ 0.0000, -0.0000,  0.0000],\n",
      "         [ 0.1250, -0.0000, -0.1250],\n",
      "         [-0.2500, -0.1875, -0.0000],\n",
      "         [-0.1250,  0.1250, -0.0000],\n",
      "         [ 0.0000,  0.0625,  0.0625],\n",
      "         [ 0.0000,  0.0000, -0.0625],\n",
      "         [-0.0000,  0.0625,  0.1250]],\n",
      "\n",
      "        [[-0.0625, -0.1250,  0.0625],\n",
      "         [ 0.1875, -0.0000, -0.1250],\n",
      "         [-0.0625,  0.0625, -0.0625],\n",
      "         [-0.1250,  0.0625,  0.1250],\n",
      "         [ 0.1250,  0.1250,  0.0000],\n",
      "         [-0.0625, -0.1875,  0.1250],\n",
      "         [ 0.0625,  0.0625, -0.1250],\n",
      "         [ 0.1250,  0.1250,  0.1250],\n",
      "         [-0.1250, -0.0625, -0.1875],\n",
      "         [ 0.1250, -0.0625, -0.0625],\n",
      "         [ 0.0625,  0.0000, -0.0625],\n",
      "         [ 0.0625,  0.0625, -0.1875],\n",
      "         [ 0.1250, -0.0625,  0.0000],\n",
      "         [ 0.1250,  0.1250, -0.0000],\n",
      "         [ 0.1875,  0.0625, -0.1250],\n",
      "         [ 0.1250,  0.0000, -0.1250]],\n",
      "\n",
      "        [[ 0.0000, -0.0000,  0.1875],\n",
      "         [ 0.0625, -0.0625, -0.0625],\n",
      "         [ 0.1250,  0.1250,  0.1250],\n",
      "         [-0.1250, -0.0625, -0.0625],\n",
      "         [-0.1250, -0.2500, -0.1875],\n",
      "         [ 0.1875, -0.0000, -0.0625],\n",
      "         [ 0.0625,  0.0625, -0.0625],\n",
      "         [ 0.1875, -0.0000,  0.1875],\n",
      "         [-0.0625,  0.0625,  0.1250],\n",
      "         [-0.0000,  0.1250, -0.1875],\n",
      "         [-0.1250,  0.0625,  0.0625],\n",
      "         [ 0.2500,  0.0625,  0.1250],\n",
      "         [ 0.0000,  0.0625,  0.1250],\n",
      "         [-0.0625,  0.0625,  0.2500],\n",
      "         [ 0.0625,  0.1875,  0.0000],\n",
      "         [ 0.1250, -0.1250, -0.0000]],\n",
      "\n",
      "        [[ 0.0000,  0.0625,  0.0000],\n",
      "         [ 0.1250,  0.0000,  0.0625],\n",
      "         [ 0.0625, -0.0000,  0.1875],\n",
      "         [ 0.0000,  0.0625,  0.1250],\n",
      "         [ 0.1250,  0.1875,  0.0625],\n",
      "         [-0.1250,  0.1250,  0.1250],\n",
      "         [ 0.0625, -0.0625,  0.0625],\n",
      "         [ 0.1875, -0.0000, -0.1875],\n",
      "         [ 0.1250, -0.1250,  0.0000],\n",
      "         [ 0.0625, -0.0000,  0.1250],\n",
      "         [-0.0625,  0.0625, -0.0000],\n",
      "         [-0.1250, -0.0625,  0.0625],\n",
      "         [-0.0625,  0.1250,  0.0000],\n",
      "         [-0.0625, -0.1250, -0.1250],\n",
      "         [ 0.0625, -0.0625, -0.0000],\n",
      "         [ 0.1250,  0.1875,  0.1875]],\n",
      "\n",
      "        [[ 0.1250, -0.0625,  0.0625],\n",
      "         [ 0.0000, -0.0000, -0.0625],\n",
      "         [ 0.1875, -0.0625,  0.1250],\n",
      "         [-0.1875,  0.0625,  0.1250],\n",
      "         [-0.1250, -0.1250, -0.1875],\n",
      "         [ 0.2500, -0.0625, -0.2500],\n",
      "         [ 0.0625, -0.1250, -0.0625],\n",
      "         [ 0.0000,  0.1250,  0.0000],\n",
      "         [ 0.0625,  0.1875,  0.1250],\n",
      "         [-0.0625, -0.1250, -0.1250],\n",
      "         [-0.1250,  0.1250,  0.1875],\n",
      "         [ 0.2500,  0.1250,  0.1250],\n",
      "         [-0.0000,  0.1875, -0.0000],\n",
      "         [-0.0625,  0.0625,  0.1250],\n",
      "         [-0.0625,  0.2500,  0.1250],\n",
      "         [-0.1250,  0.0000,  0.1875]],\n",
      "\n",
      "        [[-0.1250,  0.0000,  0.1250],\n",
      "         [-0.0625,  0.1250,  0.1250],\n",
      "         [ 0.1250, -0.0625,  0.2500],\n",
      "         [-0.0625,  0.1250, -0.0625],\n",
      "         [-0.1250,  0.1250,  0.0000],\n",
      "         [ 0.0625, -0.0625, -0.0625],\n",
      "         [-0.0625, -0.1875,  0.0625],\n",
      "         [ 0.0000, -0.0625,  0.0625],\n",
      "         [ 0.1875,  0.0625,  0.0000],\n",
      "         [-0.0625, -0.0625, -0.1250],\n",
      "         [ 0.0000, -0.0625,  0.1875],\n",
      "         [-0.0000,  0.2500, -0.0625],\n",
      "         [ 0.0625,  0.1875,  0.1875],\n",
      "         [-0.1250, -0.0625,  0.0000],\n",
      "         [-0.0000,  0.0625,  0.1250],\n",
      "         [-0.0625,  0.0625,  0.1250]],\n",
      "\n",
      "        [[-0.0625,  0.1875,  0.0000],\n",
      "         [ 0.0625,  0.1875,  0.0625],\n",
      "         [ 0.0625,  0.0000,  0.1250],\n",
      "         [ 0.0625,  0.0625,  0.0625],\n",
      "         [ 0.0625,  0.0625,  0.1250],\n",
      "         [-0.0625,  0.0000,  0.0000],\n",
      "         [-0.1250,  0.0625,  0.0000],\n",
      "         [-0.0625, -0.0625, -0.0000],\n",
      "         [-0.0000,  0.1250,  0.0625],\n",
      "         [ 0.0625,  0.1250,  0.0000],\n",
      "         [ 0.0625,  0.1250,  0.1250],\n",
      "         [ 0.0000,  0.0625,  0.1250],\n",
      "         [-0.0625, -0.0625,  0.1875],\n",
      "         [-0.1250, -0.0625, -0.1250],\n",
      "         [ 0.0625, -0.1250,  0.1875],\n",
      "         [ 0.1875,  0.1250,  0.0625]],\n",
      "\n",
      "        [[ 0.1875, -0.0000,  0.0625],\n",
      "         [-0.0625, -0.0625, -0.0000],\n",
      "         [ 0.0625,  0.0625, -0.0625],\n",
      "         [-0.0625, -0.0625,  0.0000],\n",
      "         [ 0.0625,  0.0625, -0.1875],\n",
      "         [ 0.0625, -0.1250, -0.2500],\n",
      "         [-0.0625,  0.1875,  0.1250],\n",
      "         [ 0.1250,  0.1250, -0.0000],\n",
      "         [ 0.0625,  0.2500, -0.0000],\n",
      "         [ 0.0625, -0.0625, -0.0000],\n",
      "         [-0.0625,  0.0625, -0.1250],\n",
      "         [ 0.1250,  0.1875,  0.1250],\n",
      "         [ 0.1875,  0.1875,  0.1250],\n",
      "         [ 0.1250,  0.1875,  0.0625],\n",
      "         [-0.0625, -0.0000,  0.0000],\n",
      "         [-0.0625,  0.0625,  0.0625]],\n",
      "\n",
      "        [[ 0.0625,  0.1250,  0.1875],\n",
      "         [ 0.1250, -0.0625, -0.2500],\n",
      "         [ 0.1250,  0.0625,  0.0625],\n",
      "         [-0.3125, -0.0625,  0.1250],\n",
      "         [ 0.0000, -0.2500,  0.1250],\n",
      "         [ 0.0000,  0.1250, -0.1250],\n",
      "         [ 0.1875, -0.1250, -0.1250],\n",
      "         [ 0.1250,  0.1875,  0.1250],\n",
      "         [ 0.1250, -0.0625,  0.1250],\n",
      "         [-0.0625, -0.0000, -0.1875],\n",
      "         [-0.1250,  0.0625, -0.0625],\n",
      "         [ 0.1250, -0.0000, -0.0625],\n",
      "         [ 0.1250, -0.0000, -0.0625],\n",
      "         [-0.0000, -0.0625, -0.0625],\n",
      "         [ 0.1250,  0.1250,  0.0625],\n",
      "         [-0.1250,  0.0625,  0.0625]],\n",
      "\n",
      "        [[-0.1250,  0.0000,  0.1250],\n",
      "         [-0.1250, -0.1875,  0.0000],\n",
      "         [ 0.1250, -0.1250,  0.0000],\n",
      "         [ 0.0625,  0.0625,  0.0000],\n",
      "         [ 0.1250,  0.0625, -0.0625],\n",
      "         [ 0.0000,  0.0625,  0.1250],\n",
      "         [-0.1250,  0.0625, -0.0625],\n",
      "         [-0.1250,  0.0000, -0.0625],\n",
      "         [ 0.0000, -0.1250, -0.1250],\n",
      "         [-0.0000, -0.0625,  0.0625],\n",
      "         [ 0.0000,  0.1250,  0.0000],\n",
      "         [-0.0625,  0.0625,  0.0000],\n",
      "         [ 0.0000, -0.0625, -0.0000],\n",
      "         [-0.0625, -0.0000, -0.1250],\n",
      "         [-0.0000, -0.1250, -0.0625],\n",
      "         [ 0.0625, -0.1250, -0.1250]],\n",
      "\n",
      "        [[-0.0000,  0.0000,  0.1250],\n",
      "         [ 0.0625,  0.0625, -0.1250],\n",
      "         [ 0.0625,  0.1875,  0.1875],\n",
      "         [-0.0625, -0.1875,  0.1250],\n",
      "         [ 0.0000, -0.1250, -0.1875],\n",
      "         [ 0.1875, -0.0000, -0.1875],\n",
      "         [-0.0625,  0.1250,  0.0000],\n",
      "         [ 0.1250,  0.1875,  0.1250],\n",
      "         [ 0.0625,  0.0625,  0.0625],\n",
      "         [ 0.0625, -0.1875, -0.0625],\n",
      "         [-0.1875,  0.0625, -0.0000],\n",
      "         [ 0.2500,  0.1250,  0.0000],\n",
      "         [ 0.1250,  0.0625,  0.1250],\n",
      "         [ 0.1250, -0.0625,  0.1875],\n",
      "         [-0.0000, -0.0000,  0.1250],\n",
      "         [ 0.1250, -0.1250,  0.0000]],\n",
      "\n",
      "        [[ 0.1250,  0.0625,  0.1875],\n",
      "         [-0.0625, -0.0625,  0.1250],\n",
      "         [ 0.0000,  0.1250,  0.0000],\n",
      "         [-0.0625, -0.0625, -0.1250],\n",
      "         [ 0.0625,  0.1250,  0.0000],\n",
      "         [-0.0625,  0.1250, -0.1250],\n",
      "         [ 0.1250, -0.1875, -0.1875],\n",
      "         [-0.0625,  0.1250,  0.0625],\n",
      "         [ 0.0000, -0.0000,  0.1250],\n",
      "         [-0.0625,  0.0625,  0.1250],\n",
      "         [ 0.0625, -0.0625,  0.0000],\n",
      "         [-0.1875, -0.0000,  0.1875],\n",
      "         [-0.1250,  0.1250, -0.0000],\n",
      "         [-0.0625, -0.0625, -0.1875],\n",
      "         [-0.0625, -0.0625,  0.0000],\n",
      "         [-0.0000,  0.1250,  0.1250]],\n",
      "\n",
      "        [[-0.1250,  0.0625, -0.1250],\n",
      "         [-0.1250,  0.0625,  0.0000],\n",
      "         [-0.0625, -0.1250, -0.0625],\n",
      "         [ 0.0625, -0.1250, -0.1250],\n",
      "         [ 0.0000, -0.1250, -0.1250],\n",
      "         [-0.0625, -0.0000, -0.1250],\n",
      "         [-0.1250,  0.0000, -0.1250],\n",
      "         [-0.0000, -0.0625, -0.1250],\n",
      "         [ 0.0625, -0.1250, -0.1250],\n",
      "         [ 0.0625,  0.0000,  0.1250],\n",
      "         [-0.0625, -0.0625, -0.0000],\n",
      "         [ 0.0000,  0.1250, -0.1250],\n",
      "         [-0.0000,  0.0625, -0.0625],\n",
      "         [-0.0625,  0.0625, -0.1250],\n",
      "         [ 0.0625, -0.1250,  0.0625],\n",
      "         [-0.1250,  0.0625, -0.1250]],\n",
      "\n",
      "        [[-0.0625,  0.0625,  0.1875],\n",
      "         [-0.0625,  0.0000,  0.1250],\n",
      "         [ 0.0625,  0.1875, -0.0625],\n",
      "         [-0.1250, -0.0625,  0.1875],\n",
      "         [ 0.0000, -0.1875, -0.0625],\n",
      "         [ 0.1250,  0.0000, -0.1875],\n",
      "         [-0.0000,  0.1250, -0.0625],\n",
      "         [-0.0625,  0.0000,  0.0625],\n",
      "         [ 0.0625,  0.0625,  0.0625],\n",
      "         [-0.0625,  0.0000, -0.1250],\n",
      "         [ 0.1250, -0.0625, -0.0000],\n",
      "         [ 0.0000,  0.1250,  0.2500],\n",
      "         [ 0.1875, -0.0000,  0.0625],\n",
      "         [ 0.0625,  0.1250,  0.1875],\n",
      "         [ 0.1250,  0.0625,  0.1875],\n",
      "         [-0.0000,  0.1250,  0.0625]]], grad_fn=<IntegerQuantizeBackward>)\n",
      "original bias: Parameter containing:\n",
      "tensor([ 0.1636,  0.1125,  0.2101, -0.1851, -0.0878,  0.0181, -0.0837,  0.1310,\n",
      "         0.0272, -0.0665, -0.0404, -0.0908,  0.1087, -0.1187, -0.1346, -0.1259],\n",
      "       requires_grad=True)\n",
      "quantized bias: tensor([-0.1250,  0.0625,  0.0625, -0.0000,  0.1250,  0.1250, -0.1250, -0.1250,\n",
      "        -0.0625, -0.1250, -0.1250,  0.1250,  0.0625, -0.0000,  0.1250,  0.0000],\n",
      "       grad_fn=<IntegerQuantizeBackward>)\n",
      "There is quantization at block_conv2, mase_op: conv1d\n",
      "original module: <class 'torch.nn.modules.conv.Conv1d'>, new_module: <class 'chop.passes.graph.transforms.quantize.quantized_modules.conv1d.Conv1dInteger'>\n",
      "original weight: Parameter containing:\n",
      "tensor([[[ 0.0812,  0.1581, -0.0654],\n",
      "         [ 0.0735,  0.1524,  0.0752],\n",
      "         [-0.0394,  0.0039, -0.0157],\n",
      "         [ 0.0233, -0.0708,  0.1503],\n",
      "         [ 0.1444, -0.0076,  0.1269],\n",
      "         [ 0.0973, -0.0225, -0.0158],\n",
      "         [ 0.1750, -0.0330,  0.1125],\n",
      "         [ 0.0820,  0.1431, -0.1478],\n",
      "         [-0.1442,  0.0572,  0.0758],\n",
      "         [-0.0943, -0.0285, -0.0835],\n",
      "         [-0.0352, -0.0155,  0.1815],\n",
      "         [-0.0303,  0.0870,  0.1377],\n",
      "         [ 0.1099, -0.0818,  0.1064],\n",
      "         [ 0.0771,  0.1152, -0.0627],\n",
      "         [ 0.0888,  0.1181, -0.1343],\n",
      "         [ 0.0892,  0.2007, -0.0517]],\n",
      "\n",
      "        [[ 0.0833,  0.0955,  0.0999],\n",
      "         [ 0.1899,  0.1878,  0.1543],\n",
      "         [-0.0753,  0.0297, -0.1729],\n",
      "         [-0.0781,  0.0499, -0.0054],\n",
      "         [ 0.2125,  0.1606,  0.1596],\n",
      "         [ 0.0672, -0.1706, -0.1143],\n",
      "         [ 0.0989,  0.1238,  0.1668],\n",
      "         [-0.0226, -0.0468,  0.1222],\n",
      "         [-0.0309, -0.1474,  0.0367],\n",
      "         [ 0.1468,  0.0207,  0.0168],\n",
      "         [-0.0640, -0.0353,  0.1351],\n",
      "         [-0.0669,  0.1035, -0.1104],\n",
      "         [ 0.0316,  0.0706,  0.1338],\n",
      "         [ 0.0641,  0.1518,  0.0512],\n",
      "         [-0.0663, -0.1031, -0.1291],\n",
      "         [ 0.0887,  0.2346,  0.0303]],\n",
      "\n",
      "        [[-0.0282, -0.1311,  0.0591],\n",
      "         [ 0.1010, -0.1157, -0.0646],\n",
      "         [ 0.1389,  0.0159, -0.0232],\n",
      "         [ 0.0003,  0.0434, -0.0557],\n",
      "         [-0.0880,  0.1513,  0.0289],\n",
      "         [ 0.0088, -0.0775, -0.1121],\n",
      "         [-0.0048, -0.0464,  0.1976],\n",
      "         [ 0.1070, -0.0335,  0.0120],\n",
      "         [ 0.1594,  0.0160,  0.0250],\n",
      "         [ 0.0514, -0.0595,  0.0770],\n",
      "         [ 0.0115,  0.1691,  0.0039],\n",
      "         [-0.0313,  0.1337, -0.1157],\n",
      "         [ 0.0382,  0.1794, -0.0219],\n",
      "         [ 0.1116,  0.1491,  0.1340],\n",
      "         [-0.0138,  0.1306, -0.0629],\n",
      "         [-0.0380,  0.1306,  0.1092]],\n",
      "\n",
      "        [[ 0.1116,  0.1216, -0.1222],\n",
      "         [ 0.0955,  0.0867,  0.0996],\n",
      "         [ 0.1392, -0.0481, -0.0784],\n",
      "         [ 0.0551, -0.0439,  0.1471],\n",
      "         [-0.1026,  0.0181,  0.0231],\n",
      "         [ 0.1106,  0.0745,  0.1368],\n",
      "         [ 0.0554,  0.1235,  0.2380],\n",
      "         [-0.0279,  0.0583,  0.0503],\n",
      "         [ 0.1664,  0.2287,  0.0779],\n",
      "         [-0.0291, -0.0457,  0.1392],\n",
      "         [ 0.0115,  0.1787,  0.1156],\n",
      "         [ 0.1375,  0.1085, -0.1039],\n",
      "         [ 0.0815, -0.0551,  0.0695],\n",
      "         [-0.0116,  0.0814, -0.0614],\n",
      "         [-0.1290,  0.0544,  0.0335],\n",
      "         [ 0.0429,  0.1422, -0.0335]],\n",
      "\n",
      "        [[ 0.1404,  0.0156,  0.1259],\n",
      "         [ 0.0250,  0.1579,  0.1866],\n",
      "         [ 0.2108,  0.0996,  0.1713],\n",
      "         [-0.2198, -0.1620,  0.0209],\n",
      "         [-0.0158, -0.0885, -0.0594],\n",
      "         [-0.0264, -0.1077,  0.0615],\n",
      "         [ 0.0478,  0.0342, -0.1008],\n",
      "         [-0.0932, -0.0794,  0.0366],\n",
      "         [ 0.1112, -0.0536, -0.0695],\n",
      "         [-0.0353,  0.0300, -0.0925],\n",
      "         [-0.1201,  0.1519, -0.0413],\n",
      "         [-0.0233, -0.0478, -0.1160],\n",
      "         [ 0.0321,  0.0885, -0.0212],\n",
      "         [-0.0528, -0.0404, -0.2294],\n",
      "         [ 0.1049,  0.1166,  0.0984],\n",
      "         [-0.0754,  0.0624, -0.1264]],\n",
      "\n",
      "        [[-0.0346, -0.0220, -0.0325],\n",
      "         [ 0.0526, -0.0478,  0.0196],\n",
      "         [ 0.0266, -0.0871,  0.0024],\n",
      "         [-0.2014,  0.1581,  0.1304],\n",
      "         [ 0.1704, -0.0272,  0.0007],\n",
      "         [ 0.1140,  0.2141,  0.1954],\n",
      "         [-0.0452, -0.1509, -0.1361],\n",
      "         [-0.0139,  0.1588,  0.0910],\n",
      "         [ 0.2033,  0.1761,  0.0663],\n",
      "         [-0.0945,  0.1763,  0.1518],\n",
      "         [ 0.0353, -0.0827,  0.1359],\n",
      "         [ 0.0238,  0.0932,  0.0515],\n",
      "         [ 0.0839, -0.1103, -0.0721],\n",
      "         [ 0.1080, -0.0034, -0.1250],\n",
      "         [ 0.1313, -0.0031,  0.1164],\n",
      "         [-0.1060,  0.0968, -0.0117]],\n",
      "\n",
      "        [[-0.0565, -0.0322, -0.0659],\n",
      "         [ 0.0810,  0.0045,  0.1248],\n",
      "         [ 0.0229, -0.1110, -0.1488],\n",
      "         [-0.0938,  0.0396, -0.0899],\n",
      "         [ 0.0305,  0.0616,  0.0416],\n",
      "         [-0.0334,  0.0302,  0.0364],\n",
      "         [ 0.0165, -0.0003,  0.1724],\n",
      "         [ 0.1656, -0.1266, -0.0224],\n",
      "         [-0.0290, -0.0012,  0.0872],\n",
      "         [-0.0007,  0.1618,  0.0293],\n",
      "         [ 0.0116, -0.0382,  0.0095],\n",
      "         [ 0.0564,  0.0559, -0.0038],\n",
      "         [ 0.1671, -0.0681,  0.0817],\n",
      "         [ 0.0964,  0.0561,  0.1745],\n",
      "         [ 0.0024, -0.1081, -0.0792],\n",
      "         [ 0.1031,  0.0092,  0.0749]],\n",
      "\n",
      "        [[ 0.2099,  0.1303,  0.0908],\n",
      "         [ 0.1087, -0.0029, -0.0708],\n",
      "         [-0.0823, -0.1016,  0.0887],\n",
      "         [ 0.0737, -0.0218, -0.1548],\n",
      "         [ 0.1656, -0.0113, -0.0078],\n",
      "         [-0.2078, -0.1648,  0.0930],\n",
      "         [-0.0475,  0.0165,  0.1482],\n",
      "         [-0.0123, -0.0269, -0.0329],\n",
      "         [ 0.0299, -0.1340, -0.0643],\n",
      "         [ 0.1137,  0.0635,  0.0774],\n",
      "         [-0.0476,  0.1698,  0.1102],\n",
      "         [-0.0091, -0.1219,  0.0627],\n",
      "         [ 0.1768,  0.0548,  0.1283],\n",
      "         [ 0.0111,  0.0029, -0.0209],\n",
      "         [ 0.1437,  0.0007, -0.1149],\n",
      "         [ 0.0708,  0.1583, -0.0314]],\n",
      "\n",
      "        [[-0.0245,  0.2260,  0.1890],\n",
      "         [ 0.0147,  0.0676,  0.0437],\n",
      "         [ 0.0636,  0.0128, -0.0671],\n",
      "         [-0.0441, -0.0786, -0.0489],\n",
      "         [-0.0073,  0.0900, -0.1174],\n",
      "         [-0.0226,  0.0106, -0.0657],\n",
      "         [-0.0975,  0.0271,  0.0254],\n",
      "         [-0.1229, -0.1152,  0.1152],\n",
      "         [ 0.0490,  0.0114,  0.0287],\n",
      "         [ 0.0849,  0.1260,  0.1344],\n",
      "         [-0.0196,  0.0222,  0.1707],\n",
      "         [-0.0102, -0.0933, -0.1014],\n",
      "         [ 0.1465,  0.1846,  0.1436],\n",
      "         [-0.0031,  0.0637, -0.1793],\n",
      "         [-0.1040, -0.1389,  0.1163],\n",
      "         [ 0.0405, -0.0291,  0.0952]],\n",
      "\n",
      "        [[-0.0637, -0.1210,  0.0463],\n",
      "         [ 0.0493, -0.0776, -0.0611],\n",
      "         [ 0.1536,  0.1689,  0.0698],\n",
      "         [-0.0583,  0.0692,  0.0885],\n",
      "         [-0.1575, -0.0752,  0.0621],\n",
      "         [ 0.1837,  0.0438,  0.1477],\n",
      "         [-0.1119,  0.1713,  0.1436],\n",
      "         [ 0.0876,  0.1463,  0.1382],\n",
      "         [ 0.0193,  0.1036,  0.1326],\n",
      "         [-0.0217,  0.1520, -0.0201],\n",
      "         [-0.1820, -0.0590, -0.1186],\n",
      "         [ 0.1266, -0.0640, -0.1031],\n",
      "         [-0.0274, -0.1011, -0.0332],\n",
      "         [ 0.1192, -0.0332,  0.0489],\n",
      "         [ 0.1053, -0.0003,  0.0641],\n",
      "         [-0.0937,  0.1407,  0.1814]],\n",
      "\n",
      "        [[ 0.0097,  0.1250, -0.1619],\n",
      "         [-0.0159,  0.0660, -0.0924],\n",
      "         [ 0.0038, -0.1379, -0.1243],\n",
      "         [-0.1889,  0.1321, -0.0325],\n",
      "         [ 0.0310,  0.1445,  0.1863],\n",
      "         [-0.0287, -0.1086, -0.1606],\n",
      "         [ 0.1838,  0.1347,  0.2171],\n",
      "         [ 0.1129,  0.1631, -0.0828],\n",
      "         [ 0.1476, -0.0726, -0.0878],\n",
      "         [ 0.0119,  0.0227,  0.0725],\n",
      "         [ 0.1564, -0.0271,  0.1107],\n",
      "         [-0.1067,  0.0104,  0.1193],\n",
      "         [ 0.1268,  0.1769,  0.1268],\n",
      "         [-0.0705,  0.0515, -0.0678],\n",
      "         [ 0.1225,  0.0723, -0.1056],\n",
      "         [ 0.1691,  0.0952,  0.0738]],\n",
      "\n",
      "        [[ 0.0138, -0.0082,  0.0247],\n",
      "         [-0.0285, -0.0819, -0.0272],\n",
      "         [ 0.0450,  0.1748,  0.1680],\n",
      "         [-0.1200,  0.0199, -0.0397],\n",
      "         [-0.1001, -0.0472, -0.0654],\n",
      "         [ 0.1580,  0.0032,  0.0836],\n",
      "         [-0.1250, -0.0723,  0.1160],\n",
      "         [-0.0288,  0.0479,  0.2049],\n",
      "         [ 0.1238,  0.0096, -0.0253],\n",
      "         [-0.0377, -0.0271,  0.0826],\n",
      "         [-0.0788,  0.1046, -0.0981],\n",
      "         [-0.0325,  0.0462,  0.1035],\n",
      "         [ 0.1487,  0.0286,  0.0325],\n",
      "         [-0.0108,  0.0913, -0.1541],\n",
      "         [-0.0379, -0.1206, -0.1388],\n",
      "         [ 0.0677, -0.0191,  0.0879]],\n",
      "\n",
      "        [[ 0.1029,  0.0770,  0.0662],\n",
      "         [-0.0216,  0.0811,  0.0769],\n",
      "         [ 0.0185, -0.0136, -0.0018],\n",
      "         [ 0.0151, -0.1089,  0.1004],\n",
      "         [-0.0714,  0.1189, -0.0423],\n",
      "         [-0.0637, -0.0382,  0.1138],\n",
      "         [-0.0718,  0.1230,  0.1230],\n",
      "         [ 0.1273,  0.0678,  0.0980],\n",
      "         [ 0.1476,  0.0166,  0.0722],\n",
      "         [-0.0830, -0.0130,  0.0347],\n",
      "         [ 0.0768, -0.0193, -0.1083],\n",
      "         [-0.0498,  0.0536,  0.1240],\n",
      "         [-0.1091,  0.0926, -0.1190],\n",
      "         [-0.1569, -0.1283,  0.0353],\n",
      "         [ 0.0403, -0.1098,  0.1112],\n",
      "         [ 0.1934,  0.0413,  0.1709]],\n",
      "\n",
      "        [[ 0.0042,  0.0686,  0.1021],\n",
      "         [ 0.0958, -0.0131, -0.0556],\n",
      "         [ 0.0352,  0.0061,  0.1915],\n",
      "         [ 0.0039,  0.1322, -0.1208],\n",
      "         [ 0.1677,  0.0297,  0.0731],\n",
      "         [-0.0314,  0.0158,  0.0038],\n",
      "         [ 0.1097,  0.1341, -0.1162],\n",
      "         [ 0.1619,  0.0844,  0.0786],\n",
      "         [-0.1250, -0.2034, -0.1150],\n",
      "         [ 0.1166,  0.1561,  0.1059],\n",
      "         [ 0.2174,  0.0650,  0.0045],\n",
      "         [ 0.0558,  0.0331, -0.0879],\n",
      "         [ 0.1200, -0.0236,  0.0022],\n",
      "         [-0.1716,  0.0934, -0.2019],\n",
      "         [-0.0852, -0.1413,  0.0364],\n",
      "         [-0.0216,  0.1095, -0.1578]],\n",
      "\n",
      "        [[-0.1069, -0.0770,  0.0264],\n",
      "         [ 0.1546,  0.1574,  0.0154],\n",
      "         [-0.1531, -0.0752, -0.1022],\n",
      "         [ 0.0177,  0.1147,  0.1442],\n",
      "         [ 0.1324,  0.1165, -0.0004],\n",
      "         [-0.0271, -0.0198, -0.0841],\n",
      "         [ 0.0832,  0.0896, -0.0515],\n",
      "         [ 0.1616,  0.0510, -0.0780],\n",
      "         [ 0.1656, -0.0762,  0.0492],\n",
      "         [ 0.1776,  0.0585,  0.0930],\n",
      "         [ 0.1070,  0.1841,  0.0067],\n",
      "         [-0.0852, -0.0070,  0.1106],\n",
      "         [ 0.0602,  0.1504,  0.0370],\n",
      "         [ 0.0616, -0.0425, -0.0116],\n",
      "         [-0.1374, -0.1262,  0.0120],\n",
      "         [ 0.1444,  0.1729,  0.0849]],\n",
      "\n",
      "        [[ 0.1119,  0.0542, -0.1188],\n",
      "         [-0.1043, -0.0820,  0.0405],\n",
      "         [-0.0194,  0.0096,  0.0383],\n",
      "         [ 0.0096,  0.0055,  0.0964],\n",
      "         [ 0.0685, -0.1450,  0.0463],\n",
      "         [ 0.0921,  0.1809, -0.0067],\n",
      "         [-0.0914, -0.0816,  0.1575],\n",
      "         [-0.0086, -0.0187,  0.1599],\n",
      "         [ 0.1750,  0.0461, -0.0590],\n",
      "         [ 0.1260, -0.0395, -0.0534],\n",
      "         [-0.1402, -0.1181, -0.1588],\n",
      "         [-0.0720, -0.1235, -0.0206],\n",
      "         [ 0.0523, -0.1043,  0.0467],\n",
      "         [-0.0610,  0.0937,  0.0937],\n",
      "         [-0.0191, -0.0726, -0.1109],\n",
      "         [-0.1174, -0.0024,  0.0169]]], requires_grad=True)\n",
      "quantized weight: tensor([[[ 0.0625,  0.1875, -0.0625],\n",
      "         [ 0.0625,  0.1250,  0.0625],\n",
      "         [-0.0625,  0.0000, -0.0000],\n",
      "         [ 0.0000, -0.0625,  0.1250],\n",
      "         [ 0.1250, -0.0000,  0.1250],\n",
      "         [ 0.1250, -0.0000, -0.0000],\n",
      "         [ 0.1875, -0.0625,  0.1250],\n",
      "         [ 0.0625,  0.1250, -0.1250],\n",
      "         [-0.1250,  0.0625,  0.0625],\n",
      "         [-0.1250, -0.0000, -0.0625],\n",
      "         [-0.0625, -0.0000,  0.1875],\n",
      "         [-0.0000,  0.0625,  0.1250],\n",
      "         [ 0.1250, -0.0625,  0.1250],\n",
      "         [ 0.0625,  0.1250, -0.0625],\n",
      "         [ 0.0625,  0.1250, -0.1250],\n",
      "         [ 0.0625,  0.1875, -0.0625]],\n",
      "\n",
      "        [[ 0.0625,  0.1250,  0.1250],\n",
      "         [ 0.1875,  0.1875,  0.1250],\n",
      "         [-0.0625,  0.0000, -0.1875],\n",
      "         [-0.0625,  0.0625, -0.0000],\n",
      "         [ 0.1875,  0.1875,  0.1875],\n",
      "         [ 0.0625, -0.1875, -0.1250],\n",
      "         [ 0.1250,  0.1250,  0.1875],\n",
      "         [-0.0000, -0.0625,  0.1250],\n",
      "         [-0.0000, -0.1250,  0.0625],\n",
      "         [ 0.1250,  0.0000,  0.0000],\n",
      "         [-0.0625, -0.0625,  0.1250],\n",
      "         [-0.0625,  0.1250, -0.1250],\n",
      "         [ 0.0625,  0.0625,  0.1250],\n",
      "         [ 0.0625,  0.1250,  0.0625],\n",
      "         [-0.0625, -0.1250, -0.1250],\n",
      "         [ 0.0625,  0.2500,  0.0000]],\n",
      "\n",
      "        [[-0.0000, -0.1250,  0.0625],\n",
      "         [ 0.1250, -0.1250, -0.0625],\n",
      "         [ 0.1250,  0.0000, -0.0000],\n",
      "         [ 0.0000,  0.0625, -0.0625],\n",
      "         [-0.0625,  0.1250,  0.0000],\n",
      "         [ 0.0000, -0.0625, -0.1250],\n",
      "         [-0.0000, -0.0625,  0.1875],\n",
      "         [ 0.1250, -0.0625,  0.0000],\n",
      "         [ 0.1875,  0.0000,  0.0000],\n",
      "         [ 0.0625, -0.0625,  0.0625],\n",
      "         [ 0.0000,  0.1875,  0.0000],\n",
      "         [-0.0625,  0.1250, -0.1250],\n",
      "         [ 0.0625,  0.1875, -0.0000],\n",
      "         [ 0.1250,  0.1250,  0.1250],\n",
      "         [-0.0000,  0.1250, -0.0625],\n",
      "         [-0.0625,  0.1250,  0.1250]],\n",
      "\n",
      "        [[ 0.1250,  0.1250, -0.1250],\n",
      "         [ 0.1250,  0.0625,  0.1250],\n",
      "         [ 0.1250, -0.0625, -0.0625],\n",
      "         [ 0.0625, -0.0625,  0.1250],\n",
      "         [-0.1250,  0.0000,  0.0000],\n",
      "         [ 0.1250,  0.0625,  0.1250],\n",
      "         [ 0.0625,  0.1250,  0.2500],\n",
      "         [-0.0000,  0.0625,  0.0625],\n",
      "         [ 0.1875,  0.2500,  0.0625],\n",
      "         [-0.0000, -0.0625,  0.1250],\n",
      "         [ 0.0000,  0.1875,  0.1250],\n",
      "         [ 0.1250,  0.1250, -0.1250],\n",
      "         [ 0.0625, -0.0625,  0.0625],\n",
      "         [-0.0000,  0.0625, -0.0625],\n",
      "         [-0.1250,  0.0625,  0.0625],\n",
      "         [ 0.0625,  0.1250, -0.0625]],\n",
      "\n",
      "        [[ 0.1250,  0.0000,  0.1250],\n",
      "         [ 0.0000,  0.1875,  0.1875],\n",
      "         [ 0.1875,  0.1250,  0.1875],\n",
      "         [-0.2500, -0.1875,  0.0000],\n",
      "         [-0.0000, -0.0625, -0.0625],\n",
      "         [-0.0000, -0.1250,  0.0625],\n",
      "         [ 0.0625,  0.0625, -0.1250],\n",
      "         [-0.0625, -0.0625,  0.0625],\n",
      "         [ 0.1250, -0.0625, -0.0625],\n",
      "         [-0.0625,  0.0000, -0.0625],\n",
      "         [-0.1250,  0.1250, -0.0625],\n",
      "         [-0.0000, -0.0625, -0.1250],\n",
      "         [ 0.0625,  0.0625, -0.0000],\n",
      "         [-0.0625, -0.0625, -0.2500],\n",
      "         [ 0.1250,  0.1250,  0.1250],\n",
      "         [-0.0625,  0.0625, -0.1250]],\n",
      "\n",
      "        [[-0.0625, -0.0000, -0.0625],\n",
      "         [ 0.0625, -0.0625,  0.0000],\n",
      "         [ 0.0000, -0.0625,  0.0000],\n",
      "         [-0.1875,  0.1875,  0.1250],\n",
      "         [ 0.1875, -0.0000,  0.0000],\n",
      "         [ 0.1250,  0.1875,  0.1875],\n",
      "         [-0.0625, -0.1250, -0.1250],\n",
      "         [-0.0000,  0.1875,  0.0625],\n",
      "         [ 0.1875,  0.1875,  0.0625],\n",
      "         [-0.1250,  0.1875,  0.1250],\n",
      "         [ 0.0625, -0.0625,  0.1250],\n",
      "         [ 0.0000,  0.0625,  0.0625],\n",
      "         [ 0.0625, -0.1250, -0.0625],\n",
      "         [ 0.1250, -0.0000, -0.1250],\n",
      "         [ 0.1250, -0.0000,  0.1250],\n",
      "         [-0.1250,  0.1250, -0.0000]],\n",
      "\n",
      "        [[-0.0625, -0.0625, -0.0625],\n",
      "         [ 0.0625,  0.0000,  0.1250],\n",
      "         [ 0.0000, -0.1250, -0.1250],\n",
      "         [-0.1250,  0.0625, -0.0625],\n",
      "         [ 0.0000,  0.0625,  0.0625],\n",
      "         [-0.0625,  0.0000,  0.0625],\n",
      "         [ 0.0000, -0.0000,  0.1875],\n",
      "         [ 0.1875, -0.1250, -0.0000],\n",
      "         [-0.0000, -0.0000,  0.0625],\n",
      "         [-0.0000,  0.1875,  0.0000],\n",
      "         [ 0.0000, -0.0625,  0.0000],\n",
      "         [ 0.0625,  0.0625, -0.0000],\n",
      "         [ 0.1875, -0.0625,  0.0625],\n",
      "         [ 0.1250,  0.0625,  0.1875],\n",
      "         [ 0.0000, -0.1250, -0.0625],\n",
      "         [ 0.1250,  0.0000,  0.0625]],\n",
      "\n",
      "        [[ 0.1875,  0.1250,  0.0625],\n",
      "         [ 0.1250, -0.0000, -0.0625],\n",
      "         [-0.0625, -0.1250,  0.0625],\n",
      "         [ 0.0625, -0.0000, -0.1250],\n",
      "         [ 0.1875, -0.0000, -0.0000],\n",
      "         [-0.1875, -0.1875,  0.0625],\n",
      "         [-0.0625,  0.0000,  0.1250],\n",
      "         [-0.0000, -0.0000, -0.0625],\n",
      "         [ 0.0000, -0.1250, -0.0625],\n",
      "         [ 0.1250,  0.0625,  0.0625],\n",
      "         [-0.0625,  0.1875,  0.1250],\n",
      "         [-0.0000, -0.1250,  0.0625],\n",
      "         [ 0.1875,  0.0625,  0.1250],\n",
      "         [ 0.0000,  0.0000, -0.0000],\n",
      "         [ 0.1250,  0.0000, -0.1250],\n",
      "         [ 0.0625,  0.1875, -0.0625]],\n",
      "\n",
      "        [[-0.0000,  0.2500,  0.1875],\n",
      "         [ 0.0000,  0.0625,  0.0625],\n",
      "         [ 0.0625,  0.0000, -0.0625],\n",
      "         [-0.0625, -0.0625, -0.0625],\n",
      "         [-0.0000,  0.0625, -0.1250],\n",
      "         [-0.0000,  0.0000, -0.0625],\n",
      "         [-0.1250,  0.0000,  0.0000],\n",
      "         [-0.1250, -0.1250,  0.1250],\n",
      "         [ 0.0625,  0.0000,  0.0000],\n",
      "         [ 0.0625,  0.1250,  0.1250],\n",
      "         [-0.0000,  0.0000,  0.1875],\n",
      "         [-0.0000, -0.0625, -0.1250],\n",
      "         [ 0.1250,  0.1875,  0.1250],\n",
      "         [-0.0000,  0.0625, -0.1875],\n",
      "         [-0.1250, -0.1250,  0.1250],\n",
      "         [ 0.0625, -0.0000,  0.1250]],\n",
      "\n",
      "        [[-0.0625, -0.1250,  0.0625],\n",
      "         [ 0.0625, -0.0625, -0.0625],\n",
      "         [ 0.1250,  0.1875,  0.0625],\n",
      "         [-0.0625,  0.0625,  0.0625],\n",
      "         [-0.1875, -0.0625,  0.0625],\n",
      "         [ 0.1875,  0.0625,  0.1250],\n",
      "         [-0.1250,  0.1875,  0.1250],\n",
      "         [ 0.0625,  0.1250,  0.1250],\n",
      "         [ 0.0000,  0.1250,  0.1250],\n",
      "         [-0.0000,  0.1250, -0.0000],\n",
      "         [-0.1875, -0.0625, -0.1250],\n",
      "         [ 0.1250, -0.0625, -0.1250],\n",
      "         [-0.0000, -0.1250, -0.0625],\n",
      "         [ 0.1250, -0.0625,  0.0625],\n",
      "         [ 0.1250, -0.0000,  0.0625],\n",
      "         [-0.0625,  0.1250,  0.1875]],\n",
      "\n",
      "        [[ 0.0000,  0.1250, -0.1875],\n",
      "         [-0.0000,  0.0625, -0.0625],\n",
      "         [ 0.0000, -0.1250, -0.1250],\n",
      "         [-0.1875,  0.1250, -0.0625],\n",
      "         [ 0.0000,  0.1250,  0.1875],\n",
      "         [-0.0000, -0.1250, -0.1875],\n",
      "         [ 0.1875,  0.1250,  0.1875],\n",
      "         [ 0.1250,  0.1875, -0.0625],\n",
      "         [ 0.1250, -0.0625, -0.0625],\n",
      "         [ 0.0000,  0.0000,  0.0625],\n",
      "         [ 0.1875, -0.0000,  0.1250],\n",
      "         [-0.1250,  0.0000,  0.1250],\n",
      "         [ 0.1250,  0.1875,  0.1250],\n",
      "         [-0.0625,  0.0625, -0.0625],\n",
      "         [ 0.1250,  0.0625, -0.1250],\n",
      "         [ 0.1875,  0.1250,  0.0625]],\n",
      "\n",
      "        [[ 0.0000, -0.0000,  0.0000],\n",
      "         [-0.0000, -0.0625, -0.0000],\n",
      "         [ 0.0625,  0.1875,  0.1875],\n",
      "         [-0.1250,  0.0000, -0.0625],\n",
      "         [-0.1250, -0.0625, -0.0625],\n",
      "         [ 0.1875,  0.0000,  0.0625],\n",
      "         [-0.1250, -0.0625,  0.1250],\n",
      "         [-0.0000,  0.0625,  0.1875],\n",
      "         [ 0.1250,  0.0000, -0.0000],\n",
      "         [-0.0625, -0.0000,  0.0625],\n",
      "         [-0.0625,  0.1250, -0.1250],\n",
      "         [-0.0625,  0.0625,  0.1250],\n",
      "         [ 0.1250,  0.0000,  0.0625],\n",
      "         [-0.0000,  0.0625, -0.1250],\n",
      "         [-0.0625, -0.1250, -0.1250],\n",
      "         [ 0.0625, -0.0000,  0.0625]],\n",
      "\n",
      "        [[ 0.1250,  0.0625,  0.0625],\n",
      "         [-0.0000,  0.0625,  0.0625],\n",
      "         [ 0.0000, -0.0000, -0.0000],\n",
      "         [ 0.0000, -0.1250,  0.1250],\n",
      "         [-0.0625,  0.1250, -0.0625],\n",
      "         [-0.0625, -0.0625,  0.1250],\n",
      "         [-0.0625,  0.1250,  0.1250],\n",
      "         [ 0.1250,  0.0625,  0.1250],\n",
      "         [ 0.1250,  0.0000,  0.0625],\n",
      "         [-0.0625, -0.0000,  0.0625],\n",
      "         [ 0.0625, -0.0000, -0.1250],\n",
      "         [-0.0625,  0.0625,  0.1250],\n",
      "         [-0.1250,  0.0625, -0.1250],\n",
      "         [-0.1875, -0.1250,  0.0625],\n",
      "         [ 0.0625, -0.1250,  0.1250],\n",
      "         [ 0.1875,  0.0625,  0.1875]],\n",
      "\n",
      "        [[ 0.0000,  0.0625,  0.1250],\n",
      "         [ 0.1250, -0.0000, -0.0625],\n",
      "         [ 0.0625,  0.0000,  0.1875],\n",
      "         [ 0.0000,  0.1250, -0.1250],\n",
      "         [ 0.1875,  0.0000,  0.0625],\n",
      "         [-0.0625,  0.0000,  0.0000],\n",
      "         [ 0.1250,  0.1250, -0.1250],\n",
      "         [ 0.1875,  0.0625,  0.0625],\n",
      "         [-0.1250, -0.1875, -0.1250],\n",
      "         [ 0.1250,  0.1250,  0.1250],\n",
      "         [ 0.1875,  0.0625,  0.0000],\n",
      "         [ 0.0625,  0.0625, -0.0625],\n",
      "         [ 0.1250, -0.0000,  0.0000],\n",
      "         [-0.1875,  0.0625, -0.1875],\n",
      "         [-0.0625, -0.1250,  0.0625],\n",
      "         [-0.0000,  0.1250, -0.1875]],\n",
      "\n",
      "        [[-0.1250, -0.0625,  0.0000],\n",
      "         [ 0.1250,  0.1875,  0.0000],\n",
      "         [-0.1250, -0.0625, -0.1250],\n",
      "         [ 0.0000,  0.1250,  0.1250],\n",
      "         [ 0.1250,  0.1250, -0.0000],\n",
      "         [-0.0000, -0.0000, -0.0625],\n",
      "         [ 0.0625,  0.0625, -0.0625],\n",
      "         [ 0.1875,  0.0625, -0.0625],\n",
      "         [ 0.1875, -0.0625,  0.0625],\n",
      "         [ 0.1875,  0.0625,  0.0625],\n",
      "         [ 0.1250,  0.1875,  0.0000],\n",
      "         [-0.0625, -0.0000,  0.1250],\n",
      "         [ 0.0625,  0.1250,  0.0625],\n",
      "         [ 0.0625, -0.0625, -0.0000],\n",
      "         [-0.1250, -0.1250,  0.0000],\n",
      "         [ 0.1250,  0.1875,  0.0625]],\n",
      "\n",
      "        [[ 0.1250,  0.0625, -0.1250],\n",
      "         [-0.1250, -0.0625,  0.0625],\n",
      "         [-0.0000,  0.0000,  0.0625],\n",
      "         [ 0.0000,  0.0000,  0.1250],\n",
      "         [ 0.0625, -0.1250,  0.0625],\n",
      "         [ 0.0625,  0.1875, -0.0000],\n",
      "         [-0.0625, -0.0625,  0.1875],\n",
      "         [-0.0000, -0.0000,  0.1875],\n",
      "         [ 0.1875,  0.0625, -0.0625],\n",
      "         [ 0.1250, -0.0625, -0.0625],\n",
      "         [-0.1250, -0.1250, -0.1875],\n",
      "         [-0.0625, -0.1250, -0.0000],\n",
      "         [ 0.0625, -0.1250,  0.0625],\n",
      "         [-0.0625,  0.0625,  0.0625],\n",
      "         [-0.0000, -0.0625, -0.1250],\n",
      "         [-0.1250, -0.0000,  0.0000]]], grad_fn=<IntegerQuantizeBackward>)\n",
      "original bias: Parameter containing:\n",
      "tensor([ 0.0988, -0.0527,  0.0686, -0.1088,  0.1220,  0.1760, -0.1759, -0.0036,\n",
      "         0.1347,  0.0311, -0.1160,  0.1567, -0.0214,  0.0681, -0.0690,  0.1724],\n",
      "       requires_grad=True)\n",
      "quantized bias: tensor([ 0.0625,  0.0625, -0.0000, -0.0000,  0.0000, -0.0000,  0.0000,  0.0625,\n",
      "        -0.0625,  0.0000, -0.1250, -0.0625,  0.0625, -0.0625,  0.0625,  0.0625],\n",
      "       grad_fn=<IntegerQuantizeBackward>)\n",
      "There is quantization at fc, mase_op: linear\n",
      "original module: <class 'torch.nn.modules.linear.Linear'>, new_module: <class 'chop.passes.graph.transforms.quantize.quantized_modules.linear.LinearInteger'>\n",
      "original weight: Parameter containing:\n",
      "tensor([[ 0.0752, -0.0539,  0.0252,  ...,  0.0037, -0.1073,  0.0500],\n",
      "        [-0.0059,  0.0253,  0.0007,  ...,  0.0487,  0.0635,  0.0750],\n",
      "        [ 0.0975,  0.0499, -0.0471,  ...,  0.0235,  0.0838,  0.1013],\n",
      "        [ 0.0061,  0.0469, -0.0265,  ...,  0.0446,  0.0610, -0.0798],\n",
      "        [ 0.0059, -0.0739,  0.0598,  ...,  0.0549, -0.0014, -0.0054]],\n",
      "       requires_grad=True)\n",
      "quantized weight: tensor([[ 0.0625, -0.0625,  0.0000,  ...,  0.0000, -0.1250,  0.0625],\n",
      "        [-0.0000,  0.0000,  0.0000,  ...,  0.0625,  0.0625,  0.0625],\n",
      "        [ 0.1250,  0.0625, -0.0625,  ...,  0.0000,  0.0625,  0.1250],\n",
      "        [ 0.0000,  0.0625, -0.0000,  ...,  0.0625,  0.0625, -0.0625],\n",
      "        [ 0.0000, -0.0625,  0.0625,  ...,  0.0625, -0.0000, -0.0000]],\n",
      "       grad_fn=<IntegerQuantizeBackward>)\n",
      "original bias: Parameter containing:\n",
      "tensor([-0.0223,  0.0642,  0.0230,  0.0888, -0.0599], requires_grad=True)\n",
      "quantized bias: tensor([-0.0000,  0.0625,  0.0000,  0.0625, -0.0625],\n",
      "       grad_fn=<IntegerQuantizeBackward>)\n",
      "output for original module: tensor([-0.5250,  0.8294,  0.6681,  1.3872,  0.7597], grad_fn=<ViewBackward0>)\n",
      "output for quantized module: tensor([-0.7852,  0.7617,  0.5703,  1.4648,  1.2305], grad_fn=<ViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "from machop.chop.passes.graph.utils import get_node_actual_target\n",
    "from machop.chop.passes.graph.utils import get_mase_op\n",
    "from machop.chop.passes.graph.utils import get_mase_type\n",
    "import torch\n",
    "\n",
    "for ori_n, n in zip(ori_mg.fx_graph.nodes, mg.fx_graph.nodes):\n",
    "    # As we've seen, the convolution and linear modules have changed\n",
    "    if isinstance(get_node_actual_target(ori_n), torch.nn.modules.Linear): # Linear\n",
    "        print(f\"There is quantization at {n.name}, mase_op: {get_mase_op(n)}\")\n",
    "        print(f\"original module: {type(get_node_actual_target(ori_n))}, new_module: {type(get_node_actual_target(n))}\")\n",
    "        print(f\"original weight: {get_node_actual_target(ori_n).weight}\")\n",
    "        print(f\"quantized weight: {get_node_actual_target(n).w_quantizer(get_node_actual_target(n).weight)}\")\n",
    "        print(f\"original bias: {get_node_actual_target(ori_n).bias}\")\n",
    "        print(f\"quantized bias: {get_node_actual_target(n).b_quantizer(get_node_actual_target(n).bias)}\")\n",
    "\n",
    "        # generate a random input to a quantized layer for quantisation verification\n",
    "        random_input = torch.randn(get_node_actual_target(n).in_features)\n",
    "        print(f'output for original module: {get_node_actual_target(ori_n)(random_input)}')\n",
    "        print(f'output for quantized module: {get_node_actual_target(n)(random_input)}')\n",
    "    \n",
    "    \n",
    "    if isinstance(get_node_actual_target(ori_n), torch.nn.modules.conv.Conv1d): # Conv1d\n",
    "        print(f\"There is quantization at {n.name}, mase_op: {get_mase_op(n)}\")\n",
    "        print(f\"original module: {type(get_node_actual_target(ori_n))}, new_module: {type(get_node_actual_target(n))}\")\n",
    "        print(f\"original weight: {get_node_actual_target(ori_n).weight}\")\n",
    "        print(f\"quantized weight: {get_node_actual_target(n).w_quantizer(get_node_actual_target(n).weight)}\")\n",
    "        print(f\"original bias: {get_node_actual_target(ori_n).bias}\")\n",
    "        print(f\"quantized bias: {get_node_actual_target(n).b_quantizer(get_node_actual_target(n).bias)}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/d/imperial/second_term/adls/rs1923/mase_real/machop\n",
      "Total number of JSC_1923 parameters: 3285\n",
      "Total number of JSC_Tiny parameters: 117\n",
      "Seed set to 0\n",
      "+-------------------------+--------------------------+--------------------------+-----------------+--------------------------+\n",
      "| Name                    |         Default          |       Config. File       | Manual Override |        Effective         |\n",
      "+-------------------------+--------------------------+--------------------------+-----------------+--------------------------+\n",
      "| task                    |      \u001b[38;5;8mclassification\u001b[0m      |           \u001b[38;5;8mcls\u001b[0m            |       cls       |           cls            |\n",
      "| load_name               |           \u001b[38;5;8mNone\u001b[0m           | ../mase_output/jsc-rs192 |                 | ../mase_output/jsc-rs192 |\n",
      "|                         |                          | 3_classification_jsc_202 |                 | 3_classification_jsc_202 |\n",
      "|                         |                          | 4-02-05/software/trainin |                 | 4-02-05/software/trainin |\n",
      "|                         |                          |    g_ckpts/best.ckpt     |                 |    g_ckpts/best.ckpt     |\n",
      "| load_type               |            \u001b[38;5;8mmz\u001b[0m            |            pl            |                 |            pl            |\n",
      "| batch_size              |           \u001b[38;5;8m128\u001b[0m            |           512            |                 |           512            |\n",
      "| to_debug                |          False           |                          |                 |          False           |\n",
      "| log_level               |           info           |                          |                 |           info           |\n",
      "| report_to               |       tensorboard        |                          |                 |       tensorboard        |\n",
      "| seed                    |            \u001b[38;5;8m0\u001b[0m             |            42            |                 |            42            |\n",
      "| quant_config            |           None           |                          |                 |           None           |\n",
      "| training_optimizer      |           adam           |                          |                 |           adam           |\n",
      "| trainer_precision       |         16-mixed         |                          |                 |         16-mixed         |\n",
      "| learning_rate           |          \u001b[38;5;8m1e-05\u001b[0m           |           0.01           |                 |           0.01           |\n",
      "| weight_decay            |            0             |                          |                 |            0             |\n",
      "| max_epochs              |            \u001b[38;5;8m20\u001b[0m            |            5             |                 |            5             |\n",
      "| max_steps               |            -1            |                          |                 |            -1            |\n",
      "| accumulate_grad_batches |            1             |                          |                 |            1             |\n",
      "| log_every_n_steps       |            \u001b[38;5;8m50\u001b[0m            |            5             |                 |            5             |\n",
      "| num_workers             |            \u001b[38;5;8m20\u001b[0m            |                          |        0        |            0             |\n",
      "| num_devices             |            1             |                          |                 |            1             |\n",
      "| num_nodes               |            1             |                          |                 |            1             |\n",
      "| accelerator             |           \u001b[38;5;8mauto\u001b[0m           |           cpu            |                 |           cpu            |\n",
      "| strategy                |           auto           |                          |                 |           auto           |\n",
      "| is_to_auto_requeue      |          False           |                          |                 |          False           |\n",
      "| github_ci               |          False           |                          |                 |          False           |\n",
      "| disable_dataset_cache   |          False           |                          |                 |          False           |\n",
      "| target                  |   xcu250-figd2104-2L-e   |                          |                 |   xcu250-figd2104-2L-e   |\n",
      "| num_targets             |           100            |                          |                 |           100            |\n",
      "| is_pretrained           |          False           |                          |                 |          False           |\n",
      "| max_token_len           |           512            |                          |                 |           512            |\n",
      "| project_dir             | /mnt/d/imperial/second_t |                          |                 | /mnt/d/imperial/second_t |\n",
      "|                         | erm/adls/rs1923/mase_rea |                          |                 | erm/adls/rs1923/mase_rea |\n",
      "|                         |      l/mase_output       |                          |                 |      l/mase_output       |\n",
      "| project                 |           \u001b[38;5;8mNone\u001b[0m           |        jsc-rs1923        |                 |        jsc-rs1923        |\n",
      "| model                   |           \u001b[38;5;8mNone\u001b[0m           |        jsc-rs1923        |                 |        jsc-rs1923        |\n",
      "| dataset                 |           \u001b[38;5;8mNone\u001b[0m           |           jsc            |                 |           jsc            |\n",
      "+-------------------------+--------------------------+--------------------------+-----------------+--------------------------+\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mInitialising model 'jsc-rs1923'...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mInitialising dataset 'jsc'...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mProject will be created at /mnt/d/imperial/second_term/adls/rs1923/mase_real/mase_output/jsc-rs1923\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTransforming model 'jsc-rs1923'...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mLoaded pytorch lightning checkpoint from ../mase_output/jsc-rs1923_classification_jsc_2024-02-05/software/training_ckpts/best.ckpt\u001b[0m\n",
      "/home/ruiqi/anaconda3/envs/mase/lib/python3.10/site-packages/torch/overrides.py:110: UserWarning: 'has_cuda' is deprecated, please use 'torch.backends.cuda.is_built()'\n",
      "  torch.has_cuda,\n",
      "/home/ruiqi/anaconda3/envs/mase/lib/python3.10/site-packages/torch/overrides.py:111: UserWarning: 'has_cudnn' is deprecated, please use 'torch.backends.cudnn.is_available()'\n",
      "  torch.has_cudnn,\n",
      "/home/ruiqi/anaconda3/envs/mase/lib/python3.10/site-packages/torch/overrides.py:117: UserWarning: 'has_mps' is deprecated, please use 'torch.backends.mps.is_built()'\n",
      "  torch.has_mps,\n",
      "/home/ruiqi/anaconda3/envs/mase/lib/python3.10/site-packages/torch/overrides.py:118: UserWarning: 'has_mkldnn' is deprecated, please use 'torch.backends.mkldnn.is_available()'\n",
      "  torch.has_mkldnn,\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mQuantized graph histogram:\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
      "| Original type   | OP          |   Total |   Changed |   Unchanged |\n",
      "|-----------------+-------------+---------+-----------+-------------|\n",
      "| Conv1d          | conv1d      |       4 |         4 |           0 |\n",
      "| Linear          | linear      |       1 |         1 |           0 |\n",
      "| add             | add         |       1 |         0 |           1 |\n",
      "| output          | output      |       1 |         0 |           1 |\n",
      "| relu            | relu        |       5 |         0 |           5 |\n",
      "| view            | view        |       1 |         0 |           1 |\n",
      "| x               | placeholder |       1 |         0 |           1 |\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mSaved mase graph to /mnt/d/imperial/second_term/adls/rs1923/mase_real/mase_output/jsc-rs1923/software/transform/transformed_ckpt\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTransformation is completed\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# 7. Load your own pre-trained JSC network, and perform perform the quantisation using the command line interface.\n",
    "\n",
    "%cd ./machop\n",
    "!./ch transform --config configs/examples/jsc_rs1923_by_type.toml --task cls --cpu=0\n",
    "\n",
    "# By default: quantize is by \"type\" and search is by \"name\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mnt/d/imperial/second_term/adls/rs1923/mase_real/machop'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# optional task\n",
    "\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%cd ./machop\n",
    "from chop.passes.graph.analysis import add_flops_bitops_analysis_pass\n",
    "mg = MaseGraph(model=own_model)\n",
    "mg, _ = init_metadata_analysis_pass(mg, None)\n",
    "mg, total_flops, total_bitops, _ = add_flops_bitops_analysis_pass(mg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5099520"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_bitops"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mase",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
