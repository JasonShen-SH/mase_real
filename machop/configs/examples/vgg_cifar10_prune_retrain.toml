##########################
#basics
##########################
model = "vgg7"
dataset = "cifar10"
task = "cls"

batch_size = 512
accelerator = "cpu"
project = "vgg_cifar10_prune"
seed = 42
log_every_n_steps = 50 
learning_rate = 1e-4

##########################
#prune
##########################
[passes.prune.weight]
sparsity = 0.2
scope = "local"
granularity = "elementwise"
method = "l1-norm"

[passes.prune.activation]
sparsity = 0.1
scope = "local"
granularity = "elementwise"
method = "l1-norm"


##########################
#retrain
##########################
[retrain]
load_name = "/mnt/d/imperial/second_term/adls/projects/mase/mase_output/vgg_cifar10_prune/software/prune/transformed_ckpt/state_dict.pt"
load_type = "pt"
project = "vgg_cifar10_train"

[retrain.training]
max_epochs = 1
weight_decay = 0
optimizer = "adam"
learning_rate = 1e-4
batch_size = 512

[retrain.trainer]
devices = 1
accelerator = "cpu"

