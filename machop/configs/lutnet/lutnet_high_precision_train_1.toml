# basics
model = "toy"
dataset = "cifar10"
# training
training_optimizer = "adamw"
learning_rate = 1e-5
max_epochs = 1
batch_size = 32
# torch lightning
task = "classification"
num_workers = 0
num_devices = 1
accelerator = "cpu"
project_dir = "../mase_output"

[passes.quantize]
by = "type"
report = true

[passes.quantize.default.config]
name = "binary"
binary_training = false
data_in_width = 32
data_in_frac_width = 16
data_in_stochastic = 0
data_in_bipolar = 1

weight_width = 1 # does not matter
weight_stochastic = 0
weight_bipolar = 1

bias_width = 32
bias_stochastic = 0
bias_bipolar = 1


 