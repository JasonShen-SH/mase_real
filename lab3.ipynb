{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import logging\n",
    "import os\n",
    "from pathlib import Path\n",
    "from pprint import pprint as pp\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mnt/d/imperial/second_term/adls/rs1923/mase_real'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# figure out the correct path\n",
    "machop_path = Path(\".\").resolve().parent.parent /\"new/mase/machop\"\n",
    "assert machop_path.exists(), \"Failed to find machop at: {}\".format(machop_path)\n",
    "sys.path.append(str(machop_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ruiqi/anaconda3/envs/mase/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of JSC_tiny parameters: 117\n"
     ]
    }
   ],
   "source": [
    "# Turning you network to a graph\n",
    "\n",
    "from chop.dataset import MaseDataModule, get_dataset_info\n",
    "from chop.tools.logger import get_logger\n",
    "\n",
    "from chop.passes.graph.analysis import (\n",
    "    report_node_meta_param_analysis_pass,\n",
    "    profile_statistics_analysis_pass,\n",
    ")\n",
    "from chop.passes.graph import (\n",
    "    add_common_metadata_analysis_pass,\n",
    "    init_metadata_analysis_pass,\n",
    "    add_software_metadata_analysis_pass,\n",
    ")\n",
    "from chop.tools.get_input import InputGenerator\n",
    "from chop.ir.graph.mase_graph import MaseGraph\n",
    "\n",
    "from chop.models import get_model_info, get_model\n",
    "from chop.tools.checkpoint_load import load_model\n",
    "\n",
    "from chop.passes.graph.transforms.utils import metadata_value_type_cast_transform_pass\n",
    "\n",
    "\n",
    "logger = get_logger(\"chop\")\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "batch_size = 256\n",
    "model_name = \"jsc-tiny\"\n",
    "dataset_name = \"jsc\"\n",
    "\n",
    "\n",
    "data_module = MaseDataModule(\n",
    "    name=dataset_name,\n",
    "    batch_size=batch_size,\n",
    "    model_name=model_name,\n",
    "    num_workers=0,\n",
    "    # custom_dataset_cache_path=\"../../chop/dataset\"\n",
    ")\n",
    "data_module.prepare_data()\n",
    "data_module.setup()\n",
    "\n",
    "CHECKPOINT_PATH = \"/mnt/d/imperial/second_term/adls/rs1923/mase_real/mase_output/jsc-tiny_classification_jsc_2024-02-05/software/training_ckpts/best.ckpt\"\n",
    "model_info = get_model_info(model_name)\n",
    "model = get_model(\n",
    "    model_name,\n",
    "    task=\"cls\",\n",
    "    dataset_info=data_module.dataset_info,\n",
    "    pretrained=False,\n",
    "    checkpoint = None)\n",
    "model = load_model(load_name=CHECKPOINT_PATH, load_type=\"pl\", model=model)\n",
    "\n",
    "input_generator = InputGenerator(\n",
    "    data_module=data_module,\n",
    "    model_info=model_info,\n",
    "    task=\"cls\",\n",
    "    which_dataloader=\"train\",\n",
    ")\n",
    "\n",
    "dummy_in = next(iter(input_generator))\n",
    "_ = model(**dummy_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mg = MaseGraph(model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# search space\n",
    "\n",
    "pass_args = {\n",
    "\"by\": \"type\",\n",
    "\"default\": {\"config\": {\"name\": None}},\n",
    "\n",
    "\"linear\": {\n",
    "    \"config\": {\n",
    "        \"name\": \"integer\",\n",
    "        # data\n",
    "        \"data_in_width\": 8,\n",
    "        \"data_in_frac_width\": 4,\n",
    "        # weight\n",
    "        \"weight_width\": 8,\n",
    "        \"weight_frac_width\": 4,\n",
    "        # bias\n",
    "        \"bias_width\": 8,\n",
    "        \"bias_frac_width\": 4,\n",
    "        }\n",
    "},}\n",
    "\n",
    "import copy\n",
    "# build a search space\n",
    "data_in_frac_widths = [(16, 8), (8, 6), (8, 4), (4, 2)]\n",
    "w_in_frac_widths = [(16, 8), (8, 6), (8, 4), (4, 2)]\n",
    "search_spaces = []\n",
    "for d_config in data_in_frac_widths:\n",
    "    for w_config in w_in_frac_widths:\n",
    "        pass_args['linear']['config']['data_in_width'] = d_config[0]\n",
    "        pass_args['linear']['config']['data_in_frac_width'] = d_config[1]\n",
    "        pass_args['linear']['config']['weight_width'] = w_config[0]\n",
    "        pass_args['linear']['config']['weight_frac_width'] = w_config[1]\n",
    "        # dict.copy() and dict(dict) only perform shallow copies\n",
    "        # in fact, only primitive data types in python are doing implicit copy when a = b happens\n",
    "        search_spaces.append(copy.deepcopy(pass_args))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nimport torch\\nfrom torchmetrics.classification import MulticlassAccuracy\\nfrom ptflops import get_model_complexity_info\\nfrom torch import optim\\n\\nfrom chop.passes.graph.transforms import (\\n    quantize_transform_pass,\\n    summarize_quantization_analysis_pass,\\n)\\n\\ndef init_mg(model):\\n    mg = MaseGraph(model=model)\\n    mg, _ = init_metadata_analysis_pass(mg, None)\\n    return mg\\n\\nmetric = MulticlassAccuracy(num_classes=5)\\n\\nbatch_size = 8\\noptimizer = optim.Adam(model.parameters(), lr=0.001)\\n\\nmax_epoch = 10\\nmg = init_mg(model)\\n\\nfor i, config in enumerate(search_spaces):\\n    mg, _ = quantize_transform_pass(mg, config)\\n\\n    for epoch in range(max_epoch):\\n        for inputs in data_module.train_dataloader():\\n            xs, ys = inputs\\n            optimizer.zero_grad()\\n            preds = mg.model(xs)\\n            loss = torch.nn.functional.cross_entropy(preds, ys)  \\n            loss.backward()  \\n            optimizer.step()  \\n    \\n    torch.save({\\n        'model_state_dict': mg.model.state_dict(),\\n        'optimizer_state_dict': optimizer.state_dict(),\\n        'config': config,\\n    }, f'model_and_optimizer_{i}.pth')\\n\\n    mg = init_mg(model)\\n    optimizer = optim.Adam(mg.model.parameters(), lr=0.001)\\n    \""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q1, Q2\n",
    "\n",
    "# train for QAT(Quantization-Aware Training)\n",
    "\n",
    "# This is not suitable for our case of PTQ\n",
    "\n",
    "# But we could make comparisons on the performance between PTQ and QAT\n",
    "\n",
    "'''\n",
    "import torch\n",
    "from torchmetrics.classification import MulticlassAccuracy\n",
    "from ptflops import get_model_complexity_info\n",
    "from torch import optim\n",
    "\n",
    "from chop.passes.graph.transforms import (\n",
    "    quantize_transform_pass,\n",
    "    summarize_quantization_analysis_pass,\n",
    ")\n",
    "\n",
    "def init_mg(model):\n",
    "    mg = MaseGraph(model=model)\n",
    "    mg, _ = init_metadata_analysis_pass(mg, None)\n",
    "    return mg\n",
    "\n",
    "metric = MulticlassAccuracy(num_classes=5)\n",
    "\n",
    "batch_size = 8\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "max_epoch = 10\n",
    "mg = init_mg(model)\n",
    "\n",
    "for i, config in enumerate(search_spaces):\n",
    "    mg, _ = quantize_transform_pass(mg, config)\n",
    "\n",
    "    for epoch in range(max_epoch):\n",
    "        for inputs in data_module.train_dataloader():\n",
    "            xs, ys = inputs\n",
    "            optimizer.zero_grad()\n",
    "            preds = mg.model(xs)\n",
    "            loss = torch.nn.functional.cross_entropy(preds, ys)  \n",
    "            loss.backward()  \n",
    "            optimizer.step()  \n",
    "    \n",
    "    torch.save({\n",
    "        'model_state_dict': mg.model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'config': config,\n",
    "    }, f'model_and_optimizer_{i}.pth')\n",
    "\n",
    "    mg = init_mg(model)\n",
    "    optimizer = optim.Adam(mg.model.parameters(), lr=0.001)\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<chop.ir.graph.mase_graph.MaseGraph object at 0x7f7bf7a1b1f0>\n",
      "<chop.ir.graph.mase_graph.MaseGraph object at 0x7f7d43cc7130>\n",
      "<chop.ir.graph.mase_graph.MaseGraph object at 0x7f7bf7a688b0>\n",
      "<chop.ir.graph.mase_graph.MaseGraph object at 0x7f7c3686ea70>\n",
      "<chop.ir.graph.mase_graph.MaseGraph object at 0x7f7d43e3f490>\n",
      "<chop.ir.graph.mase_graph.MaseGraph object at 0x7f7bf00d0b20>\n",
      "<chop.ir.graph.mase_graph.MaseGraph object at 0x7f7bf7a1a320>\n",
      "<chop.ir.graph.mase_graph.MaseGraph object at 0x7f7d43cc4dc0>\n",
      "<chop.ir.graph.mase_graph.MaseGraph object at 0x7f7ce4e98970>\n",
      "<chop.ir.graph.mase_graph.MaseGraph object at 0x7f7c2db65ed0>\n",
      "<chop.ir.graph.mase_graph.MaseGraph object at 0x7f7bf00d9b40>\n",
      "<chop.ir.graph.mase_graph.MaseGraph object at 0x7f7c3686ea70>\n",
      "<chop.ir.graph.mase_graph.MaseGraph object at 0x7f7bf7e06680>\n",
      "<chop.ir.graph.mase_graph.MaseGraph object at 0x7f7d43e3f490>\n",
      "<chop.ir.graph.mase_graph.MaseGraph object at 0x7f7bf7e06410>\n",
      "<chop.ir.graph.mase_graph.MaseGraph object at 0x7f7bee682b60>\n",
      "<chop.ir.graph.mase_graph.MaseGraph object at 0x7f7bee560520>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "229"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q1, Q2\n",
    "\n",
    "# search (grid search)\n",
    "\n",
    "import torch\n",
    "from torchmetrics.classification import MulticlassAccuracy\n",
    "from ptflops import get_model_complexity_info\n",
    "import time\n",
    "import gc\n",
    "\n",
    "from chop.passes.graph.transforms import (\n",
    "    quantize_transform_pass,\n",
    "    summarize_quantization_analysis_pass,\n",
    ")\n",
    "\n",
    "from chop.passes.graph.transforms.quantize.quantized_modules.linear import LinearInteger\n",
    "from chop.passes.graph.utils import get_node_actual_target\n",
    "\n",
    "\n",
    "def init_mg():\n",
    "    mg = MaseGraph(model=model)\n",
    "    mg, _ = init_metadata_analysis_pass(mg, None)\n",
    "    mg, _ = add_common_metadata_analysis_pass(mg, {\"dummy_in\": dummy_in})\n",
    "    return mg\n",
    "\n",
    "metric = MulticlassAccuracy(num_classes=5)\n",
    "batch_size = 256\n",
    "\n",
    "# model storage size (unit: Byte)\n",
    "def model_storage_size(model, weight_bit_width, bias_bit_width, data_bit_width):\n",
    "    total_bits = 0 \n",
    "    for name, param in model.named_parameters():\n",
    "        if param.requires_grad and 'weight' in name:\n",
    "            bits = param.numel() * weight_bit_width\n",
    "            total_bits += bits\n",
    "\n",
    "        elif param.requires_grad and 'bias' in name:\n",
    "            bits = param.numel() * bias_bit_width\n",
    "            total_bits += bits\n",
    "\n",
    "    total_bits += data_bit_width*(1*16+1) # mean and variance\n",
    "\n",
    "    total_bytes = total_bits / 8\n",
    "    return total_bytes\n",
    "\n",
    "\n",
    "# FLOP\n",
    "def calculate_flop_for_linear(module, batch_size):\n",
    "    in_features = module.in_features\n",
    "    out_features = module.out_features\n",
    "    return batch_size*(in_features * out_features)\n",
    "def calculate_flop_for_batchnorm1d(module, batch_size):\n",
    "    num_features = module.num_features\n",
    "    # calculate the mean: num_features * batch_size  [for each element, (batch_size-1)add, 1division]\n",
    "    # calculate the variance: (2*num_features+(num_features-1))*batch_size + (batch_size-1)  [for each element:2, for each sample: 2*num_features+(num_features-1)]\n",
    "    # calculate the denominator (knowing variance): 2  [add bias & square root]\n",
    "    # calculate for each sample xi: 4*num_features  [for each element, 4: 1*minus, 1*division, 1*multiply, 1*add]\n",
    "    return num_features * batch_size + (2*num_features+(num_features-1))*batch_size + (batch_size-1) + 2 + batch_size*(4*num_features)\n",
    "def calculate_flop_for_relu(module, input_features, batch_size):\n",
    "    # per element comparison with 0 (in essence, a minus)\n",
    "    input_features = input_features*batch_size\n",
    "    return input_features\n",
    "def add_flops_bitops_analysis_pass(graph):\n",
    "    total_flops = 0\n",
    "    for node in graph.fx_graph.nodes:\n",
    "        if isinstance(get_node_actual_target(node), torch.nn.modules.Linear):\n",
    "            flops = calculate_flop_for_linear(get_node_actual_target(node), batch_size)\n",
    "            total_flops += flops\n",
    "        elif isinstance(get_node_actual_target(node), torch.nn.modules.BatchNorm1d):\n",
    "            flops = calculate_flop_for_batchnorm1d(get_node_actual_target(node), batch_size)\n",
    "            total_flops += flops\n",
    "    flops = calculate_flop_for_relu(get_node_actual_target(node), 16, batch_size)\n",
    "    total_flops += flops\n",
    "    flops = calculate_flop_for_relu(get_node_actual_target(node), 5, batch_size)\n",
    "    total_flops += flops\n",
    "    return total_flops\n",
    "\n",
    "\n",
    "\n",
    "# bit-wise Operations (unit: number)\n",
    "def bit_wise_op(model, input_res, weight_width, bias_width, data_width, batch_size):\n",
    "    total_bitwise_ops = 0\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, LinearInteger):\n",
    "            bitwise_ops = calculate_bitwise_ops_for_linear(module, input_res, weight_width, bias_width, data_width, batch_size)\n",
    "            total_bitwise_ops += bitwise_ops\n",
    "    return total_bitwise_ops\n",
    "\n",
    "def calculate_bitwise_ops_for_linear(module, input_res, weight_bit_width, bias_bit_width, data_bit_width, batch_size):\n",
    "    in_features = module.in_features\n",
    "    out_features = module.out_features\n",
    "    bitwise_ops_per_multiplication = data_bit_width * weight_bit_width\n",
    "    bitwise_ops_per_addition = data_bit_width * weight_bit_width\n",
    "    bitwise_ops_per_output_feature = in_features * bitwise_ops_per_multiplication + (in_features - 1) * bitwise_ops_per_addition\n",
    "    if module.bias is not None:\n",
    "        bitwise_ops_per_output_feature += bias_bit_width\n",
    "    total_bitwise_ops = out_features * bitwise_ops_per_output_feature\n",
    "    return total_bitwise_ops*batch_size\n",
    "\n",
    "\n",
    "# search (grid search)\n",
    "\n",
    "mg = init_mg()\n",
    "recorded_metrics = []\n",
    "for i, config in enumerate(search_spaces):\n",
    "    linear_config = config['linear']['config']\n",
    "    data_width = linear_config['data_in_width']\n",
    "    data_frac_width = linear_config['data_in_frac_width']\n",
    "    weight_width = linear_config['weight_width']\n",
    "    weight_frac_width = linear_config['weight_frac_width']\n",
    "    bias_width = linear_config['bias_width']\n",
    "    bias_frac_width = linear_config['bias_frac_width']\n",
    "\n",
    "    mg, _ = quantize_transform_pass(mg, config)\n",
    "    data_bit_width = config['linear']['config']['data_in_width']\n",
    "    weight_bit_width = config['linear']['config']['weight_width']\n",
    "    bias_bit_width = config['linear']['config']['bias_width']\n",
    "\n",
    "    size = model_storage_size(mg.model, weight_bit_width, bias_bit_width, data_bit_width)  # model size after it has been quantized\n",
    "    flop = add_flops_bitops_analysis_pass(mg)\n",
    "    bit_op = bit_wise_op(mg.model, (16,), weight_bit_width, bias_bit_width, data_bit_width, batch_size)\n",
    "\n",
    "    acc_avg, loss_avg = 0, 0\n",
    "    accs, losses, latencies = [], [], []\n",
    "\n",
    "    for inputs in data_module.train_dataloader():\n",
    "        xs, ys = inputs\n",
    "        start_time = time.time()\n",
    "        preds = mg.model(xs)\n",
    "        end_time = time.time()\n",
    "        latency = end_time - start_time \n",
    "        latencies.append(latency*1000) # (unit: ms)\n",
    "\n",
    "        acc = metric(preds, ys)\n",
    "        accs.append(acc)\n",
    "        loss = torch.nn.functional.cross_entropy(preds, ys)\n",
    "        losses.append(loss)\n",
    "\n",
    "    acc_avg = sum(accs) / len(accs)\n",
    "    loss_avg = sum(losses) / len(losses)\n",
    "    latency_avg = sum(latencies) / len(latencies) \n",
    "\n",
    "    recorded_metrics.append({\n",
    "        \"data_width\": data_width,\n",
    "        \"data_frac_width\": data_frac_width,\n",
    "        \"weight_width\": weight_width,\n",
    "        \"weight_frac_width\": weight_frac_width,\n",
    "        \"bias_width\": bias_width,\n",
    "        \"bias_frac_width\": bias_frac_width,\n",
    "        \n",
    "        \"acc(%)\": (acc_avg.item())*100,\n",
    "        \"loss\": loss_avg.item(),\n",
    "        \"latency(ms)\": latency_avg*1000,\n",
    "        \"model_size(Byte)\": size,\n",
    "        \"flop(number)\": flop,\n",
    "        \"bitwise_ops(number)\": bit_op,\n",
    "    }) \n",
    "    del accs, losses, latencies, acc_avg, loss_avg, latency_avg, size, flop, bit_op\n",
    "    gc.collect()\n",
    "\n",
    "    mg = init_mg()\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'data_width': 16,\n",
       "  'data_frac_width': 8,\n",
       "  'weight_width': 16,\n",
       "  'weight_frac_width': 8,\n",
       "  'bias_width': 8,\n",
       "  'bias_frac_width': 4,\n",
       "  'acc(%)': 51.60192251205444,\n",
       "  'loss': 1.325373888015747,\n",
       "  'latency(ms)': 349.6421604923392,\n",
       "  'model_size(Byte)': 247.0,\n",
       "  'flop(number)': 58625,\n",
       "  'bitwise_ops(number)': 10168320},\n",
       " {'data_width': 16,\n",
       "  'data_frac_width': 8,\n",
       "  'weight_width': 8,\n",
       "  'weight_frac_width': 6,\n",
       "  'bias_width': 8,\n",
       "  'bias_frac_width': 4,\n",
       "  'acc(%)': 51.70328617095947,\n",
       "  'loss': 1.3258105516433716,\n",
       "  'latency(ms)': 298.0583218130465,\n",
       "  'model_size(Byte)': 151.0,\n",
       "  'flop(number)': 58625,\n",
       "  'bitwise_ops(number)': 5089280},\n",
       " {'data_width': 16,\n",
       "  'data_frac_width': 8,\n",
       "  'weight_width': 8,\n",
       "  'weight_frac_width': 4,\n",
       "  'bias_width': 8,\n",
       "  'bias_frac_width': 4,\n",
       "  'acc(%)': 51.464223861694336,\n",
       "  'loss': 1.3287193775177002,\n",
       "  'latency(ms)': 307.19731413746007,\n",
       "  'model_size(Byte)': 151.0,\n",
       "  'flop(number)': 58625,\n",
       "  'bitwise_ops(number)': 5089280},\n",
       " {'data_width': 16,\n",
       "  'data_frac_width': 8,\n",
       "  'weight_width': 4,\n",
       "  'weight_frac_width': 2,\n",
       "  'bias_width': 8,\n",
       "  'bias_frac_width': 4,\n",
       "  'acc(%)': 51.015448570251465,\n",
       "  'loss': 1.3313390016555786,\n",
       "  'latency(ms)': 306.4579382326198,\n",
       "  'model_size(Byte)': 103.0,\n",
       "  'flop(number)': 58625,\n",
       "  'bitwise_ops(number)': 2549760},\n",
       " {'data_width': 8,\n",
       "  'data_frac_width': 6,\n",
       "  'weight_width': 16,\n",
       "  'weight_frac_width': 8,\n",
       "  'bias_width': 8,\n",
       "  'bias_frac_width': 4,\n",
       "  'acc(%)': 51.63904428482056,\n",
       "  'loss': 1.342086911201477,\n",
       "  'latency(ms)': 301.28176574113303,\n",
       "  'model_size(Byte)': 230.0,\n",
       "  'flop(number)': 58625,\n",
       "  'bitwise_ops(number)': 5089280},\n",
       " {'data_width': 8,\n",
       "  'data_frac_width': 6,\n",
       "  'weight_width': 8,\n",
       "  'weight_frac_width': 6,\n",
       "  'bias_width': 8,\n",
       "  'bias_frac_width': 4,\n",
       "  'acc(%)': 51.695048809051514,\n",
       "  'loss': 1.3430596590042114,\n",
       "  'latency(ms)': 312.07252569235715,\n",
       "  'model_size(Byte)': 134.0,\n",
       "  'flop(number)': 58625,\n",
       "  'bitwise_ops(number)': 2549760},\n",
       " {'data_width': 8,\n",
       "  'data_frac_width': 6,\n",
       "  'weight_width': 8,\n",
       "  'weight_frac_width': 4,\n",
       "  'bias_width': 8,\n",
       "  'bias_frac_width': 4,\n",
       "  'acc(%)': 51.47773623466492,\n",
       "  'loss': 1.3444429636001587,\n",
       "  'latency(ms)': 316.18880236040604,\n",
       "  'model_size(Byte)': 134.0,\n",
       "  'flop(number)': 58625,\n",
       "  'bitwise_ops(number)': 2549760},\n",
       " {'data_width': 8,\n",
       "  'data_frac_width': 6,\n",
       "  'weight_width': 4,\n",
       "  'weight_frac_width': 2,\n",
       "  'bias_width': 8,\n",
       "  'bias_frac_width': 4,\n",
       "  'acc(%)': 50.961071252822876,\n",
       "  'loss': 1.3446311950683594,\n",
       "  'latency(ms)': 332.3940760739892,\n",
       "  'model_size(Byte)': 86.0,\n",
       "  'flop(number)': 58625,\n",
       "  'bitwise_ops(number)': 1280000},\n",
       " {'data_width': 8,\n",
       "  'data_frac_width': 4,\n",
       "  'weight_width': 16,\n",
       "  'weight_frac_width': 8,\n",
       "  'bias_width': 8,\n",
       "  'bias_frac_width': 4,\n",
       "  'acc(%)': 51.612430810928345,\n",
       "  'loss': 1.325469970703125,\n",
       "  'latency(ms)': 342.234176729749,\n",
       "  'model_size(Byte)': 230.0,\n",
       "  'flop(number)': 58625,\n",
       "  'bitwise_ops(number)': 5089280},\n",
       " {'data_width': 8,\n",
       "  'data_frac_width': 4,\n",
       "  'weight_width': 8,\n",
       "  'weight_frac_width': 6,\n",
       "  'bias_width': 8,\n",
       "  'bias_frac_width': 4,\n",
       "  'acc(%)': 51.707714796066284,\n",
       "  'loss': 1.325859546661377,\n",
       "  'latency(ms)': 342.8204823406135,\n",
       "  'model_size(Byte)': 134.0,\n",
       "  'flop(number)': 58625,\n",
       "  'bitwise_ops(number)': 2549760},\n",
       " {'data_width': 8,\n",
       "  'data_frac_width': 4,\n",
       "  'weight_width': 8,\n",
       "  'weight_frac_width': 4,\n",
       "  'bias_width': 8,\n",
       "  'bias_frac_width': 4,\n",
       "  'acc(%)': 51.40484571456909,\n",
       "  'loss': 1.3287560939788818,\n",
       "  'latency(ms)': 334.4871963817631,\n",
       "  'model_size(Byte)': 134.0,\n",
       "  'flop(number)': 58625,\n",
       "  'bitwise_ops(number)': 2549760},\n",
       " {'data_width': 8,\n",
       "  'data_frac_width': 4,\n",
       "  'weight_width': 4,\n",
       "  'weight_frac_width': 2,\n",
       "  'bias_width': 8,\n",
       "  'bias_frac_width': 4,\n",
       "  'acc(%)': 51.01280212402344,\n",
       "  'loss': 1.3313686847686768,\n",
       "  'latency(ms)': 319.36941752947104,\n",
       "  'model_size(Byte)': 86.0,\n",
       "  'flop(number)': 58625,\n",
       "  'bitwise_ops(number)': 1280000},\n",
       " {'data_width': 4,\n",
       "  'data_frac_width': 2,\n",
       "  'weight_width': 16,\n",
       "  'weight_frac_width': 8,\n",
       "  'bias_width': 8,\n",
       "  'bias_frac_width': 4,\n",
       "  'acc(%)': 51.326191425323486,\n",
       "  'loss': 1.3534139394760132,\n",
       "  'latency(ms)': 352.30326436063814,\n",
       "  'model_size(Byte)': 221.5,\n",
       "  'flop(number)': 58625,\n",
       "  'bitwise_ops(number)': 2549760},\n",
       " {'data_width': 4,\n",
       "  'data_frac_width': 2,\n",
       "  'weight_width': 8,\n",
       "  'weight_frac_width': 6,\n",
       "  'bias_width': 8,\n",
       "  'bias_frac_width': 4,\n",
       "  'acc(%)': 51.62806510925293,\n",
       "  'loss': 1.3544719219207764,\n",
       "  'latency(ms)': 338.71479689997614,\n",
       "  'model_size(Byte)': 125.5,\n",
       "  'flop(number)': 58625,\n",
       "  'bitwise_ops(number)': 1280000},\n",
       " {'data_width': 4,\n",
       "  'data_frac_width': 2,\n",
       "  'weight_width': 8,\n",
       "  'weight_frac_width': 4,\n",
       "  'bias_width': 8,\n",
       "  'bias_frac_width': 4,\n",
       "  'acc(%)': 51.29737854003906,\n",
       "  'loss': 1.3552448749542236,\n",
       "  'latency(ms)': 368.51263541037315,\n",
       "  'model_size(Byte)': 125.5,\n",
       "  'flop(number)': 58625,\n",
       "  'bitwise_ops(number)': 1280000},\n",
       " {'data_width': 4,\n",
       "  'data_frac_width': 2,\n",
       "  'weight_width': 4,\n",
       "  'weight_frac_width': 2,\n",
       "  'bias_width': 8,\n",
       "  'bias_frac_width': 4,\n",
       "  'acc(%)': 50.73213577270508,\n",
       "  'loss': 1.3554396629333496,\n",
       "  'latency(ms)': 355.984063773149,\n",
       "  'model_size(Byte)': 77.5,\n",
       "  'flop(number)': 58625,\n",
       "  'bitwise_ops(number)': 645120}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recorded_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data_width</th>\n",
       "      <th>data_frac_width</th>\n",
       "      <th>weight_width</th>\n",
       "      <th>weight_frac_width</th>\n",
       "      <th>bias_width</th>\n",
       "      <th>bias_frac_width</th>\n",
       "      <th>acc(%)</th>\n",
       "      <th>loss</th>\n",
       "      <th>latency(ms)</th>\n",
       "      <th>model_size(Byte)</th>\n",
       "      <th>flop(number)</th>\n",
       "      <th>bitwise_ops(number)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>51.601923</td>\n",
       "      <td>1.325374</td>\n",
       "      <td>349.642160</td>\n",
       "      <td>247.0</td>\n",
       "      <td>58625</td>\n",
       "      <td>10168320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>51.703286</td>\n",
       "      <td>1.325811</td>\n",
       "      <td>298.058322</td>\n",
       "      <td>151.0</td>\n",
       "      <td>58625</td>\n",
       "      <td>5089280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>51.464224</td>\n",
       "      <td>1.328719</td>\n",
       "      <td>307.197314</td>\n",
       "      <td>151.0</td>\n",
       "      <td>58625</td>\n",
       "      <td>5089280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>51.015449</td>\n",
       "      <td>1.331339</td>\n",
       "      <td>306.457938</td>\n",
       "      <td>103.0</td>\n",
       "      <td>58625</td>\n",
       "      <td>2549760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>51.639044</td>\n",
       "      <td>1.342087</td>\n",
       "      <td>301.281766</td>\n",
       "      <td>230.0</td>\n",
       "      <td>58625</td>\n",
       "      <td>5089280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>51.695049</td>\n",
       "      <td>1.343060</td>\n",
       "      <td>312.072526</td>\n",
       "      <td>134.0</td>\n",
       "      <td>58625</td>\n",
       "      <td>2549760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>51.477736</td>\n",
       "      <td>1.344443</td>\n",
       "      <td>316.188802</td>\n",
       "      <td>134.0</td>\n",
       "      <td>58625</td>\n",
       "      <td>2549760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>50.961071</td>\n",
       "      <td>1.344631</td>\n",
       "      <td>332.394076</td>\n",
       "      <td>86.0</td>\n",
       "      <td>58625</td>\n",
       "      <td>1280000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>51.612431</td>\n",
       "      <td>1.325470</td>\n",
       "      <td>342.234177</td>\n",
       "      <td>230.0</td>\n",
       "      <td>58625</td>\n",
       "      <td>5089280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>51.707715</td>\n",
       "      <td>1.325860</td>\n",
       "      <td>342.820482</td>\n",
       "      <td>134.0</td>\n",
       "      <td>58625</td>\n",
       "      <td>2549760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>51.404846</td>\n",
       "      <td>1.328756</td>\n",
       "      <td>334.487196</td>\n",
       "      <td>134.0</td>\n",
       "      <td>58625</td>\n",
       "      <td>2549760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>51.012802</td>\n",
       "      <td>1.331369</td>\n",
       "      <td>319.369418</td>\n",
       "      <td>86.0</td>\n",
       "      <td>58625</td>\n",
       "      <td>1280000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>51.326191</td>\n",
       "      <td>1.353414</td>\n",
       "      <td>352.303264</td>\n",
       "      <td>221.5</td>\n",
       "      <td>58625</td>\n",
       "      <td>2549760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>51.628065</td>\n",
       "      <td>1.354472</td>\n",
       "      <td>338.714797</td>\n",
       "      <td>125.5</td>\n",
       "      <td>58625</td>\n",
       "      <td>1280000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>51.297379</td>\n",
       "      <td>1.355245</td>\n",
       "      <td>368.512635</td>\n",
       "      <td>125.5</td>\n",
       "      <td>58625</td>\n",
       "      <td>1280000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>50.732136</td>\n",
       "      <td>1.355440</td>\n",
       "      <td>355.984064</td>\n",
       "      <td>77.5</td>\n",
       "      <td>58625</td>\n",
       "      <td>645120</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    data_width  data_frac_width  weight_width  weight_frac_width  bias_width  \\\n",
       "0           16                8            16                  8           8   \n",
       "1           16                8             8                  6           8   \n",
       "2           16                8             8                  4           8   \n",
       "3           16                8             4                  2           8   \n",
       "4            8                6            16                  8           8   \n",
       "5            8                6             8                  6           8   \n",
       "6            8                6             8                  4           8   \n",
       "7            8                6             4                  2           8   \n",
       "8            8                4            16                  8           8   \n",
       "9            8                4             8                  6           8   \n",
       "10           8                4             8                  4           8   \n",
       "11           8                4             4                  2           8   \n",
       "12           4                2            16                  8           8   \n",
       "13           4                2             8                  6           8   \n",
       "14           4                2             8                  4           8   \n",
       "15           4                2             4                  2           8   \n",
       "\n",
       "    bias_frac_width     acc(%)      loss  latency(ms)  model_size(Byte)  \\\n",
       "0                 4  51.601923  1.325374   349.642160             247.0   \n",
       "1                 4  51.703286  1.325811   298.058322             151.0   \n",
       "2                 4  51.464224  1.328719   307.197314             151.0   \n",
       "3                 4  51.015449  1.331339   306.457938             103.0   \n",
       "4                 4  51.639044  1.342087   301.281766             230.0   \n",
       "5                 4  51.695049  1.343060   312.072526             134.0   \n",
       "6                 4  51.477736  1.344443   316.188802             134.0   \n",
       "7                 4  50.961071  1.344631   332.394076              86.0   \n",
       "8                 4  51.612431  1.325470   342.234177             230.0   \n",
       "9                 4  51.707715  1.325860   342.820482             134.0   \n",
       "10                4  51.404846  1.328756   334.487196             134.0   \n",
       "11                4  51.012802  1.331369   319.369418              86.0   \n",
       "12                4  51.326191  1.353414   352.303264             221.5   \n",
       "13                4  51.628065  1.354472   338.714797             125.5   \n",
       "14                4  51.297379  1.355245   368.512635             125.5   \n",
       "15                4  50.732136  1.355440   355.984064              77.5   \n",
       "\n",
       "    flop(number)  bitwise_ops(number)  \n",
       "0          58625             10168320  \n",
       "1          58625              5089280  \n",
       "2          58625              5089280  \n",
       "3          58625              2549760  \n",
       "4          58625              5089280  \n",
       "5          58625              2549760  \n",
       "6          58625              2549760  \n",
       "7          58625              1280000  \n",
       "8          58625              5089280  \n",
       "9          58625              2549760  \n",
       "10         58625              2549760  \n",
       "11         58625              1280000  \n",
       "12         58625              2549760  \n",
       "13         58625              1280000  \n",
       "14         58625              1280000  \n",
       "15         58625               645120  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics = pd.DataFrame(recorded_metrics)\n",
    "\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/d/imperial/second_term/adls/rs1923/mase_real/machop\n"
     ]
    }
   ],
   "source": [
    "%cd machop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of JSC_1923 parameters: 3285\n",
      "Total number of JSC_Tiny parameters: 117\n",
      "Seed set to 0\n",
      "+-------------------------+--------------------------+--------------------------+--------------------------+--------------------------+\n",
      "| Name                    |         Default          |       Config. File       |     Manual Override      |        Effective         |\n",
      "+-------------------------+--------------------------+--------------------------+--------------------------+--------------------------+\n",
      "| task                    |      \u001b[38;5;8mclassification\u001b[0m      |           cls            |                          |           cls            |\n",
      "| load_name               |           \u001b[38;5;8mNone\u001b[0m           | \u001b[38;5;8m../mase_output/jsc-tiny_\u001b[0m | /mnt/d/imperial/second_t | /mnt/d/imperial/second_t |\n",
      "|                         |                          | \u001b[38;5;8mclassification_jsc_2024-\u001b[0m | erm/adls/new/mase/mase_o | erm/adls/new/mase/mase_o |\n",
      "|                         |                          | \u001b[38;5;8m02-05/software/training_\u001b[0m | utput/jsc-tiny_classific | utput/jsc-tiny_classific |\n",
      "|                         |                          |     \u001b[38;5;8mckpts/best.ckpt\u001b[0m      | ation_jsc_2024-02-05/sof | ation_jsc_2024-02-05/sof |\n",
      "|                         |                          |                          | tware/training_ckpts/bes | tware/training_ckpts/bes |\n",
      "|                         |                          |                          |          t.ckpt          |          t.ckpt          |\n",
      "| load_type               |            \u001b[38;5;8mmz\u001b[0m            |            pl            |                          |            pl            |\n",
      "| batch_size              |           \u001b[38;5;8m128\u001b[0m            |           256            |                          |           256            |\n",
      "| to_debug                |          False           |                          |                          |          False           |\n",
      "| log_level               |           info           |                          |                          |           info           |\n",
      "| report_to               |       tensorboard        |                          |                          |       tensorboard        |\n",
      "| seed                    |            \u001b[38;5;8m0\u001b[0m             |            42            |                          |            42            |\n",
      "| quant_config            |           None           |                          |                          |           None           |\n",
      "| training_optimizer      |           adam           |                          |                          |           adam           |\n",
      "| trainer_precision       |         16-mixed         |                          |                          |         16-mixed         |\n",
      "| learning_rate           |          \u001b[38;5;8m1e-05\u001b[0m           |          1e-05           |                          |          1e-05           |\n",
      "| weight_decay            |            0             |                          |                          |            0             |\n",
      "| max_epochs              |            \u001b[38;5;8m20\u001b[0m            |            5             |                          |            5             |\n",
      "| max_steps               |            -1            |                          |                          |            -1            |\n",
      "| accumulate_grad_batches |            1             |                          |                          |            1             |\n",
      "| log_every_n_steps       |            \u001b[38;5;8m50\u001b[0m            |            5             |                          |            5             |\n",
      "| num_workers             |            20            |                          |                          |            20            |\n",
      "| num_devices             |            1             |                          |                          |            1             |\n",
      "| num_nodes               |            1             |                          |                          |            1             |\n",
      "| accelerator             |           \u001b[38;5;8mauto\u001b[0m           |           cpu            |                          |           cpu            |\n",
      "| strategy                |           auto           |                          |                          |           auto           |\n",
      "| is_to_auto_requeue      |          False           |                          |                          |          False           |\n",
      "| github_ci               |          False           |                          |                          |          False           |\n",
      "| disable_dataset_cache   |          False           |                          |                          |          False           |\n",
      "| target                  |   xcu250-figd2104-2L-e   |                          |                          |   xcu250-figd2104-2L-e   |\n",
      "| num_targets             |           100            |                          |                          |           100            |\n",
      "| is_pretrained           |          False           |                          |                          |          False           |\n",
      "| max_token_len           |           512            |                          |                          |           512            |\n",
      "| project_dir             | /mnt/d/imperial/second_t |                          |                          | /mnt/d/imperial/second_t |\n",
      "|                         | erm/adls/rs1923/mase_rea |                          |                          | erm/adls/rs1923/mase_rea |\n",
      "|                         |      l/mase_output       |                          |                          |      l/mase_output       |\n",
      "| project                 |           \u001b[38;5;8mNone\u001b[0m           |         jsc-tiny         |                          |         jsc-tiny         |\n",
      "| model                   |           \u001b[38;5;8mNone\u001b[0m           |         jsc-tiny         |                          |         jsc-tiny         |\n",
      "| dataset                 |           \u001b[38;5;8mNone\u001b[0m           |           jsc            |                          |           jsc            |\n",
      "+-------------------------+--------------------------+--------------------------+--------------------------+--------------------------+\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mInitialising model 'jsc-tiny'...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mInitialising dataset 'jsc'...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mProject will be created at /mnt/d/imperial/second_term/adls/rs1923/mase_real/mase_output/jsc-tiny\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mLoaded pytorch lightning checkpoint from /mnt/d/imperial/second_term/adls/new/mase/mase_output/jsc-tiny_classification_jsc_2024-02-05/software/training_ckpts/best.ckpt\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mLoaded model from /mnt/d/imperial/second_term/adls/new/mase/mase_output/jsc-tiny_classification_jsc_2024-02-05/software/training_ckpts/best.ckpt.\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mBuilding search space...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mSearch started...\u001b[0m\n",
      "100%|███████████████████████| 20/20 [00:07<00:00,  2.52it/s, 7.94/20000 seconds]\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mBest trial(s):\n",
      "Best trial(s):\n",
      "|    |   number | software_metrics                   | hardware_metrics                                 | scaled_metrics                               |\n",
      "|----+----------+------------------------------------+--------------------------------------------------+----------------------------------------------|\n",
      "|  0 |        0 | {'loss': 1.351, 'accuracy': 0.516} | {'average_bitwidth': 8.0, 'memory_density': 4.0} | {'accuracy': 0.516, 'average_bitwidth': 1.6} |\n",
      "|  1 |       10 | {'loss': 1.423, 'accuracy': 0.447} | {'average_bitwidth': 4.0, 'memory_density': 8.0} | {'accuracy': 0.447, 'average_bitwidth': 0.8} |\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mSearching is completed\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!./ch search --config configs/examples/jsc_toy_by_type.toml --load /mnt/d/imperial/second_term/adls/new/mase/mase_output/jsc-tiny_classification_jsc_2024-02-05/software/training_ckpts/best.ckpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample efficiency:\n",
    "# uses as few trials(samples) as possible to achieve a certain(optimal) hyperparameters"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mase",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
